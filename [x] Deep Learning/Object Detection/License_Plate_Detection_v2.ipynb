{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K4i-5AkfNnL",
        "outputId": "42fce304-d3b6-43b3-d721-a754c08bd138",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting git+https://github.com/ultralytics/ultralytics.git@main\n",
            "  Cloning https://github.com/ultralytics/ultralytics.git (to revision main) to /tmp/pip-req-build-czhmlzn8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ultralytics/ultralytics.git /tmp/pip-req-build-czhmlzn8\n",
            "  Resolved https://github.com/ultralytics/ultralytics.git to commit 04d7fcb7af34635ac9a4409eb0e975cbbf24f38a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.49) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.49) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.49) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.49) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.49) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.49) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.49) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.49) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.49) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.49) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.49) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.49) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.49) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.49) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.3.49) (2.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.49) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.49) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.49) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.49) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.49) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.49) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.49) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.3.49) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.3.49) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.3.49) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.3.49) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.3.49) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.3.49) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.3.49) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.3.49) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.3.49) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.3.49) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.3.49) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics==8.3.49) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics==8.3.49) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.3.49) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics==8.3.49) (3.0.2)\n",
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.20.1+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (11.0.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.24.0)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.6.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.6)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.3.0.post6)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->easyocr) (1.3.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (3.0.2)\n",
            "Using device: cpu\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Install ultralytics and torch libraries\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install git+https://github.com/ultralytics/ultralytics.git@main\n",
        "!pip install easyocr\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "import io\n",
        "import os\n",
        "import requests\n",
        "import easyocr\n",
        "from PIL import Image\n",
        "import logging\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Check if CUDA is available and set device accordingly\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load a pre-trained YOLO model (placeholder for now)\n",
        "#model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "# Mount Google Drive (Optional)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load your custom model\n",
        "model = YOLO(\"/content/drive/MyDrive/Detection_License_Plate_model/best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# With image enhancements // OCR gpu is nulled and super resolution is nulled\n",
        "\n",
        "!wget https://github.com/Saafke/EDSR_Tensorflow/raw/master/models/EDSR_x4.pb\n",
        "from cv2.dnn_superres import DnnSuperResImpl_create\n",
        "\n",
        "# Initialize EasyOCR reader with GPU enabled for faster processing\n",
        "reader = easyocr.Reader(['en'])#, gpu=True)\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(filename='processing.log', level=logging.INFO,\n",
        "                    format='%(asctime)s - %(message)s')\n",
        "\n",
        "# Initialize Super-Resolution model\n",
        "sr = DnnSuperResImpl_create()\n",
        "sr.readModel(\"EDSR_x4.pb\")  # Pre-trained model\n",
        "sr.setModel(\"edsr\", 4)  # 4x upscaling\n",
        "\n",
        "# Function to enhance image contrast using CLAHE\n",
        "def enhance_contrast(image):\n",
        "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
        "    l = clahe.apply(l)\n",
        "    lab = cv2.merge((l, a, b))\n",
        "    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "# Function for gamma correction\n",
        "def gamma_correction(image, gamma=1.5):\n",
        "    inv_gamma = 1.0 / gamma\n",
        "    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in range(256)]).astype(\"uint8\")\n",
        "    return cv2.LUT(image, table)\n",
        "\n",
        "# Function to preprocess an image\n",
        "def preprocess_plate(plate_region):\n",
        "    plate_region = enhance_contrast(plate_region)\n",
        "    plate_region = gamma_correction(plate_region, gamma=1.2)\n",
        "    gray = cv2.cvtColor(plate_region, cv2.COLOR_BGR2GRAY)\n",
        "    preprocessed_image = cv2.adaptiveThreshold(\n",
        "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
        "    )\n",
        "    return preprocessed_image\n",
        "\n",
        "# Function to enhance plate region with super-resolution\n",
        "def super_resolve(plate_region):\n",
        "    return sr.upsample(plate_region)\n",
        "\n",
        "# Function to validate and format license plate text\n",
        "def validate_and_format_text(text):\n",
        "    allowed_characters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789- \"  # License plate-specific characters\n",
        "    filtered_text = ''.join([char for char in text.upper() if char in allowed_characters])\n",
        "    if len(filtered_text) >= 5:  # Validate based on region-specific patterns\n",
        "        return filtered_text\n",
        "    return None\n",
        "\n",
        "# Function to process a single image\n",
        "def process_image(image, model, show_preprocessing=False):\n",
        "    results = model.predict(image, conf=0.15, iou=0.25)  # Fine-tuned thresholds\n",
        "    detected_texts = []\n",
        "    fixed_plate_resolution = (240, 120)  # Fixed resolution for plate images\n",
        "\n",
        "    for r in results:\n",
        "        if hasattr(r, 'boxes'):\n",
        "            for i, box in enumerate(r.boxes):\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "\n",
        "                # Add dynamic padding\n",
        "                padding = int(0.05 * min(x2 - x1, y2 - y1))\n",
        "                x1, y1 = max(0, x1 - padding), max(0, y1 - padding)\n",
        "                x2, y2 = min(image.shape[1], x2 + padding), min(image.shape[0], y2 + padding)\n",
        "\n",
        "                # Preprocess the cropped region\n",
        "                plate_region = image[y1:y2, x1:x2]\n",
        "                #plate_region = super_resolve(plate_region)  # Apply super-resolution\n",
        "                preprocessed_image = preprocess_plate(plate_region)\n",
        "\n",
        "                # Perform OCR\n",
        "                ocr_results = reader.readtext(preprocessed_image, detail=1)\n",
        "\n",
        "                for _, text, _ in ocr_results:\n",
        "                    formatted_text = validate_and_format_text(text)\n",
        "                    if formatted_text:\n",
        "                        detected_texts.append(formatted_text)\n",
        "\n",
        "                        # Display cropped plate region above detection box\n",
        "                        overlay_x1 = max(0, x1)\n",
        "                        overlay_x2 = min(image.shape[1], x1 + fixed_plate_resolution[0])\n",
        "                        overlay_y1 = max(0, y1 - fixed_plate_resolution[1] - 50)\n",
        "                        overlay_y2 = y1 - 50\n",
        "\n",
        "                        if overlay_y1 >= 0:  # Ensure the overlay doesn't go out of bounds\n",
        "                            resized_plate = cv2.resize(plate_region, fixed_plate_resolution)\n",
        "                            image[overlay_y1:overlay_y2, overlay_x1:overlay_x2] = resized_plate\n",
        "\n",
        "                        # Draw bounding boxes and text above cropped plate\n",
        "                        text_size = cv2.getTextSize(formatted_text, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)[0]\n",
        "                        text_x, text_y = overlay_x1, overlay_y1 - 10\n",
        "                        cv2.rectangle(\n",
        "                            image,\n",
        "                            (text_x, text_y - text_size[1] - 5),\n",
        "                            (text_x + text_size[0] + 5, text_y + 5),\n",
        "                            (0, 255, 0), -1\n",
        "                        )\n",
        "                        cv2.putText(\n",
        "                            image, formatted_text, (text_x, text_y),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2\n",
        "                        )\n",
        "\n",
        "    return image, \"\\n\".join(detected_texts)\n",
        "\n",
        "# Function to save results\n",
        "def save_results(file_path, processed_image, extracted_text, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    filename = os.path.basename(file_path)\n",
        "    base_name = os.path.splitext(filename)[0]\n",
        "\n",
        "    if processed_image is not None:\n",
        "        processed_image_path = os.path.join(output_dir, f\"{base_name}_processed.jpg\")\n",
        "        cv2.imwrite(processed_image_path, processed_image)\n",
        "\n",
        "    text_file_path = os.path.join(output_dir, f\"{base_name}_detected_plates.txt\")\n",
        "    with open(text_file_path, \"w\") as f:\n",
        "        f.write(extracted_text)\n",
        "\n",
        "    logging.info(f\"Processed results saved for: {file_path}\")\n",
        "\n",
        "# Function to process images/videos from a folder or single file\n",
        "def process_files(input_path, output_dir, model, show_preprocessing=False):\n",
        "    if os.path.isfile(input_path):\n",
        "        process_file(input_path, output_dir, model, show_preprocessing)\n",
        "    elif os.path.isdir(input_path):\n",
        "        files = [os.path.join(input_path, f) for f in os.listdir(input_path)\n",
        "                 if f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".mp4\"))]\n",
        "\n",
        "        # Process files in parallel\n",
        "        with ThreadPoolExecutor() as executor:\n",
        "            for file_path in files:\n",
        "                executor.submit(process_file, file_path, output_dir, model, show_preprocessing)\n",
        "    else:\n",
        "        logging.error(f\"Invalid path: {input_path}\")\n",
        "\n",
        "# Function to process a single file (image or video)\n",
        "def process_file(file_path, output_dir, model, show_preprocessing=False):\n",
        "    if file_path.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        image = cv2.imread(file_path)\n",
        "        if image is not None:\n",
        "            processed_image, extracted_text = process_image(image, model, show_preprocessing)\n",
        "            save_results(file_path, processed_image, extracted_text, output_dir)\n",
        "    elif file_path.lower().endswith('.mp4'):\n",
        "        process_video(file_path, output_dir, model)\n",
        "\n",
        "# Function to process video files\n",
        "def process_video(video_path, output_dir, model):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    output_video_path = os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(video_path))[0]}_processed.mp4\")\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Process every single frame\n",
        "        processed_frame, _ = process_image(frame, model)\n",
        "        out.write(processed_frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    logging.info(f\"Processed video saved to: {output_video_path}\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    from ultralytics import YOLO\n",
        "\n",
        "    input_path = \"/content/drive/MyDrive/Detection_License_Plate_model/number_plates_post_model_train\"\n",
        "    output_dir = \"/content/drive/MyDrive/Detection_License_Plate_model/detected_results\"\n",
        "\n",
        "\n",
        "    # Process folder or single file\n",
        "    process_files(input_path, output_dir, model, show_preprocessing=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woZbiObVRFY9",
        "outputId": "cc023c9f-1838-465f-cb65-19048ed1e87f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-14 11:17:33--  https://github.com/Saafke/EDSR_Tensorflow/raw/master/models/EDSR_x4.pb\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Saafke/EDSR_Tensorflow/master/models/EDSR_x4.pb [following]\n",
            "--2024-12-14 11:17:33--  https://raw.githubusercontent.com/Saafke/EDSR_Tensorflow/master/models/EDSR_x4.pb\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 38573255 (37M) [application/octet-stream]\n",
            "Saving to: ‘EDSR_x4.pb.4’\n",
            "\n",
            "EDSR_x4.pb.4        100%[===================>]  36.79M   144MB/s    in 0.3s    \n",
            "\n",
            "2024-12-14 11:17:34 (144 MB/s) - ‘EDSR_x4.pb.4’ saved [38573255/38573255]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "0: 448x640 1 License_Plate, 280.0ms\n",
            "Speed: 7.3ms preprocess, 280.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x448 1 License_Plate, 394.3ms\n",
            "Speed: 8.8ms preprocess, 394.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
            "0: 448x640 3 License_Plates, 399.0ms\n",
            "Speed: 11.5ms preprocess, 399.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x448 1 License_Plate, 495.1ms\n",
            "Speed: 24.4ms preprocess, 495.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n",
            "0: 448x640 1 License_Plate, 494.5ms\n",
            "Speed: 19.8ms preprocess, 494.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "0: 320x640 2 License_Plates, 659.4ms\n",
            "Speed: 5.5ms preprocess, 659.4ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 448x640 5 License_Plates, 620.2ms\n",
            "Speed: 4.9ms preprocess, 620.2ms inference, 8.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "\n",
            "0: 384x640 2 License_Plates, 530.3ms\n",
            "Speed: 3.7ms preprocess, 530.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x512 1 License_Plate, 775.1ms\n",
            "Speed: 11.2ms preprocess, 775.1ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 384x640 2 License_Plates, 454.0ms\n",
            "Speed: 4.7ms preprocess, 454.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 640x640 1 License_Plate, 808.2ms\n",
            "Speed: 23.8ms preprocess, 808.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "0: 448x640 2 License_Plates, 522.8ms\n",
            "Speed: 19.8ms preprocess, 522.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "0: 448x640 2 License_Plates, 519.6ms\n",
            "Speed: 4.6ms preprocess, 519.6ms inference, 9.5ms postprocess per image at shape (1, 3, 448, 640)\n"
          ]
        }
      ]
    }
  ]
}