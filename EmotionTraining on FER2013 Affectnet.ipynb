{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1351797,"sourceType":"datasetVersion","datasetId":786787},{"sourceId":10537282,"sourceType":"datasetVersion","datasetId":6519896},{"sourceId":10634054,"sourceType":"datasetVersion","datasetId":6583945}],"dockerImageVersionId":30841,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ResNet18 + MobileNetV2 + EfficientNetB0\n# folcalloss is good for fer2013\n\n!pip install tensorflow\n!pip install numpy\n!pip install matplotlib\n!pip install psutil\nimport tensorflow as tf\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Customized 2.2 (deepsea)\n\nimport os\nimport gc\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom tensorflow.keras.applications import MobileNetV2, Xception, EfficientNetB0\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\nfrom tensorflow.keras.layers import Concatenate, Activation, Lambda, Input\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport psutil\nfrom datetime import datetime\n\n# =============================================================================\n# Configure GPU and enable mixed precision\n# =============================================================================\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(f\"Found {len(gpus)} GPUs: Memory growth enabled\")\n    except RuntimeError as e:\n        print(f\"GPU error: {e}\")\n\n# Enable mixed precision training\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled\")\n\n# =============================================================================\n# Key parameters (Adjusted for memory optimization)\n# =============================================================================\nBATCH_SIZE = 64  # Maintain balance between memory and throughput\nAUTOTUNE = tf.data.AUTOTUNE\nLOG_DIR = \"./emotion_logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\ndef ensure_dir(directory):\n    if not os.path.exists(directory):\n        os.makedirs(directory, exist_ok=True)\n\n# Create main log directories\nensure_dir(LOG_DIR)\nensure_dir(LOG_DIR + '/affectnet')\nensure_dir(LOG_DIR + '/fer2013')\nensure_dir(LOG_DIR + '/combined')\nensure_dir(LOG_DIR + '/ensemble')\nensure_dir(\"./model_checkpoints\")\nensure_dir(\"./cache\")\nensure_dir(\"./weights\")\n\n#===========>\n# Make sure this code block runs successfully BEFORE creating the model\n!mkdir -p weights\n!wget https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5 -P weights\n!wget https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5 -P weights\n\n# The original URL isn't working, so let's try these alternatives for EfficientNetB0\n#!wget https://github.com/Runist/BasicNet/releases/download/dataset/efficientnetb0_notop.h5 -P weights\n# If that fails, try this direct link\n!wget /kaggle/input/efficientnetb0-notop-h5/efficientnetb0_notop.h5 -P weights\n\n# Verify downloads\n!ls -lh weights/*\n#===========>\n\n\n# Define problematic classes for targeted augmentation\nPROBLEMATIC_CLASSES = ['surprise', 'sad', 'disgust']\n\n# =============================================================================\n# Focal Loss for better handling of class imbalance\n# =============================================================================\ndef focal_loss(gamma=2.0, alpha=None):\n    \"\"\"\n    Focal loss implementation for better handling of class imbalance.\n    Focuses training on hard examples by down-weighting easy examples.\n    \n    Args:\n        gamma: Focusing parameter (higher = more focus on hard examples)\n        alpha: Optional class weight factors\n        \n    Returns:\n        Loss function\n    \"\"\"\n    def loss_fn(y_true, y_pred):\n        # Add small epsilon to avoid log(0)\n        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0)\n        \n        # Basic cross entropy\n        cross_entropy = -y_true * tf.math.log(y_pred)\n        \n        # Apply class weighting if provided\n        if alpha is not None:\n            # Convert alpha to proper shape if it's a dict\n            if isinstance(alpha, dict):\n                # Create a tensor of appropriate shape filled with ones\n                alpha_tensor = tf.ones_like(y_true)\n                \n                # For each class index in the alpha dict, update the corresponding\n                # position in alpha_tensor with the weight value\n                for class_idx, weight in alpha.items():\n                    # Create a mask for the current class\n                    class_mask = tf.cast(tf.equal(tf.argmax(y_true, axis=-1), class_idx), tf.float32)\n                    \n                    # Reshape to broadcast properly\n                    class_mask = tf.expand_dims(class_mask, axis=-1)\n                    \n                    # Update weights for this class\n                    alpha_tensor = alpha_tensor * (1 - class_mask) + weight * class_mask\n                \n                cross_entropy = alpha_tensor * cross_entropy\n            else:\n                cross_entropy = alpha * cross_entropy\n        \n        # Apply focusing parameter\n        focal_weight = tf.pow(1 - y_pred, gamma)\n        focal_loss = focal_weight * cross_entropy\n        \n        # Sum over classes\n        return tf.reduce_sum(focal_loss, axis=-1)\n    \n    return loss_fn\n\n# =============================================================================\n# FIXED: Enhanced Image Preprocessing with Consistent Size\n# =============================================================================\ndef preprocess_image(file_path, label, source, training=True):\n    \"\"\"\n    Enhanced preprocessing with consistent output size for all images.\n    \n    Args:\n        file_path: Path to the image file\n        label: Emotion label (as index)\n        source: Dataset source ('fer2013' or 'affectnet')\n        training: Whether to apply augmentation\n        \n    Returns:\n        Preprocessed image (consistent size) and one-hot encoded label\n    \"\"\"\n    # Read the file\n    img = tf.io.read_file(file_path)\n    \n    # Decode image with proper error handling\n    def decode_image():\n        try:\n            decoded = tf.image.decode_image(img, channels=3, expand_animations=False)\n            decoded = tf.ensure_shape(decoded, [None, None, 3])\n            return decoded\n        except:\n            # Return blank image if decoding fails\n            return tf.zeros([224, 224, 3], dtype=tf.uint8)\n    \n    img = decode_image()\n    img = tf.cast(img, tf.float32)\n    \n    # Dataset-specific preprocessing for grayscale/RGB\n    if source == 'fer2013':\n        # Properly handle grayscale images\n        if tf.shape(img)[-1] == 1:\n            img = tf.tile(img, [1, 1, 3])  # Expand to 3 channels\n        else:\n            # Convert to grayscale then back to 3 channels for consistency\n            img = tf.image.rgb_to_grayscale(img)\n            img = tf.tile(img, [1, 1, 3])\n    \n    # CRITICAL: Resize ALL images to a standard intermediate size\n    # 224x224 is chosen as it's compatible with EfficientNetB0\n    img = tf.image.resize(img, [224, 224], method='bilinear')\n    \n    # Apply basic augmentation during training\n    if training:\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_brightness(img, 0.2)\n        img = tf.image.random_contrast(img, 0.8, 1.2)\n        noise = tf.random.normal(shape=tf.shape(img), mean=0.0, stddev=0.01)\n        img = img + noise\n        img = tf.clip_by_value(img, 0.0, 255.0)  # Ensure valid range\n    \n    # Basic normalization to [0,1] range for consistency\n    # Note: Model-specific normalization will happen in the model\n    img = img / 255.0\n    \n    # One-hot encode label\n    label = tf.one_hot(label, depth=8)  # 8 emotion classes\n    \n    return img, label\n\n# =============================================================================\n# Build DataFrame from dataset directory structure\n# =============================================================================\ndef build_image_df(root_dir, subfolders=[\"fer2013\", \"affectnet\"]):\n    \"\"\"\n    Scans the directory and returns a DataFrame with file paths and labels.\n    \"\"\"\n    data = []\n    emotions = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n    \n    print(f\"Found {len(emotions)} emotion categories: {emotions}\")\n    \n    for emotion in emotions:\n        emotion_path = os.path.join(root_dir, emotion)\n        for sub in subfolders:\n            sub_path = os.path.join(emotion_path, sub)\n            if os.path.exists(sub_path):\n                img_files = [f for f in os.listdir(sub_path) \n                            if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n                \n                print(f\"Found {len(img_files)} images in {emotion}/{sub}\")\n                \n                for img_file in img_files:\n                    data.append({\n                        \"filepath\": os.path.join(sub_path, img_file),\n                        \"label\": emotion,\n                        \"source\": sub\n                    })\n    \n    df = pd.DataFrame(data)\n    print(f\"Total images: {len(df)}\")\n    return df\n\n# =============================================================================\n# FIXED: Enhanced dataset creation with caching and repeat\n# =============================================================================\ndef create_dataset(dataframe, is_training=True, dataset_type=None, cache=False):\n    \"\"\"Memory-optimized dataset creation\"\"\"\n    if dataset_type:\n        dataframe = dataframe[dataframe['source'] == dataset_type].reset_index(drop=True)\n    \n    class_indices = {cls: i for i, cls in enumerate(sorted(dataframe[\"label\"].unique()))}\n    labels = [class_indices[label] for label in dataframe[\"label\"]]\n    \n    ds = tf.data.Dataset.from_tensor_slices((\n        dataframe[\"filepath\"].values,\n        labels,\n        dataframe[\"source\"].values\n    ))\n    \n    # Memory optimization: Only cache validation/test datasets\n    if cache and not is_training:\n        ds = ds.cache(f'./cache/{dataset_type}_cache' if dataset_type else './cache/combined_cache')\n    \n    training_value = tf.constant(is_training)\n    ds = ds.map(\n        lambda path, label, source: preprocess_image(path, label, source, training=training_value),\n        num_parallel_calls=AUTOTUNE\n    )\n    \n    if is_training:\n        ds = ds.shuffle(buffer_size=min(10000, len(dataframe)))\n        ds = ds.repeat()\n    \n    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n    \n    return ds, class_indices\n\n# =============================================================================\n# Create balanced dataset with emphasis classes\n# =============================================================================\ndef create_emphasis_dataset(dataframe, is_training=True, emphasis_classes=PROBLEMATIC_CLASSES):\n    \"\"\"\n    Creates a balanced dataset with emphasis on problematic classes.\n    \n    Args:\n        dataframe: Input DataFrame\n        is_training: Whether to apply training augmentations\n        emphasis_classes: List of classes to emphasize (oversample)\n        cache: Whether to cache the dataset\n        \n    Returns:\n        Balanced tf.data.Dataset with emphasis on specified classes\n    \"\"\"\n    balanced_data = []\n    \n    # Sample from each class with emphasis on problematic ones\n    for class_name in sorted(dataframe[\"label\"].unique()):\n        class_df = dataframe[dataframe[\"label\"] == class_name]\n        samples_per_class = 400  # Base sampling\n        \n        # Increase samples for emphasis classes\n        if class_name in emphasis_classes:\n            samples_per_class = 600  # 50% more samples for problematic classes\n            \n        # Sample with replacement if needed\n        if len(class_df) <= samples_per_class:\n            sampled = class_df.sample(n=samples_per_class, replace=True)\n        else:\n            sampled = class_df.sample(n=samples_per_class, replace=False)\n            \n        balanced_data.append(sampled)\n    \n    # Combine all balanced samples\n    balanced_df = pd.concat(balanced_data, ignore_index=True)\n    print(f\"Created balanced dataset with {len(balanced_df)} samples (with emphasis on {emphasis_classes})\")\n    \n    # Create dataset with caching\n    return create_dataset(balanced_df, is_training=is_training, cache=False)\n\n# =============================================================================\n# Enhanced Confusion Matrix Callback with Class-Specific Monitoring\n# =============================================================================\nclass EnhancedConfusionMatrixCallback(tf.keras.callbacks.Callback):\n    \"\"\"\n    Enhanced callback to monitor class-specific metrics during training.\n    \"\"\"\n    def __init__(self, validation_data, class_names, log_dir, model_name=\"model\", freq=5):\n        super(EnhancedConfusionMatrixCallback, self).__init__()\n        self.validation_data = validation_data\n        self.class_names = class_names\n        self.freq = freq\n        self.log_dir = log_dir\n        self.model_name = model_name\n        self.zero_prediction_classes = set()  # Track classes with zero predictions\n        self.class_metrics_history = {cls: [] for cls in class_names}  # Track per-class metrics\n        \n        # Ensure log directory exists\n        ensure_dir(self.log_dir)\n        \n    def on_epoch_end(self, epoch, logs=None):\n        # Calculate and log class-specific metrics every epoch\n        val_steps = 20  # Limit computation\n        y_true = []\n        y_pred = []\n        \n        # Get predictions for validation data\n        for i, (images, labels) in enumerate(self.validation_data):\n            if i >= val_steps:\n                break\n            batch_preds = self.model.predict(images, verbose=0)\n            y_pred.append(np.argmax(batch_preds, axis=1))\n            y_true.append(np.argmax(labels.numpy(), axis=1))\n        \n        # Flatten the lists\n        y_true = np.concatenate(y_true)\n        y_pred = np.concatenate(y_pred)\n        \n        # Calculate confusion matrix\n        cm = confusion_matrix(y_true, y_pred)\n        \n        # Calculate per-class metrics\n        class_accuracies = np.zeros(len(self.class_names))\n        for i in range(len(self.class_names)):\n            if np.sum(y_true == i) > 0:  # Avoid division by zero\n                class_accuracies[i] = cm[i, i] / np.sum(y_true == i)\n                \n            # Track metrics history\n            self.class_metrics_history[self.class_names[i]].append(class_accuracies[i])\n        \n        # Check for classes with zero predictions\n        zero_pred_classes = []\n        for i, class_name in enumerate(self.class_names):\n            if np.sum(cm[:, i]) == 0:\n                zero_pred_classes.append(class_name)\n                self.zero_prediction_classes.add(class_name)\n        \n        # Log warnings for zero prediction classes\n        if zero_pred_classes:\n            warning_msg = f\"\\n⚠️ WARNING: Zero predictions for classes: {', '.join(zero_pred_classes)}\"\n            print(warning_msg)\n            \n            # Save warning to log file\n            with open(f\"{self.log_dir}/warnings.txt\", \"a\") as f:\n                f.write(f\"Epoch {epoch+1}: {warning_msg}\\n\")\n       \n        # Save visualizations and detailed reports on the specified frequency\n        if (epoch + 1) % self.freq == 0:\n            # Print confusion matrix\n            print(\"\\nConfusion Matrix:\")\n            print(cm)\n            \n            # Print per-class accuracy\n            for i, (name, acc) in enumerate(zip(self.class_names, class_accuracies)):\n                print(f\"{name}: {acc:.4f}\", end=\"  \")\n                if (i + 1) % 4 == 0:\n                    print()  # New line for readability\n            print(\"\\n\")\n            \n            # Print class accuracy trends\n            print(\"Class Accuracy Trends:\")\n            for class_name in self.class_names:\n                history = self.class_metrics_history[class_name]\n                trend = \", \".join([f\"{acc:.4f}\" for acc in history[-5:]])  # Show last 5 epochs\n                print(f\"{class_name}: [{trend}]\")\n            print()\n            \n            # Save confusion matrix visualization\n            plt.figure(figsize=(10, 8))\n            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                       xticklabels=self.class_names,\n                       yticklabels=self.class_names)\n            plt.xlabel('Predicted')\n            plt.ylabel('True')\n            plt.title(f'Confusion Matrix - {self.model_name} - Epoch {epoch+1}')\n            plt.tight_layout()\n            \n            try:\n                plt.savefig(f'{self.log_dir}/confusion_matrix_epoch_{epoch+1}.png')\n            except Exception as e:\n                print(f\"Warning: Could not save confusion matrix plot: {e}\")\n            \n            plt.close()\n\n        # Add memory cleanup\n        del images, labels, batch_preds\n        gc.collect()\n\n# =============================================================================\n# FIXED: Create Ensemble Model Architecture with Internal Preprocessing\n# =============================================================================\ndef create_ensemble_model(num_classes=8, freeze_base=True):\n    \"\"\"\n    Create an ensemble with model-specific preprocessing layers.\n    All preprocessing happens inside the model, which expects\n    a standard size input (224x224x3 normalized to [0,1]).\n    \n    Args:\n        num_classes: Number of emotion classes\n        freeze_base: Whether to freeze base models initially\n        \n    Returns:\n        Compiled Keras ensemble model\n    \"\"\"\n    # Create inputs for consistently sized images\n    inputs = keras.layers.Input(shape=(224, 224, 3), name='image_input')\n    \n    # === MobileNetV2 Branch ===\n    # Resize and normalize for MobileNetV2\n    mobilenet_preprocess = Lambda(\n        lambda x: tf.image.resize(x*255.0, [96, 96]) / 127.5 - 1,\n        name='mobilenet_preprocess'\n    )(inputs)\n    \n    try:\n        mobilenet_base = MobileNetV2(\n            include_top=False, \n            weights='imagenet',\n            input_tensor=mobilenet_preprocess,\n            alpha=1.0,\n            name='mobilenet_base'\n        )\n    except Exception as e:\n        print(f\"MobileNetV2 imagenet weights failed to load: {e}\")\n        mobilenet_base = MobileNetV2(\n            include_top=False,\n            weights=None,\n            input_tensor=mobilenet_preprocess,\n            alpha=1.0,\n            name='mobilenet_base'\n        )\n        mobilenet_base.load_weights('weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5')\n\n    if freeze_base:\n        mobilenet_base.trainable = False\n\n    # === Xception Branch ===\n    # Resize and normalize for Xception\n    xception_preprocess = Lambda(\n        lambda x: tf.keras.applications.xception.preprocess_input(\n            tf.image.resize(x*255.0, [299, 299])\n        ),\n        name='xception_preprocess'\n    )(inputs)\n    \n    try:\n        xception_base = Xception(\n            include_top=False,\n            weights='imagenet',\n            input_tensor=xception_preprocess,\n            name='xception_base'\n        )\n    except Exception as e:\n        print(f\"Xception imagenet weights failed to load: {e}\")\n        xception_base = Xception(\n            include_top=False,\n            weights=None,\n            input_tensor=xception_preprocess,\n            name='xception_base'\n        )\n        xception_base.load_weights('weights/xception_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\n    if freeze_base:\n        xception_base.trainable = False\n\n    # === EfficientNetB0 Branch ===\n    efficientnet_preprocess = Lambda(\n        lambda x: tf.keras.applications.efficientnet.preprocess_input(\n        tf.image.resize(x, [224, 224])  # Remove *255.0 scaling\n    ),\n        name='efficientnet_preprocess'\n    )(inputs)\n    \n    try:\n        efficientnet_base = EfficientNetB0(\n            include_top=False,\n            weights='imagenet',\n            input_tensor=efficientnet_preprocess,\n            name='efficientnet_base'\n        )\n    except Exception as e:\n        print(f\"EfficientNetB0 imagenet weights failed to load: {e}\")\n        efficientnet_base = EfficientNetB0(\n            include_top=False,\n            weights=None,\n            input_tensor=efficientnet_preprocess,\n            name='efficientnet_base'\n        )\n        efficientnet_base.load_weights('weights/efficientnetb0_notop.h5')\n\n    if freeze_base:\n        efficientnet_base.trainable = False\n\n    # Feature extraction for all branches\n    mobilenet_features = GlobalAveragePooling2D(name='mobilenet_gap')(mobilenet_base.output)\n    xception_features = GlobalAveragePooling2D(name='xception_gap')(xception_base.output)\n    efficientnet_features = GlobalAveragePooling2D(name='efficientnet_gap')(efficientnet_base.output)\n\n    # Feature processing\n    def create_projection_head(inputs, name):\n        x = Dense(128, name=f'{name}_projection')(inputs)\n        x = BatchNormalization()(x)\n        return Activation('relu')(x)\n    \n    mobilenet_features = create_projection_head(mobilenet_features, 'mobilenet')\n    xception_features = create_projection_head(xception_features, 'xception')\n    efficientnet_features = create_projection_head(efficientnet_features, 'efficientnet')\n\n    # Feature fusion\n    merged_features = Concatenate(name='feature_fusion')([\n        mobilenet_features, \n        xception_features, \n        efficientnet_features\n    ])\n\n    # Classification head\n    x = Dense(256, name='fusion_dense1')(merged_features)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.5)(x)\n    \n    x = Dense(128, name='fusion_dense2')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.3)(x)\n    \n    outputs = Dense(num_classes, activation='softmax', dtype='float32', name='emotion_output')(x)\n\n    # Create and compile model\n    model = keras.Model(inputs=inputs, outputs=outputs, name='emotion_ensemble')\n    \n    optimizer = tf.keras.mixed_precision.LossScaleOptimizer(\n        keras.optimizers.Adam(\n            tf.keras.optimizers.schedules.CosineDecay(\n                initial_learning_rate=1e-3, \n                decay_steps=10000\n            )\n        )\n    )\n    \n    model.compile(\n        optimizer=optimizer,\n        loss=focal_loss(gamma=2.0),\n        metrics=['accuracy']\n    )\n    \n    return model\n\n# =============================================================================\n# Evaluation function\n# =============================================================================\ndef evaluate_model(model, test_ds, steps, class_names, log_dir, dataset_name=\"\"):\n    \"\"\"\n    Evaluate model with detailed metrics and visualizations.\n    \"\"\"\n    print(f\"\\nEvaluating model on {dataset_name} test set\")\n    \n    # Get predictions\n    y_true = []\n    y_pred = []\n    \n    # Loop through test batches\n    for i, (images, labels) in enumerate(test_ds):\n        if i >= steps:\n            break\n        batch_preds = model.predict(images, verbose=0)\n        y_pred.append(np.argmax(batch_preds, axis=1))\n        y_true.append(np.argmax(labels.numpy(), axis=1))\n    \n    # Concatenate\n    y_true = np.concatenate(y_true)\n    y_pred = np.concatenate(y_pred)\n    \n    # Calculate metrics\n    test_accuracy = np.mean(y_pred == y_true)\n    f1 = f1_score(y_true, y_pred, average='weighted')\n    \n    print(f\"{dataset_name} Test Accuracy: {test_accuracy:.4f}\")\n    print(f\"{dataset_name} Weighted F1-Score: {f1:.4f}\")\n    \n    # Calculate confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Visualize confusion matrix\n    plt.figure(figsize=(12, 10))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n               xticklabels=class_names,\n               yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title(f'Confusion Matrix - {dataset_name} Test Set')\n    plt.tight_layout()\n    \n    try:\n        plt.savefig(f'{log_dir}/confusion_matrix_{dataset_name}_test.png')\n    except Exception as e:\n        print(f\"Warning: Could not save confusion matrix plot: {e}\")\n        \n    plt.close()\n    \n    # Print classification report\n    print(f\"\\n{dataset_name} Classification Report:\")\n    report = classification_report(\n        y_true, \n        y_pred, \n        target_names=class_names,\n        zero_division=0\n    )\n    print(report)\n    \n    # Save report to file\n    with open(f'{log_dir}/classification_report_{dataset_name}.txt', 'w') as f:\n        f.write(report)\n    \n    return {\n        'accuracy': test_accuracy,\n        'f1_score': f1,\n        'confusion_matrix': cm\n    }\n\n# =============================================================================\n# Progressive Training Strategy for Ensemble\n# =============================================================================\ndef train_ensemble_with_progressive_strategy(model, train_ds, val_ds, \n                                           steps_per_epoch, val_steps,\n                                           total_epochs=30,\n                                           callbacks=None,\n                                           class_weights=None):\n    \"\"\"\n    Three-stage training approach for ensemble:\n    1. Train only the fusion layers (all base models frozen)\n    2. Unfreeze and train EfficientNet and MobileNet (keep Xception frozen)\n    3. Unfreeze and fine-tune all models\n    \n    Args:\n        model: The ensemble model\n        train_ds: Training dataset\n        val_ds: Validation dataset\n        steps_per_epoch: Steps per training epoch\n        val_steps: Validation steps\n        total_epochs: Total epochs across all stages\n        callbacks: List of callbacks\n        class_weights: Class weights for handling imbalance\n        \n    Returns:\n        Training history\n    \"\"\"\n    histories = []\n    \n    # Stage 1: Train only fusion layers (10% of total epochs)\n    stage1_epochs = max(3, int(total_epochs * 0.1))\n    print(f\"\\nStage 1: Training only fusion layers ({stage1_epochs} epochs)\")\n    \n    # Ensure base models are frozen\n    for layer in model.layers:\n        if any(base_name in layer.name for base_name in ['mobilenet_base', 'xception_base', 'efficientnet_base']):\n            for base_layer in layer.layers:\n                base_layer.trainable = False\n    \n    # Train fusion layers\n    history1 = model.fit(\n        train_ds,\n        epochs=stage1_epochs,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=val_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    histories.append(history1)\n\n    K.clear_session()\n    gc.collect()\n    \n    # Stage 2: Unfreeze and train EfficientNet and MobileNet (30% of total epochs)\n    stage2_epochs = max(6, int(total_epochs * 0.3))\n    print(f\"\\nStage 2: Training EfficientNet and MobileNet branches ({stage2_epochs} epochs)\")\n    \n    # Get reference to actual base models\n    mobilenet = model.get_layer('mobilenet_base')  # Correct access\n    efficientnet = model.get_layer('efficientnet_base')  # Correct access\n    for base_model in [mobilenet, efficientnet]:  # Proper iteration\n        for layer in base_model.layers[-30:]:  # Correct layer access\n                layer.trainable = True\n    \n    # Recompile with lower learning rate\n    optimizer = keras.optimizers.Adam(1e-4)  # Lower learning rate\n    optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n    \n    model.compile(\n        optimizer=optimizer,\n        loss=focal_loss(gamma=2.0),\n        metrics=['accuracy']\n    )\n    \n    # Train with partial unfreezing\n    history2 = model.fit(\n        train_ds,\n        epochs=stage2_epochs,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=val_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    histories.append(history2)\n\n    K.clear_session()\n    gc.collect()\n    \n    # Stage 3: Unfreeze all models and fine-tune (remaining epochs)\n    stage3_epochs = total_epochs - stage1_epochs - stage2_epochs\n    print(f\"\\nStage 3: Fine-tuning all models ({stage3_epochs} epochs)\")\n    \n    # Get reference to all base models\n    xception = model.get_layer('xception_base')\n    for base_model in [mobilenet, efficientnet, xception]:\n        for layer in base_model.layers[-50:]:\n            layer.trainable = True\n    \n    # Recompile with even lower learning rate\n    optimizer = keras.optimizers.Adam(5e-5)  # Very low learning rate for fine-tuning\n    optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n    \n    model.compile(\n        optimizer=optimizer,\n        loss=focal_loss(gamma=2.0),\n        metrics=['accuracy']\n    )\n    \n    # Final fine-tuning\n    history3 = model.fit(\n        train_ds,\n        epochs=stage3_epochs,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=val_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    histories.append(history3)\n\n    K.clear_session()\n    gc.collect()\n    \n    return histories\n\n# =============================================================================\n# Main training pipeline with ensemble\n# =============================================================================\ndef train_emotion_ensemble(data_dir):\n    \"\"\"\n    Enhanced sequential training pipeline for emotion recognition ensemble.\n    \n    Args:\n        data_dir: Path to dataset directory\n        \n    Returns:\n        Trained ensemble model and evaluation metrics\n    \"\"\"\n    print(\"Starting enhanced ensemble training for emotion recognition\")\n    \n    # 1. Load and prepare data\n    print(\"\\n1. Loading datasets\")\n    train_dir = os.path.join(data_dir, \"Train\")\n    test_dir = os.path.join(data_dir, \"Test\")\n    \n    train_df_full = build_image_df(train_dir)\n    test_df = build_image_df(test_dir)\n    \n    # Show dataset distributions\n    print(\"\\nAffectNet training distribution:\")\n    print(train_df_full[train_df_full['source'] == 'affectnet']['label'].value_counts())\n    \n    print(\"\\nFER2013 training distribution:\")\n    print(train_df_full[train_df_full['source'] == 'fer2013']['label'].value_counts())\n    \n    # 2. Split test set by dataset source\n    test_affectnet_df = test_df[test_df['source'] == 'affectnet']\n    test_fer_df = test_df[test_df['source'] == 'fer2013']\n    \n    print(f\"\\nTest sets: AffectNet={len(test_affectnet_df)}, FER2013={len(test_fer_df)}\")\n    \n    # Get classes for later use\n    classes = sorted(train_df_full[\"label\"].unique())\n    num_classes = len(classes)\n    print(f\"Classes: {classes}\")\n    \n    # 3. Create validation splits\n    # For AffectNet\n    affectnet_train_df = train_df_full[train_df_full['source'] == 'affectnet']\n    affectnet_train_df, affectnet_val_df = train_test_split(\n        affectnet_train_df, \n        test_size=0.15, \n        stratify=affectnet_train_df[\"label\"], \n        random_state=42\n    )\n    \n    # For FER2013\n    fer_train_df = train_df_full[train_df_full['source'] == 'fer2013']\n    fer_train_df, fer_val_df = train_test_split(\n        fer_train_df, \n        test_size=0.15, \n        stratify=fer_train_df[\"label\"], \n        random_state=42\n    )\n    \n    print(f\"AffectNet: {len(affectnet_train_df)} train, {len(affectnet_val_df)} validation\")\n    print(f\"FER2013: {len(fer_train_df)} train, {len(fer_val_df)} validation\")\n    \n    # 4. Create datasets with emphasis on problematic classes and caching\n    print(\"\\n2. Creating enhanced data pipelines with caching\")\n    \n    # Create datasets with memory optimizations\n    affectnet_train_ds, class_indices = create_emphasis_dataset(\n        affectnet_train_df, is_training=True\n    )\n    \n    affectnet_val_ds, _ = create_dataset(\n        affectnet_val_df, is_training=False, \n        dataset_type='affectnet', cache=True\n    )\n    \n    affectnet_test_ds, _ = create_dataset(\n        test_affectnet_df, is_training=False, \n        dataset_type='affectnet', cache=True\n    )\n    \n    fer_train_ds, _ = create_emphasis_dataset(\n        fer_train_df, is_training=True\n    )\n    \n    fer_val_ds, _ = create_dataset(\n        fer_val_df, is_training=False, \n        dataset_type='fer2013', cache=True\n    )\n    \n    fer_test_ds, _ = create_dataset(\n        test_fer_df, is_training=False, \n        dataset_type='fer2013', cache=True\n    )\n    \n    # Create combined test dataset\n    combined_test_ds, _ = create_dataset(\n        test_df, is_training=False, cache=True)\n\n    # Add periodic garbage collection during evaluation\n    def evaluate_with_gc(model, test_ds, steps, class_names, log_dir, dataset_name):\n        metrics = evaluate_model(model, test_ds, steps, class_names, log_dir, dataset_name)\n        K.clear_session()\n        gc.collect()\n        return metrics\n    \n    # 5. Calculate steps with increased batch size\n    affectnet_steps_per_epoch = len(affectnet_train_df) // BATCH_SIZE\n    affectnet_val_steps = len(affectnet_val_df) // BATCH_SIZE\n    affectnet_test_steps = len(test_affectnet_df) // BATCH_SIZE\n    \n    fer_steps_per_epoch = len(fer_train_df) // BATCH_SIZE\n    fer_val_steps = len(fer_val_df) // BATCH_SIZE\n    fer_test_steps = len(test_fer_df) // BATCH_SIZE\n    \n    combined_test_steps = len(test_df) // BATCH_SIZE\n    \n    # 6. Create ensemble model\n    print(\"\\n3. Creating ensemble model architecture\")\n    ensemble_model = create_ensemble_model(num_classes=num_classes, freeze_base=True)\n    print(f\"Ensemble model created with {ensemble_model.count_params():,} parameters\")\n    \n    # 7. Compute class weights for each dataset with adjustments\n    print(\"\\n4. Computing class weights with adjustments for problematic classes\")\n    \n    # AffectNet class weights\n    affectnet_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(affectnet_train_df[\"label\"].values),\n        y=affectnet_train_df[\"label\"].values\n    )\n    affectnet_class_weights = {class_indices[label]: weight for label, weight in \n                     zip(np.unique(affectnet_train_df[\"label\"].values), affectnet_weights)}\n    \n    # FER2013 class weights\n    fer_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(fer_train_df[\"label\"].values),\n        y=fer_train_df[\"label\"].values\n    )\n    fer_class_weights = {class_indices[label]: weight for label, weight in \n                zip(np.unique(fer_train_df[\"label\"].values), fer_weights)}\n    \n    # Increase weights for problematic classes\n    for problem_class in PROBLEMATIC_CLASSES:\n        if problem_class in class_indices:\n            class_idx = class_indices[problem_class]\n            # Increase the weight by 20%\n            if class_idx in affectnet_class_weights:\n                affectnet_class_weights[class_idx] *= 1.2\n            if class_idx in fer_class_weights:\n                fer_class_weights[class_idx] *= 1.2\n    \n    print(\"Enhanced AffectNet class weights:\", affectnet_class_weights)\n    print(\"Enhanced FER2013 class weights:\", fer_class_weights)\n    \n    # 8. Setup callbacks with enhanced monitoring\n    print(\"\\n5. Setting up enhanced callbacks\")\n    \n    # Base callbacks shared across training phases\n    base_callbacks = [\n        # Early stopping\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=8,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        # TensorBoard\n        tf.keras.callbacks.TensorBoard(\n            log_dir=LOG_DIR + '/ensemble',\n            histogram_freq=1,\n            update_freq='epoch'\n        )\n    ]\n    \n    # AffectNet-specific callbacks\n    affectnet_callbacks = base_callbacks + [\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'model_checkpoints/affectnet_ensemble_best.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        ),\n        # Enhanced confusion matrix monitoring\n        EnhancedConfusionMatrixCallback(\n            affectnet_val_ds, \n            classes, \n            log_dir=LOG_DIR + '/affectnet',\n            model_name=\"AffectNet Ensemble\",\n            freq=3\n        ),\n        # CSV Logger\n        tf.keras.callbacks.CSVLogger(\n            'affectnet_ensemble_training_log.csv', \n            append=True\n        )\n    ]\n    \n    # FER2013-specific callbacks\n    fer_callbacks = base_callbacks + [\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'model_checkpoints/fer2013_ensemble_best.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        ),\n        # Enhanced confusion matrix monitoring\n        EnhancedConfusionMatrixCallback(\n            fer_val_ds, \n            classes, \n            log_dir=LOG_DIR + '/fer2013',\n            model_name=\"FER2013 Ensemble\",\n            freq=3\n        ),\n        # CSV Logger\n        tf.keras.callbacks.CSVLogger(\n            'fer2013_ensemble_training_log.csv', \n            append=True\n        )\n    ]\n    \n    # 9. STAGE 1: Train ensemble on AffectNet using progressive strategy\n    print(\"\\n6. STAGE 1: Training ensemble on AffectNet with progressive strategy\")\n    \n    affectnet_histories = train_ensemble_with_progressive_strategy(\n        ensemble_model,\n        affectnet_train_ds, affectnet_val_ds,\n        affectnet_steps_per_epoch, affectnet_val_steps,\n        total_epochs=20,  # Adjust as needed\n        callbacks=affectnet_callbacks,\n        class_weights=affectnet_class_weights\n    )\n    \n    # Save AffectNet model\n    ensemble_model.save(\"affectnet_ensemble_model.keras\")\n    print(\"AffectNet ensemble model saved to 'affectnet_ensemble_model.keras'\")\n    \n    # 10. Evaluate on AffectNet test set\n    affectnet_metrics = evaluate_with_gc(\n        ensemble_model, \n        affectnet_test_ds, \n        affectnet_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"AffectNet\"\n    )\n    \n    # 11. STAGE 2: Fine-tune on FER2013 with progressive strategy\n    print(\"\\n7. STAGE 2: Fine-tuning ensemble on FER2013 with progressive strategy\")\n    \n    fer_histories = train_ensemble_with_progressive_strategy(\n        ensemble_model,\n        fer_train_ds, fer_val_ds,\n        fer_steps_per_epoch, fer_val_steps,\n        total_epochs=15,  # Adjust as needed\n        callbacks=fer_callbacks,\n        class_weights=fer_class_weights\n    )\n    \n    # 12. Evaluate on FER2013 test set\n    fer_metrics = evaluate_with_gc(\n        ensemble_model, \n        fer_test_ds, \n        fer_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"FER2013\"\n    )\n    \n    # 13. Evaluate on combined test set\n    combined_metrics = evaluate_with_gc(\n        ensemble_model, \n        combined_test_ds, \n        combined_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"Combined\"\n    )\n    \n    # 14. Save the final model\n    ensemble_model.save(\"final_emotion_ensemble.keras\")\n    print(\"Final ensemble model saved to 'final_emotion_ensemble.keras'\")\n    \n    # Return model and metrics\n    return ensemble_model, {\n        'affectnet': affectnet_metrics,\n        'fer2013': fer_metrics,\n        'combined': combined_metrics\n    }\n\n# =============================================================================\n# Main entry point\n# =============================================================================\nif __name__ == \"__main__\":\n    data_dir = \"/kaggle/input/custom-fer2013affectnet/Custom_ferAffect2013net\"\n    \n    # Add memory monitoring\n    print(\"Initial RAM usage:\", psutil.virtual_memory().percent)\n    model, metrics = train_emotion_ensemble(data_dir)\n    print(\"Final RAM usage:\", psutil.virtual_memory().percent)\n      \n    # Print final results\n    print(\"\\n=== FINAL RESULTS ===\")\n    print(f\"AffectNet Test Accuracy: {metrics['affectnet']['accuracy']:.4f}\")\n    print(f\"AffectNet F1 Score: {metrics['affectnet']['f1_score']:.4f}\")\n    print(f\"FER2013 Test Accuracy: {metrics['fer2013']['accuracy']:.4f}\")\n    print(f\"FER2013 F1 Score: {metrics['fer2013']['f1_score']:.4f}\")\n    print(f\"Combined Test Accuracy: {metrics['combined']['accuracy']:.4f}\")\n    print(f\"Combined F1 Score: {metrics['combined']['f1_score']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T22:11:23.563506Z","iopub.execute_input":"2025-03-21T22:11:23.563880Z","iopub.status.idle":"2025-03-21T22:11:29.719423Z","shell.execute_reply.started":"2025-03-21T22:11:23.563846Z","shell.execute_reply":"2025-03-21T22:11:29.718206Z"}},"outputs":[{"name":"stdout","text":"Found 1 GPUs: Memory growth enabled\nMixed precision enabled\n--2025-03-21 22:11:23--  https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\nResolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.207, 74.125.135.207, 142.250.99.207, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.207|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 9406464 (9.0M) [application/octet-stream]\nSaving to: ‘weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5.7’\n\nmobilenet_v2_weight 100%[===================>]   8.97M  --.-KB/s    in 0.04s   \n\n2025-03-21 22:11:24 (244 MB/s) - ‘weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5.7’ saved [9406464/9406464]\n\n--2025-03-21 22:11:24--  https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\nResolving storage.googleapis.com (storage.googleapis.com)... 172.253.117.207, 142.250.107.207, 74.125.135.207, ...\nConnecting to storage.googleapis.com (storage.googleapis.com)|172.253.117.207|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 83683744 (80M) [application/octet-stream]\nSaving to: ‘weights/xception_weights_tf_dim_ordering_tf_kernels_notop.h5.7’\n\nxception_weights_tf 100%[===================>]  79.81M   213MB/s    in 0.4s    \n\n2025-03-21 22:11:24 (213 MB/s) - ‘weights/xception_weights_tf_dim_ordering_tf_kernels_notop.h5.7’ saved [83683744/83683744]\n\n/kaggle/input/efficientnetb0-notop-h5/efficientnetb0_notop.h5: Scheme missing.\n-rw-r--r-- 1 root root 8.8K Mar 21 22:05 weights/efficientnetb0-notop-h5\n-rw-r--r-- 1 root root 9.0M Dec  5  2019 weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n-rw-r--r-- 1 root root 9.0M Dec  5  2019 weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5.1\n-rw-r--r-- 1 root root 9.0M Dec  5  2019 weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5.2\n-rw-r--r-- 1 root root 9.0M Dec  5  2019 weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5.3\n-rw-r--r-- 1 root root 9.0M Dec  5  2019 weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5.4\n-rw-r--r-- 1 root root 9.0M Dec  5  2019 weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5.5\n-rw-r--r-- 1 root root 9.0M Dec  5  2019 weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5.6\n-rw-r--r-- 1 root root 9.0M Dec  5  2019 weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5.7\n-rw-r--r-- 1 root root  80M Dec  5  2019 weights/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n-rw-r--r-- 1 root root  80M Dec  5  2019 weights/xception_weights_tf_dim_ordering_tf_kernels_notop.h5.1\n-rw-r--r-- 1 root root  80M Dec  5  2019 weights/xception_weights_tf_dim_ordering_tf_kernels_notop.h5.2\n-rw-r--r-- 1 root root  80M Dec  5  2019 weights/xception_weights_tf_dim_ordering_tf_kernels_notop.h5.3\n-rw-r--r-- 1 root root  80M Dec  5  2019 weights/xception_weights_tf_dim_ordering_tf_kernels_notop.h5.4\n-rw-r--r-- 1 root root  80M Dec  5  2019 weights/xception_weights_tf_dim_ordering_tf_kernels_notop.h5.5\n-rw-r--r-- 1 root root  80M Dec  5  2019 weights/xception_weights_tf_dim_ordering_tf_kernels_notop.h5.6\n-rw-r--r-- 1 root root  80M Dec  5  2019 weights/xception_weights_tf_dim_ordering_tf_kernels_notop.h5.7\nInitial RAM usage: 6.7\nStarting enhanced ensemble training for emotion recognition\n\n1. Loading datasets\nFound 8 emotion categories: ['surprise', 'fear', 'neutral', 'sad', 'disgust', 'contempt', 'happy', 'anger']\nFound 3161 images in surprise/fer2013\nFound 4039 images in surprise/affectnet\nFound 4092 images in fear/fer2013\nFound 3176 images in fear/affectnet\nFound 4951 images in neutral/fer2013\nFound 5126 images in neutral/affectnet\nFound 4823 images in sad/fer2013\nFound 3091 images in sad/affectnet\nFound 435 images in disgust/fer2013\nFound 2477 images in disgust/affectnet\nFound 54 images in contempt/fer2013\nFound 2871 images in contempt/affectnet\nFound 7199 images in happy/fer2013\nFound 5044 images in happy/affectnet\nFound 3987 images in anger/fer2013\nFound 3218 images in anger/affectnet\nTotal images: 57744\nFound 8 emotion categories: ['surprise', 'fear', 'neutral', 'sad', 'disgust', 'contempt', 'happy', 'anger']\nFound 831 images in surprise/fer2013\nFound 4039 images in surprise/affectnet\nFound 1024 images in fear/fer2013\nFound 3176 images in fear/affectnet\nFound 1233 images in neutral/fer2013\nFound 5126 images in neutral/affectnet\nFound 1247 images in sad/fer2013\nFound 3091 images in sad/affectnet\nFound 111 images in disgust/fer2013\nFound 2477 images in disgust/affectnet\nFound 54 images in contempt/fer2013\nFound 2871 images in contempt/affectnet\nFound 1774 images in happy/fer2013\nFound 5044 images in happy/affectnet\nFound 958 images in anger/fer2013\nFound 3218 images in anger/affectnet\nTotal images: 36274\n\nAffectNet training distribution:\nlabel\nneutral     5126\nhappy       5044\nsurprise    4039\nanger       3218\nfear        3176\nsad         3091\ncontempt    2871\ndisgust     2477\nName: count, dtype: int64\n\nFER2013 training distribution:\nlabel\nhappy       7199\nneutral     4951\nsad         4823\nfear        4092\nanger       3987\nsurprise    3161\ndisgust      435\ncontempt      54\nName: count, dtype: int64\n\nTest sets: AffectNet=29042, FER2013=7232\nClasses: ['anger', 'contempt', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\nAffectNet: 24685 train, 4357 validation\nFER2013: 24396 train, 4306 validation\n\n2. Creating enhanced data pipelines with caching\nCreated balanced dataset with 3800 samples (with emphasis on ['surprise', 'sad', 'disgust'])\nCreated balanced dataset with 3800 samples (with emphasis on ['surprise', 'sad', 'disgust'])\n\n3. Creating ensemble model architecture\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-9-cf2168fb5973>:440: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n  mobilenet_base = MobileNetV2(\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnet_base_notop.h5\nEfficientNetB0 imagenet weights failed to load: URL fetch failure on https://storage.googleapis.com/keras-applications/efficientnet_base_notop.h5: 403 -- Forbidden\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-cf2168fb5973>\u001b[0m in \u001b[0;36m<cell line: 1073>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1076\u001b[0m     \u001b[0;31m# Add memory monitoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initial RAM usage:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvirtual_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_emotion_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final RAM usage:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvirtual_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpercent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-cf2168fb5973>\u001b[0m in \u001b[0;36mtrain_emotion_ensemble\u001b[0;34m(data_dir)\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;31m# 6. Create ensemble model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n3. Creating ensemble model architecture\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m     \u001b[0mensemble_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ensemble_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze_base\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Ensemble model created with {ensemble_model.count_params():,} parameters\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-cf2168fb5973>\u001b[0m in \u001b[0;36mcreate_ensemble_model\u001b[0;34m(num_classes, freeze_base)\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'efficientnet_base'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         )\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mefficientnet_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights/efficientnetb0_notop.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfreeze_base\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    559\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 561\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'weights/efficientnetb0_notop.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"],"ename":"FileNotFoundError","evalue":"[Errno 2] Unable to synchronously open file (unable to open file: name = 'weights/efficientnetb0_notop.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"# customized 3.0 (cloudy) - CONSUME DISK SPACE .82\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom tensorflow.keras.applications import MobileNetV2, EfficientNetB0\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\nfrom tensorflow.keras.layers import Concatenate, Activation, Lambda, Input\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nimport gc\nimport psutil\n\n# =============================================================================\n# Memory-optimized configuration\n# =============================================================================\n# Configure GPU and enable memory growth\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(f\"Found {len(gpus)} GPUs: Memory growth enabled\")\n    except RuntimeError as e:\n        print(f\"GPU error: {e}\")\n\n# Enable mixed precision training (helps with memory)\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled\")\n\n# Adaptive batch size based on system memory\ntotal_ram_gb = psutil.virtual_memory().total / (1024**3)\nif total_ram_gb > 32:\n    BATCH_SIZE = 48  # High memory system\nelif total_ram_gb > 16:\n    BATCH_SIZE = 32  # Medium memory system\nelse:\n    BATCH_SIZE = 16  # Low memory system\nprint(f\"Adaptive batch size set to {BATCH_SIZE} based on {total_ram_gb:.1f}GB RAM\")\n\n# Limit TensorFlow's GPU memory usage\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            # Limit GPU memory (adjust percentage based on your system)\n            memory_limit = int(total_ram_gb * 0.7 * 1024)  # 70% of RAM in MB\n            tf.config.experimental.set_virtual_device_configuration(\n                gpu,\n                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memory_limit)]\n            )\n        print(f\"GPU memory limited to {memory_limit}MB\")\n    except RuntimeError as e:\n        print(f\"GPU memory limitation error: {e}\")\n\n# Other key parameters\nAUTOTUNE = tf.data.AUTOTUNE\nLOG_DIR = \"./emotion_logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nIMAGE_SIZE = 160  # Reduced from 224 to save memory\nPROBLEMATIC_CLASSES = ['surprise', 'sad', 'disgust']\n\n# Create required directories\ndef ensure_dir(directory):\n    \"\"\"Make sure a directory exists, creating it if necessary\"\"\"\n    if not os.path.exists(directory):\n        os.makedirs(directory, exist_ok=True)\n\n# Create main log and cache directories\nensure_dir(LOG_DIR)\nensure_dir(LOG_DIR + '/affectnet')\nensure_dir(LOG_DIR + '/fer2013')\nensure_dir(LOG_DIR + '/combined')\nensure_dir(\"./model_checkpoints\")\nensure_dir(\"./cache\")\nensure_dir(\"./cache/affectnet\")\nensure_dir(\"./cache/fer2013\")\nensure_dir(\"./cache/combined\")\n\n# =============================================================================\n# Memory monitoring\n# =============================================================================\ndef log_memory_usage(stage):\n    \"\"\"Log memory usage at various stages of training\"\"\"\n    process = psutil.Process()\n    memory_info = process.memory_info()\n    memory_gb = memory_info.rss / (1024 ** 3)\n    \n    # Log to console\n    print(f\"\\n[MEMORY] {stage}: {memory_gb:.2f} GB\")\n    \n    # Save to log file\n    with open(os.path.join(LOG_DIR, \"memory_usage.log\"), \"a\") as f:\n        f.write(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {stage}: {memory_gb:.2f} GB\\n\")\n    \n    # Get GPU memory if available\n    try:\n        gpu_info = tf.config.experimental.get_memory_info('GPU:0')\n        gpu_used_gb = gpu_info['current'] / (1024 ** 3)\n        gpu_total_gb = gpu_info['peak'] / (1024 ** 3)\n        print(f\"[GPU MEMORY] Used: {gpu_used_gb:.2f} GB, Peak: {gpu_total_gb:.2f} GB\")\n        \n        with open(os.path.join(LOG_DIR, \"memory_usage.log\"), \"a\") as f:\n            f.write(f\"GPU Memory - Used: {gpu_used_gb:.2f} GB, Peak: {gpu_total_gb:.2f} GB\\n\")\n    except:\n        pass  # Skip if GPU memory info not available\n\n# =============================================================================\n# Focal Loss - Memory efficient implementation\n# =============================================================================\ndef focal_loss(gamma=2.0, alpha=None):\n    \"\"\"\n    Memory-efficient focal loss implementation\n    \"\"\"\n    def loss_fn(y_true, y_pred):\n        # Clip values to avoid numerical instability\n        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0)\n        \n        # Basic cross entropy\n        cross_entropy = -y_true * tf.math.log(y_pred)\n        \n        # Apply focusing parameter more efficiently\n        focal_weight = tf.pow(1 - y_pred, gamma)\n        focal_loss = focal_weight * cross_entropy\n        \n        # Sum over classes\n        return tf.reduce_sum(focal_loss, axis=-1)\n    \n    return loss_fn\n\n# =============================================================================\n# Memory-optimized image preprocessing\n# =============================================================================\ndef preprocess_image(file_path, label, source, training=True):\n    \"\"\"\n    Memory-efficient preprocessing with smaller images\n    \"\"\"\n    # Read the file\n    img = tf.io.read_file(file_path)\n    \n    # Decode image with proper error handling\n    def decode_image():\n        try:\n            decoded = tf.image.decode_image(img, channels=3, expand_animations=False)\n            decoded = tf.ensure_shape(decoded, [None, None, 3])\n            return decoded\n        except:\n            # Return blank image if decoding fails\n            return tf.zeros([IMAGE_SIZE, IMAGE_SIZE, 3], dtype=tf.uint8)\n    \n    img = decode_image()\n    img = tf.cast(img, tf.float32)\n    \n    # Dataset-specific preprocessing for grayscale/RGB\n    if source == 'fer2013':\n        # Convert to grayscale then back to 3 channels for consistency\n        if tf.shape(img)[-1] == 3:\n            img = tf.image.rgb_to_grayscale(img)\n        img = tf.tile(img, [1, 1, 3])\n    \n    # Resize to smaller intermediate size\n    img = tf.image.resize(img, [IMAGE_SIZE, IMAGE_SIZE], method='bilinear')\n    \n    # Apply limited augmentation during training (fewer operations)\n    if training:\n        img = tf.image.random_flip_left_right(img)\n        # Only apply brightness OR contrast, not both (saves computation)\n        if tf.random.uniform(shape=[], maxval=1.0) > 0.5:\n            img = tf.image.random_brightness(img, 0.1)\n        else:\n            img = tf.image.random_contrast(img, 0.9, 1.1)\n    \n    # Basic normalization\n    img = img / 255.0\n    \n    # One-hot encode label\n    label = tf.one_hot(label, depth=8)\n    \n    return img, label\n\n# =============================================================================\n# Memory-efficient dataset creation\n# =============================================================================\ndef build_image_df(root_dir, subfolders=[\"fer2013\", \"affectnet\"], limit_samples=None):\n    \"\"\"\n    Scans the directory and returns a DataFrame with file paths and labels.\n    Adds option to limit samples per category for testing.\n    \"\"\"\n    data = []\n    emotions = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n    \n    print(f\"Found {len(emotions)} emotion categories: {emotions}\")\n    \n    for emotion in emotions:\n        emotion_path = os.path.join(root_dir, emotion)\n        for sub in subfolders:\n            sub_path = os.path.join(emotion_path, sub)\n            if os.path.exists(sub_path):\n                img_files = [f for f in os.listdir(sub_path) \n                            if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n                \n                # Limit samples if specified (for testing with less memory)\n                if limit_samples is not None:\n                    np.random.shuffle(img_files)\n                    img_files = img_files[:limit_samples]\n                \n                print(f\"Found {len(img_files)} images in {emotion}/{sub}\")\n                \n                for img_file in img_files:\n                    data.append({\n                        \"filepath\": os.path.join(sub_path, img_file),\n                        \"label\": emotion,\n                        \"source\": sub\n                    })\n    \n    df = pd.DataFrame(data)\n    print(f\"Total images: {len(df)}\")\n    return df\n\ndef create_dataset(dataframe, is_training=True, dataset_type=None, cache=True):\n    \"\"\"\n    Creates memory-efficient tf.data.Dataset with disk-based caching.\n    \"\"\"\n    # Optionally filter to specific dataset\n    if dataset_type is not None:\n        dataframe = dataframe[dataframe['source'] == dataset_type].reset_index(drop=True)\n        print(f\"Filtered to {len(dataframe)} {dataset_type} images\")\n    \n    # Create class indices\n    class_indices = {cls: i for i, cls in enumerate(sorted(dataframe[\"label\"].unique()))}\n    \n    # Create a generator function to avoid storing all labels in memory\n    def generate_samples():\n        for i in range(len(dataframe)):\n            yield (\n                dataframe[\"filepath\"].iloc[i],\n                class_indices[dataframe[\"label\"].iloc[i]],\n                dataframe[\"source\"].iloc[i]\n            )\n    \n    # Create dataset from generator\n    ds = tf.data.Dataset.from_generator(\n        generate_samples,\n        output_signature=(\n            tf.TensorSpec(shape=(), dtype=tf.string),\n            tf.TensorSpec(shape=(), dtype=tf.int32),\n            tf.TensorSpec(shape=(), dtype=tf.string)\n        )\n    )\n    \n    # Apply preprocessing with training flag\n    training_value = tf.constant(is_training)\n    ds = ds.map(\n        lambda path, label, source: preprocess_image(path, label, source, training=training_value),\n        num_parallel_calls=AUTOTUNE\n    )\n    \n    if is_training:\n        # Use smaller buffer size to limit memory usage\n        buffer_size = min(1000, len(dataframe))\n        ds = ds.shuffle(buffer_size=buffer_size)\n        ds = ds.repeat()\n    \n    # Use disk-based caching instead of RAM\n    if cache:\n        cache_file = f\"./cache/{dataset_type or 'combined'}/dataset_cache\"\n        ds = ds.cache(filename=cache_file)\n    \n    # Batch and limit prefetch to save memory\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(2)  # Reduced from AUTOTUNE to limit memory\n    \n    return ds, class_indices\n\ndef create_emphasis_dataset(dataframe, is_training=True, emphasis_classes=PROBLEMATIC_CLASSES, cache=True):\n    \"\"\"\n    Creates a balanced dataset with emphasis on problematic classes.\n    Memory-optimized version.\n    \"\"\"\n    balanced_data = []\n    \n    # Use smaller base samples per class to save memory\n    base_samples = 300  # Reduced from 400\n    emphasis_samples = 400  # Reduced from 600\n    \n    # Sample from each class with emphasis on problematic ones\n    for class_name in sorted(dataframe[\"label\"].unique()):\n        class_df = dataframe[dataframe[\"label\"] == class_name]\n        samples_per_class = base_samples\n        \n        # Increase samples for emphasis classes\n        if class_name in emphasis_classes:\n            samples_per_class = emphasis_samples\n            \n        # Sample with replacement if needed\n        if len(class_df) <= samples_per_class:\n            sampled = class_df.sample(n=samples_per_class, replace=True)\n        else:\n            sampled = class_df.sample(n=samples_per_class, replace=False)\n            \n        balanced_data.append(sampled)\n    \n    # Combine all balanced samples\n    balanced_df = pd.concat(balanced_data, ignore_index=True)\n    print(f\"Created balanced dataset with {len(balanced_df)} samples (with emphasis on {emphasis_classes})\")\n    \n    # Create dataset with disk-based caching\n    return create_dataset(balanced_df, is_training=is_training, cache=cache)\n\n# =============================================================================\n# Memory-efficient Confusion Matrix Callback\n# =============================================================================\nclass MemoryEfficientConfusionMatrixCallback(tf.keras.callbacks.Callback):\n    \"\"\"\n    Memory-efficient callback to monitor metrics during training.\n    \"\"\"\n    def __init__(self, validation_data, class_names, log_dir, model_name=\"model\", freq=5):\n        super(MemoryEfficientConfusionMatrixCallback, self).__init__()\n        self.validation_data = validation_data\n        self.class_names = class_names\n        self.freq = freq\n        self.log_dir = log_dir\n        self.model_name = model_name\n        self.zero_prediction_classes = set()\n        self.class_metrics_history = {cls: [] for cls in class_names}\n        \n        # Ensure log directory exists\n        ensure_dir(self.log_dir)\n        \n    def on_epoch_end(self, epoch, logs=None):\n        # Only calculate metrics at the specified frequency to save computation\n        if (epoch + 1) % self.freq != 0:\n            return\n            \n        # Limit validation steps to save memory\n        val_steps = min(20, sum(1 for _ in self.validation_data))\n        y_true = []\n        y_pred = []\n        \n        # Get predictions in smaller batches\n        for i, (images, labels) in enumerate(self.validation_data):\n            if i >= val_steps:\n                break\n            # Use smaller batches for prediction to save memory\n            batch_preds = self.model.predict(images, verbose=0)\n            y_pred.append(np.argmax(batch_preds, axis=1))\n            y_true.append(np.argmax(labels.numpy(), axis=1))\n            \n            # Force garbage collection after each batch\n            gc.collect()\n        \n        # Flatten the lists\n        y_true = np.concatenate(y_true)\n        y_pred = np.concatenate(y_pred)\n        \n        # Calculate confusion matrix\n        cm = confusion_matrix(y_true, y_pred)\n        \n        # Calculate per-class metrics\n        class_accuracies = np.zeros(len(self.class_names))\n        for i in range(len(self.class_names)):\n            if np.sum(y_true == i) > 0:\n                class_accuracies[i] = cm[i, i] / np.sum(y_true == i)\n                \n            # Track metrics history (keep only last 5 epochs to save memory)\n            history = self.class_metrics_history[self.class_names[i]]\n            history.append(class_accuracies[i])\n            if len(history) > 5:\n                history.pop(0)\n        \n        # Check for classes with zero predictions\n        zero_pred_classes = []\n        for i, class_name in enumerate(self.class_names):\n            if np.sum(cm[:, i]) == 0:\n                zero_pred_classes.append(class_name)\n                self.zero_prediction_classes.add(class_name)\n        \n        # Log warnings for zero prediction classes\n        if zero_pred_classes:\n            warning_msg = f\"\\n⚠️ WARNING: Zero predictions for classes: {', '.join(zero_pred_classes)}\"\n            print(warning_msg)\n            \n            # Save warning to log file\n            with open(f\"{self.log_dir}/warnings.txt\", \"a\") as f:\n                f.write(f\"Epoch {epoch+1}: {warning_msg}\\n\")\n        \n        # Print confusion matrix\n        print(\"\\nConfusion Matrix:\")\n        print(cm)\n        \n        # Print per-class accuracy\n        for i, (name, acc) in enumerate(zip(self.class_names, class_accuracies)):\n            print(f\"{name}: {acc:.4f}\", end=\"  \")\n            if (i + 1) % 4 == 0:\n                print()\n        print(\"\\n\")\n        \n        # Save confusion matrix visualization with reduced figure size\n        plt.figure(figsize=(8, 6))  # Smaller figure size\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                   xticklabels=self.class_names,\n                   yticklabels=self.class_names)\n        plt.xlabel('Predicted')\n        plt.ylabel('True')\n        plt.title(f'Confusion Matrix - {self.model_name} - Epoch {epoch+1}')\n        plt.tight_layout()\n        \n        try:\n            plt.savefig(f'{self.log_dir}/confusion_matrix_epoch_{epoch+1}.png', dpi=100)  # Lower DPI\n        except Exception as e:\n            print(f\"Warning: Could not save confusion matrix plot: {e}\")\n        \n        plt.close()\n        \n        # Force garbage collection\n        gc.collect()\n\n# =============================================================================\n# Memory-efficient Ensemble Model\n# =============================================================================\ndef create_lightweight_ensemble_model(num_classes=8, freeze_base=True):\n    \"\"\"\n    Create a memory-efficient version of the ensemble\n    \"\"\"\n    # Create inputs with smaller size\n    inputs = keras.layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3), name='image_input')\n    \n    # === MobileNetV2 Branch with reduced alpha ===\n    mobilenet_preprocess = Lambda(\n        lambda x: tf.image.resize(x*255.0, [96, 96]) / 127.5 - 1,\n        name='mobilenet_preprocess'\n    )(inputs)\n    \n    mobilenet_base = MobileNetV2(\n        include_top=False, \n        weights='imagenet',\n        input_tensor=mobilenet_preprocess,\n        alpha=0.75  # Reduced from 1.0 to save memory\n    )\n    \n    if freeze_base:\n        for layer in mobilenet_base.layers:\n            layer.trainable = False\n            \n    mobilenet_features = GlobalAveragePooling2D(name='mobilenet_gap')(mobilenet_base.output)\n    mobilenet_features = Dense(96, name='mobilenet_projection')(mobilenet_features)  # Reduced from 128\n    mobilenet_features = BatchNormalization()(mobilenet_features)\n    mobilenet_features = Activation('relu')(mobilenet_features)\n    \n    # === EfficientNetB0 Branch ===\n    efficientnet_preprocess = Lambda(\n        lambda x: tf.keras.applications.efficientnet.preprocess_input(x*255.0),\n        name='efficientnet_preprocess'\n    )(inputs)\n    \n    efficientnet_base = EfficientNetB0(\n        include_top=False,\n        weights='imagenet',\n        input_tensor=efficientnet_preprocess\n    )\n    \n    if freeze_base:\n        for layer in efficientnet_base.layers:\n            layer.trainable = False\n            \n    efficientnet_features = GlobalAveragePooling2D(name='efficientnet_gap')(efficientnet_base.output)\n    efficientnet_features = Dense(96, name='efficientnet_projection')(efficientnet_features)  # Reduced from 128\n    efficientnet_features = BatchNormalization()(efficientnet_features)\n    efficientnet_features = Activation('relu')(efficientnet_features)\n    \n    # === Feature Fusion ===\n    merged_features = Concatenate(name='feature_fusion')([mobilenet_features, efficientnet_features])\n    \n    # Simplified classification head\n    x = Dense(128, name='fusion_dense1')(merged_features)  # Reduced from 256\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.5)(x)\n    \n    # Output layer\n    outputs = Dense(num_classes, activation='softmax', dtype='float32', name='emotion_output')(x)\n    \n    # Create model\n    model = keras.Model(inputs=inputs, outputs=outputs, name='emotion_ensemble_lite')\n    \n    # Compile with focal loss\n    optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n    optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n    \n    model.compile(\n        optimizer=optimizer,\n        loss=focal_loss(gamma=2.0),\n        metrics=['accuracy']\n    )\n    \n    return model\n\n# =============================================================================\n# Memory-efficient Training Strategy\n# =============================================================================\ndef train_ensemble_with_memory_efficient_strategy(model, train_ds, val_ds, \n                                                steps_per_epoch, val_steps,\n                                                total_epochs=30,\n                                                callbacks=None,\n                                                class_weights=None):\n    \"\"\"\n    Memory-efficient training approach with staged unfreezing\n    \"\"\"\n    histories = []\n    \n    # Stage 1: Train only fusion layers (keep all base models frozen)\n    stage1_epochs = max(3, int(total_epochs * 0.2))\n    print(f\"\\nStage 1: Training only fusion layers ({stage1_epochs} epochs)\")\n    log_memory_usage(\"Before Stage 1 Training\")\n    \n    # Ensure base models are frozen\n    for layer in model.layers:\n        if any(base_name in layer.name for base_name in ['mobilenet_base', 'efficientnet_base']):\n            for base_layer in layer.layers:\n                base_layer.trainable = False\n    \n    # Train fusion layers\n    history1 = model.fit(\n        train_ds,\n        epochs=stage1_epochs,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=val_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    histories.append(history1)\n    \n    # Memory cleanup\n    log_memory_usage(\"After Stage 1 Training\")\n    tf.keras.backend.clear_session()\n    gc.collect()\n    \n    # Stage 2: Unfreeze and train only the last 15 layers of each base model\n    stage2_epochs = total_epochs - stage1_epochs\n    print(f\"\\nStage 2: Fine-tuning with reduced layers ({stage2_epochs} epochs)\")\n    log_memory_usage(\"Before Stage 2 Training\")\n    \n    # Unfreeze only the last 15 layers (instead of 30-50)\n    for layer in model.layers:\n        if any(base_name in layer.name for base_name in ['mobilenet_base', 'efficientnet_base']):\n            for base_layer in layer.layers[:-15]:\n                base_layer.trainable = False\n            for base_layer in layer.layers[-15:]:\n                base_layer.trainable = True\n    \n    # Recompile with lower learning rate\n    optimizer = keras.optimizers.Adam(5e-5)\n    optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n    \n    model.compile(\n        optimizer=optimizer,\n        loss=focal_loss(gamma=2.0),\n        metrics=['accuracy']\n    )\n    \n    # Train with partial unfreezing\n    history2 = model.fit(\n        train_ds,\n        epochs=stage2_epochs,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=val_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    histories.append(history2)\n    \n    log_memory_usage(\"After Stage 2 Training\")\n    return histories\n\n# =============================================================================\n# Memory-efficient Evaluation\n# =============================================================================\ndef evaluate_model(model, test_ds, steps, class_names, log_dir, dataset_name=\"\"):\n    \"\"\"\n    Memory-efficient model evaluation\n    \"\"\"\n    print(f\"\\nEvaluating model on {dataset_name} test set\")\n    log_memory_usage(f\"Before {dataset_name} Evaluation\")\n    \n    # Get predictions in smaller batches\n    y_true = []\n    y_pred = []\n    \n    # Use limited steps for evaluation\n    actual_steps = min(steps, 30)\n    \n    # Loop through test batches\n    for i, (images, labels) in enumerate(test_ds):\n        if i >= actual_steps:\n            break\n        # Use smaller batches if needed\n        batch_preds = model.predict(images, verbose=0)\n        y_pred.append(np.argmax(batch_preds, axis=1))\n        y_true.append(np.argmax(labels.numpy(), axis=1))\n        \n        # Cleanup after each batch\n        if i % 5 == 0:\n            gc.collect()\n    \n    # Concatenate\n    y_true = np.concatenate(y_true)\n    y_pred = np.concatenate(y_pred)\n    \n    # Calculate metrics\n    test_accuracy = np.mean(y_pred == y_true)\n    f1 = f1_score(y_true, y_pred, average='weighted')\n    \n    print(f\"{dataset_name} Test Accuracy: {test_accuracy:.4f}\")\n    print(f\"{dataset_name} Weighted F1-Score: {f1:.4f}\")\n    \n    # Calculate confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Save smaller confusion matrix visualization\n    plt.figure(figsize=(8, 6))  # Smaller figure\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n               xticklabels=class_names,\n               yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title(f'Confusion Matrix - {dataset_name} Test Set')\n    plt.tight_layout()\n    \n    try:\n        plt.savefig(f'{log_dir}/confusion_matrix_{dataset_name}_test.png', dpi=100)  # Lower DPI\n    except Exception as e:\n        print(f\"Warning: Could not save confusion matrix plot: {e}\")\n        \n    plt.close()\n    \n    # Print classification report\n    print(f\"\\n{dataset_name} Classification Report:\")\n    report = classification_report(\n        y_true, \n        y_pred, \n        target_names=class_names,\n        zero_division=0\n    )\n    print(report)\n    \n    # Save report to file\n    with open(f'{log_dir}/classification_report_{dataset_name}.txt', 'w') as f:\n        f.write(report)\n    \n    log_memory_usage(f\"After {dataset_name} Evaluation\")\n    \n    # Memory cleanup\n    gc.collect()\n    \n    return {\n        'accuracy': test_accuracy,\n        'f1_score': f1,\n        'confusion_matrix': cm\n    }\n\n# =============================================================================\n# Main training pipeline with memory monitoring\n# =============================================================================\ndef train_emotion_ensemble(data_dir, limit_samples=None):\n    \"\"\"\n    Memory-efficient training pipeline for emotion recognition\n    \n    Args:\n        data_dir: Path to dataset directory\n        limit_samples: Optional limit on samples per class (for testing)\n        \n    Returns:\n        Trained model and evaluation metrics\n    \"\"\"\n    print(\"Starting memory-optimized ensemble training for emotion recognition\")\n    \n    # 1. Load and prepare data with optional sample limiting\n    print(\"\\n1. Loading datasets\")\n    log_memory_usage(\"Initial\")\n    \n    train_dir = os.path.join(data_dir, \"Train\")\n    test_dir = os.path.join(data_dir, \"Test\")\n    \n    train_df_full = build_image_df(train_dir, limit_samples=limit_samples)\n    test_df = build_image_df(test_dir, limit_samples=limit_samples)\n    \n    # Show dataset distributions\n    print(\"\\nAffectNet training distribution:\")\n    print(train_df_full[train_df_full['source'] == 'affectnet']['label'].value_counts())\n    \n    print(\"\\nFER2013 training distribution:\")\n    print(train_df_full[train_df_full['source'] == 'fer2013']['label'].value_counts())\n    \n    log_memory_usage(\"After dataframe creation\")\n    \n    # 2. Split test set by dataset source\n    test_affectnet_df = test_df[test_df['source'] == 'affectnet'].copy()  # Use copy to avoid view\n    test_fer_df = test_df[test_df['source'] == 'fer2013'].copy()  # Use copy to avoid view\n    \n    print(f\"\\nTest sets: AffectNet={len(test_affectnet_df)}, FER2013={len(test_fer_df)}\")\n    \n    # Get classes for later use\n    classes = sorted(train_df_full[\"label\"].unique())\n    num_classes = len(classes)\n    print(f\"Classes: {classes}\")\n    \n    # 3. Create validation splits with separate DataFrames\n    print(\"\\n2. Creating train/validation splits\")\n    \n    # For AffectNet\n    affectnet_train_df = train_df_full[train_df_full['source'] == 'affectnet'].copy()\n    affectnet_train_idx, affectnet_val_idx = train_test_split(\n        np.arange(len(affectnet_train_df)), \n        test_size=0.15, \n        stratify=affectnet_train_df[\"label\"], \n        random_state=42\n    )\n    affectnet_val_df = affectnet_train_df.iloc[affectnet_val_idx].copy()\n    affectnet_train_df = affectnet_train_df.iloc[affectnet_train_idx].copy()\n    \n    # For FER2013\n    fer_train_df = train_df_full[train_df_full['source'] == 'fer2013'].copy()\n    fer_train_idx, fer_val_idx = train_test_split(\n        np.arange(len(fer_train_df)), \n        test_size=0.15, \n        stratify=fer_train_df[\"label\"], \n        random_state=42\n    )\n    fer_val_df = fer_train_df.iloc[fer_val_idx].copy()\n    fer_train_df = fer_train_df.iloc[fer_train_idx].copy()\n    \n    print(f\"AffectNet: {len(affectnet_train_df)} train, {len(affectnet_val_df)} validation\")\n    print(f\"FER2013: {len(fer_train_df)} train, {len(fer_val_df)} validation\")\n    \n    # Clear the full dataframe to save memory\n    del train_df_full\n    gc.collect()\n    log_memory_usage(\"After train/val split\")\n    \n    # 4. Create datasets with disk-based caching\n    print(\"\\n3. Creating memory-efficient data pipelines with disk caching\")\n    \n    # AffectNet datasets - Create only what's needed for current training stage\n    print(\"Creating AffectNet datasets...\")\n    affectnet_train_ds, class_indices = create_emphasis_dataset(\n        affectnet_train_df, is_training=True, cache=True)\n    \n    affectnet_val_ds, _ = create_dataset(\n        affectnet_val_df, is_training=False, \n        dataset_type='affectnet', cache=True)\n    \n    log_memory_usage(\"After AffectNet dataset creation\")\n    \n    # Calculate steps with increased batch size\n    affectnet_steps_per_epoch = max(1, len(affectnet_train_df) // BATCH_SIZE // 2)  # Reduce steps to save time\n    affectnet_val_steps = max(1, len(affectnet_val_df) // BATCH_SIZE)\n    \n    # 5. Create lightweight ensemble model\n    print(\"\\n4. Creating lightweight ensemble model\")\n    ensemble_model = create_lightweight_ensemble_model(num_classes=num_classes, freeze_base=True)\n    print(f\"Ensemble model created with {ensemble_model.count_params():,} parameters\")\n    \n    log_memory_usage(\"After model creation\")\n    \n    # 6. Compute class weights for AffectNet\n    print(\"\\n5. Computing class weights for AffectNet\")\n    \n    # AffectNet class weights\n    affectnet_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(affectnet_train_df[\"label\"].values),\n        y=affectnet_train_df[\"label\"].values\n    )\n    affectnet_class_weights = {class_indices[label]: weight for label, weight in \n                     zip(np.unique(affectnet_train_df[\"label\"].values), affectnet_weights)}\n    \n    # Increase weights for problematic classes\n    for problem_class in PROBLEMATIC_CLASSES:\n        if problem_class in class_indices:\n            class_idx = class_indices[problem_class]\n            # Increase the weight by 20%\n            if class_idx in affectnet_class_weights:\n                affectnet_class_weights[class_idx] *= 1.2\n    \n    print(\"Enhanced AffectNet class weights:\", affectnet_class_weights)\n    \n    # 7. Setup AffectNet callbacks\n    print(\"\\n6. Setting up AffectNet callbacks\")\n    \n    # Memory-efficient callbacks\n    affectnet_callbacks = [\n        # Early stopping\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=5,  # Reduced from 8\n            restore_best_weights=True,\n            verbose=1\n        ),\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'model_checkpoints/affectnet_ensemble_best.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,  # Save only weights to reduce file size\n            verbose=1\n        ),\n        # Memory-efficient confusion matrix monitoring (reduced frequency)\n        MemoryEfficientConfusionMatrixCallback(\n            affectnet_val_ds, \n            classes, \n            log_dir=LOG_DIR + '/affectnet',\n            model_name=\"AffectNet Ensemble\",\n            freq=5  # Increased from 3 to check less frequently\n        ),\n        # CSV Logger\n        tf.keras.callbacks.CSVLogger(\n            'affectnet_ensemble_training_log.csv', \n            append=True\n        )\n    ]\n    \n    # 8. Train ensemble on AffectNet using memory-efficient strategy\n    print(\"\\n7. STAGE 1: Training ensemble on AffectNet with memory-efficient strategy\")\n    \n    affectnet_histories = train_ensemble_with_memory_efficient_strategy(\n        ensemble_model,\n        affectnet_train_ds, affectnet_val_ds,\n        affectnet_steps_per_epoch, affectnet_val_steps,\n        total_epochs=15,  # Reduced from 20\n        callbacks=affectnet_callbacks,\n        class_weights=affectnet_class_weights\n    )\n    \n    # Save AffectNet model (weights only to save space)\n    ensemble_model.save_weights(\"affectnet_ensemble_weights.h5\")\n    print(\"AffectNet ensemble model weights saved\")\n    \n    log_memory_usage(\"After AffectNet training\")\n    \n    # 9. Clean up AffectNet resources\n    del affectnet_train_ds, affectnet_val_ds, affectnet_train_df, affectnet_val_df\n    gc.collect()\n    \n    # 10. Create AffectNet test dataset for evaluation\n    print(\"\\n8. Evaluating on AffectNet test set\")\n    affectnet_test_ds, _ = create_dataset(\n        test_affectnet_df, is_training=False, \n        dataset_type='affectnet', cache=True)\n    \n    # Calculate test steps\n    affectnet_test_steps = max(1, len(test_affectnet_df) // BATCH_SIZE)\n    \n    # 11. Evaluate on AffectNet test set\n    affectnet_metrics = evaluate_model(\n        ensemble_model, \n        affectnet_test_ds, \n        affectnet_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"AffectNet\"\n    )\n    \n    # 12. Clean up AffectNet test resources\n    del affectnet_test_ds, test_affectnet_df\n    gc.collect()\n    \n    # 13. Create FER2013 datasets\n    print(\"\\n9. Creating FER2013 datasets...\")\n    fer_train_ds, _ = create_emphasis_dataset(\n        fer_train_df, is_training=True, cache=True)\n    \n    fer_val_ds, _ = create_dataset(\n        fer_val_df, is_training=False, \n        dataset_type='fer2013', cache=True)\n    \n    log_memory_usage(\"After FER2013 dataset creation\")\n    \n    # Calculate steps\n    fer_steps_per_epoch = max(1, len(fer_train_df) // BATCH_SIZE // 2)  # Reduce steps\n    fer_val_steps = max(1, len(fer_val_df) // BATCH_SIZE)\n    \n    # 14. Compute class weights for FER2013\n    print(\"\\n10. Computing class weights for FER2013\")\n    \n    # FER2013 class weights\n    fer_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(fer_train_df[\"label\"].values),\n        y=fer_train_df[\"label\"].values\n    )\n    fer_class_weights = {class_indices[label]: weight for label, weight in \n                zip(np.unique(fer_train_df[\"label\"].values), fer_weights)}\n    \n    # Increase weights for problematic classes\n    for problem_class in PROBLEMATIC_CLASSES:\n        if problem_class in class_indices:\n            class_idx = class_indices[problem_class]\n            if class_idx in fer_class_weights:\n                fer_class_weights[class_idx] *= 1.2\n    \n    print(\"Enhanced FER2013 class weights:\", fer_class_weights)\n    \n    # 15. Setup FER2013 callbacks\n    print(\"\\n11. Setting up FER2013 callbacks\")\n    \n    # Memory-efficient callbacks\n    fer_callbacks = [\n        # Early stopping\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=5,  # Reduced from 8\n            restore_best_weights=True,\n            verbose=1\n        ),\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'model_checkpoints/fer2013_ensemble_best.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        ),\n        # Memory-efficient confusion matrix monitoring\n        MemoryEfficientConfusionMatrixCallback(\n            fer_val_ds, \n            classes, \n            log_dir=LOG_DIR + '/fer2013',\n            model_name=\"FER2013 Ensemble\",\n            freq=5  # Increased from 3\n        ),\n        # CSV Logger\n        tf.keras.callbacks.CSVLogger(\n            'fer2013_ensemble_training_log.csv', \n            append=True\n        )\n    ]\n    \n    # 16. STAGE 2: Fine-tune on FER2013 with memory-efficient strategy\n    print(\"\\n12. STAGE 2: Fine-tuning ensemble on FER2013 with memory-efficient strategy\")\n    \n    fer_histories = train_ensemble_with_memory_efficient_strategy(\n        ensemble_model,\n        fer_train_ds, fer_val_ds,\n        fer_steps_per_epoch, fer_val_steps,\n        total_epochs=10,  # Reduced from 15\n        callbacks=fer_callbacks,\n        class_weights=fer_class_weights\n    )\n    \n    log_memory_usage(\"After FER2013 training\")\n    \n    # 17. Create FER2013 test dataset\n    print(\"\\n13. Evaluating on FER2013 test set\")\n    fer_test_ds, _ = create_dataset(\n        test_fer_df, is_training=False, \n        dataset_type='fer2013', cache=True)\n    \n    # Calculate test steps\n    fer_test_steps = max(1, len(test_fer_df) // BATCH_SIZE)\n    \n    # 18. Evaluate on FER2013 test set\n    fer_metrics = evaluate_model(\n        ensemble_model, \n        fer_test_ds, \n        fer_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"FER2013\"\n    )\n    \n    # 19. Save the final model (weights only)\n    ensemble_model.save_weights(\"final_emotion_ensemble_weights.h5\")\n    print(\"Final ensemble model weights saved\")\n    \n    # 20. Print final results\n    print(\"\\n=== FINAL RESULTS ===\")\n    print(f\"AffectNet Test Accuracy: {affectnet_metrics['accuracy']:.4f}\")\n    print(f\"AffectNet F1 Score: {affectnet_metrics['f1_score']:.4f}\")\n    print(f\"FER2013 Test Accuracy: {fer_metrics['accuracy']:.4f}\")\n    print(f\"FER2013 F1 Score: {fer_metrics['f1_score']:.4f}\")\n    \n    log_memory_usage(\"Final\")\n    \n    # Return model and metrics\n    return ensemble_model, {\n        'affectnet': affectnet_metrics,\n        'fer2013': fer_metrics\n    }\n\n# =============================================================================\n# Main entry point with memory limits\n# =============================================================================\nif __name__ == \"__main__\":\n    # Set data directory path\n    data_dir = \"/kaggle/input/custom-fer2013affectnet/Custom_ferAffect2013net\"\n    \n    # Optional: Limit samples for testing (uncomment to use)\n    # Set to None for full dataset, or a number to limit samples per class\n    limit_samples = None  # e.g., 100 for quick testing\n    \n    try:\n        # Train with memory monitoring\n        #model, metrics = train_emotion_ensemble(data_dir, limit_samples=100)\n        model, metrics = train_emotion_ensemble(data_dir, limit_samples=None)\n        print(\"Training completed successfully!\")\n    except Exception as e:\n        print(f\"Error during training: {e}\")\n        # Log the error\n        with open(os.path.join(LOG_DIR, \"error_log.txt\"), \"a\") as f:\n            f.write(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - ERROR: {str(e)}\\n\")\n        raise","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Customized 2.0 (RAM MOSNTER)\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom tensorflow.keras.applications import MobileNetV2, Xception, EfficientNetB0\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\nfrom tensorflow.keras.layers import Concatenate, Activation, Lambda, Input\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\n\n# =============================================================================\n# Configure GPU and enable mixed precision\n# =============================================================================\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(f\"Found {len(gpus)} GPUs: Memory growth enabled\")\n    except RuntimeError as e:\n        print(f\"GPU error: {e}\")\n\n# Enable mixed precision training\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled\")\n\n# =============================================================================\n# Key parameters\n# =============================================================================\nBATCH_SIZE = 64  # Increased from 32 to 64 for better GPU utilization\nAUTOTUNE = tf.data.AUTOTUNE\nLOG_DIR = \"./emotion_logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\n# Create all required directories\ndef ensure_dir(directory):\n    \"\"\"Make sure a directory exists, creating it if necessary\"\"\"\n    if not os.path.exists(directory):\n        os.makedirs(directory, exist_ok=True)\n\n# Create main log directories\nensure_dir(LOG_DIR)\nensure_dir(LOG_DIR + '/affectnet')\nensure_dir(LOG_DIR + '/fer2013')\nensure_dir(LOG_DIR + '/combined')\nensure_dir(LOG_DIR + '/ensemble')\nensure_dir(\"./model_checkpoints\")\n\n# Define problematic classes for targeted augmentation\nPROBLEMATIC_CLASSES = ['surprise', 'sad', 'disgust']\n\n# =============================================================================\n# Focal Loss for better handling of class imbalance\n# =============================================================================\ndef focal_loss(gamma=2.0, alpha=None):\n    \"\"\"\n    Focal loss implementation for better handling of class imbalance.\n    Focuses training on hard examples by down-weighting easy examples.\n    \n    Args:\n        gamma: Focusing parameter (higher = more focus on hard examples)\n        alpha: Optional class weight factors\n        \n    Returns:\n        Loss function\n    \"\"\"\n    def loss_fn(y_true, y_pred):\n        # Add small epsilon to avoid log(0)\n        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0)\n        \n        # Basic cross entropy\n        cross_entropy = -y_true * tf.math.log(y_pred)\n        \n        # Apply class weighting if provided\n        if alpha is not None:\n            # Convert alpha to proper shape if it's a dict\n            if isinstance(alpha, dict):\n                # Create a tensor of appropriate shape filled with ones\n                alpha_tensor = tf.ones_like(y_true)\n                \n                # For each class index in the alpha dict, update the corresponding\n                # position in alpha_tensor with the weight value\n                for class_idx, weight in alpha.items():\n                    # Create a mask for the current class\n                    class_mask = tf.cast(tf.equal(tf.argmax(y_true, axis=-1), class_idx), tf.float32)\n                    \n                    # Reshape to broadcast properly\n                    class_mask = tf.expand_dims(class_mask, axis=-1)\n                    \n                    # Update weights for this class\n                    alpha_tensor = alpha_tensor * (1 - class_mask) + weight * class_mask\n                \n                cross_entropy = alpha_tensor * cross_entropy\n            else:\n                cross_entropy = alpha * cross_entropy\n        \n        # Apply focusing parameter\n        focal_weight = tf.pow(1 - y_pred, gamma)\n        focal_loss = focal_weight * cross_entropy\n        \n        # Sum over classes\n        return tf.reduce_sum(focal_loss, axis=-1)\n    \n    return loss_fn\n\n# =============================================================================\n# FIXED: Enhanced Image Preprocessing with Consistent Size\n# =============================================================================\ndef preprocess_image(file_path, label, source, training=True):\n    \"\"\"\n    Enhanced preprocessing with consistent output size for all images.\n    \n    Args:\n        file_path: Path to the image file\n        label: Emotion label (as index)\n        source: Dataset source ('fer2013' or 'affectnet')\n        training: Whether to apply augmentation\n        \n    Returns:\n        Preprocessed image (consistent size) and one-hot encoded label\n    \"\"\"\n    # Read the file\n    img = tf.io.read_file(file_path)\n    \n    # Decode image with proper error handling\n    def decode_image():\n        try:\n            decoded = tf.image.decode_image(img, channels=3, expand_animations=False)\n            decoded = tf.ensure_shape(decoded, [None, None, 3])\n            return decoded\n        except:\n            # Return blank image if decoding fails\n            return tf.zeros([224, 224, 3], dtype=tf.uint8)\n    \n    img = decode_image()\n    img = tf.cast(img, tf.float32)\n    \n    # Dataset-specific preprocessing for grayscale/RGB\n    if source == 'fer2013':\n        # Properly handle grayscale images\n        if tf.shape(img)[-1] == 1:\n            img = tf.tile(img, [1, 1, 3])  # Expand to 3 channels\n        else:\n            # Convert to grayscale then back to 3 channels for consistency\n            img = tf.image.rgb_to_grayscale(img)\n            img = tf.tile(img, [1, 1, 3])\n    \n    # CRITICAL: Resize ALL images to a standard intermediate size\n    # 224x224 is chosen as it's compatible with EfficientNetB0\n    img = tf.image.resize(img, [224, 224], method='bilinear')\n    \n    # Apply basic augmentation during training\n    if training:\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_brightness(img, 0.2)\n        img = tf.image.random_contrast(img, 0.8, 1.2)\n        noise = tf.random.normal(shape=tf.shape(img), mean=0.0, stddev=0.01)\n        img = img + noise\n        img = tf.clip_by_value(img, 0.0, 255.0)  # Ensure valid range\n    \n    # Basic normalization to [0,1] range for consistency\n    # Note: Model-specific normalization will happen in the model\n    img = img / 255.0\n    \n    # One-hot encode label\n    label = tf.one_hot(label, depth=8)  # 8 emotion classes\n    \n    return img, label\n\n# =============================================================================\n# Build DataFrame from dataset directory structure\n# =============================================================================\ndef build_image_df(root_dir, subfolders=[\"fer2013\", \"affectnet\"]):\n    \"\"\"\n    Scans the directory and returns a DataFrame with file paths and labels.\n    \"\"\"\n    data = []\n    emotions = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n    \n    print(f\"Found {len(emotions)} emotion categories: {emotions}\")\n    \n    for emotion in emotions:\n        emotion_path = os.path.join(root_dir, emotion)\n        for sub in subfolders:\n            sub_path = os.path.join(emotion_path, sub)\n            if os.path.exists(sub_path):\n                img_files = [f for f in os.listdir(sub_path) \n                            if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n                \n                print(f\"Found {len(img_files)} images in {emotion}/{sub}\")\n                \n                for img_file in img_files:\n                    data.append({\n                        \"filepath\": os.path.join(sub_path, img_file),\n                        \"label\": emotion,\n                        \"source\": sub\n                    })\n    \n    df = pd.DataFrame(data)\n    print(f\"Total images: {len(df)}\")\n    return df\n\n# =============================================================================\n# FIXED: Enhanced dataset creation with caching and repeat\n# =============================================================================\ndef create_dataset(dataframe, is_training=True, dataset_type=None, cache=True):\n    \"\"\"\n    Creates enhanced tf.data.Dataset with caching.\n    \n    Args:\n        dataframe: DataFrame with filepath, label, and source columns\n        is_training: Whether this is for training (includes augmentation)\n        dataset_type: Optional filter for specific dataset ('affectnet' or 'fer2013')\n        cache: Whether to cache the dataset\n        \n    Returns:\n        tf.data.Dataset and class mapping\n    \"\"\"\n    # Optionally filter to specific dataset\n    if dataset_type is not None:\n        dataframe = dataframe[dataframe['source'] == dataset_type].reset_index(drop=True)\n        print(f\"Filtered to {len(dataframe)} {dataset_type} images\")\n    \n    # Create class indices\n    class_indices = {cls: i for i, cls in enumerate(sorted(dataframe[\"label\"].unique()))}\n    labels = [class_indices[label] for label in dataframe[\"label\"]]\n    \n    # Create dataset\n    ds = tf.data.Dataset.from_tensor_slices((\n        dataframe[\"filepath\"].values,\n        labels,\n        dataframe[\"source\"].values\n    ))\n    \n    # Apply preprocessing with training flag\n    training_value = tf.constant(is_training)\n    ds = ds.map(\n        lambda path, label, source: preprocess_image(path, label, source, training=training_value),\n        num_parallel_calls=AUTOTUNE\n    )\n    \n    if is_training:\n        # Training pipeline with shuffle\n        ds = ds.shuffle(buffer_size=min(10000, len(dataframe)))\n        # FIXED: Add repeat to provide enough batches for all epochs\n        ds = ds.repeat()\n    \n    # Cache the dataset if requested (major speed improvement)\n    if cache:\n        ds = ds.cache()\n    \n    # Batch and prefetch\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(AUTOTUNE)\n    \n    return ds, class_indices\n\n# =============================================================================\n# Create balanced dataset with emphasis classes\n# =============================================================================\ndef create_emphasis_dataset(dataframe, is_training=True, emphasis_classes=PROBLEMATIC_CLASSES, cache=True):\n    \"\"\"\n    Creates a balanced dataset with emphasis on problematic classes.\n    \n    Args:\n        dataframe: Input DataFrame\n        is_training: Whether to apply training augmentations\n        emphasis_classes: List of classes to emphasize (oversample)\n        cache: Whether to cache the dataset\n        \n    Returns:\n        Balanced tf.data.Dataset with emphasis on specified classes\n    \"\"\"\n    balanced_data = []\n    \n    # Sample from each class with emphasis on problematic ones\n    for class_name in sorted(dataframe[\"label\"].unique()):\n        class_df = dataframe[dataframe[\"label\"] == class_name]\n        samples_per_class = 400  # Base sampling\n        \n        # Increase samples for emphasis classes\n        if class_name in emphasis_classes:\n            samples_per_class = 600  # 50% more samples for problematic classes\n            \n        # Sample with replacement if needed\n        if len(class_df) <= samples_per_class:\n            sampled = class_df.sample(n=samples_per_class, replace=True)\n        else:\n            sampled = class_df.sample(n=samples_per_class, replace=False)\n            \n        balanced_data.append(sampled)\n    \n    # Combine all balanced samples\n    balanced_df = pd.concat(balanced_data, ignore_index=True)\n    print(f\"Created balanced dataset with {len(balanced_df)} samples (with emphasis on {emphasis_classes})\")\n    \n    # Create dataset with caching\n    return create_dataset(balanced_df, is_training=is_training, cache=cache)\n\n# =============================================================================\n# Enhanced Confusion Matrix Callback with Class-Specific Monitoring\n# =============================================================================\nclass EnhancedConfusionMatrixCallback(tf.keras.callbacks.Callback):\n    \"\"\"\n    Enhanced callback to monitor class-specific metrics during training.\n    \"\"\"\n    def __init__(self, validation_data, class_names, log_dir, model_name=\"model\", freq=5):\n        super(EnhancedConfusionMatrixCallback, self).__init__()\n        self.validation_data = validation_data\n        self.class_names = class_names\n        self.freq = freq\n        self.log_dir = log_dir\n        self.model_name = model_name\n        self.zero_prediction_classes = set()  # Track classes with zero predictions\n        self.class_metrics_history = {cls: [] for cls in class_names}  # Track per-class metrics\n        \n        # Ensure log directory exists\n        ensure_dir(self.log_dir)\n        \n    def on_epoch_end(self, epoch, logs=None):\n        # Calculate and log class-specific metrics every epoch\n        val_steps = 30  # Limit computation\n        y_true = []\n        y_pred = []\n        \n        # Get predictions for validation data\n        for i, (images, labels) in enumerate(self.validation_data):\n            if i >= val_steps:\n                break\n            batch_preds = self.model.predict(images, verbose=0)\n            y_pred.append(np.argmax(batch_preds, axis=1))\n            y_true.append(np.argmax(labels.numpy(), axis=1))\n        \n        # Flatten the lists\n        y_true = np.concatenate(y_true)\n        y_pred = np.concatenate(y_pred)\n        \n        # Calculate confusion matrix\n        cm = confusion_matrix(y_true, y_pred)\n        \n        # Calculate per-class metrics\n        class_accuracies = np.zeros(len(self.class_names))\n        for i in range(len(self.class_names)):\n            if np.sum(y_true == i) > 0:  # Avoid division by zero\n                class_accuracies[i] = cm[i, i] / np.sum(y_true == i)\n                \n            # Track metrics history\n            self.class_metrics_history[self.class_names[i]].append(class_accuracies[i])\n        \n        # Check for classes with zero predictions\n        zero_pred_classes = []\n        for i, class_name in enumerate(self.class_names):\n            if np.sum(cm[:, i]) == 0:\n                zero_pred_classes.append(class_name)\n                self.zero_prediction_classes.add(class_name)\n        \n        # Log warnings for zero prediction classes\n        if zero_pred_classes:\n            warning_msg = f\"\\n⚠️ WARNING: Zero predictions for classes: {', '.join(zero_pred_classes)}\"\n            print(warning_msg)\n            \n            # Save warning to log file\n            with open(f\"{self.log_dir}/warnings.txt\", \"a\") as f:\n                f.write(f\"Epoch {epoch+1}: {warning_msg}\\n\")\n        \n        # Save visualizations and detailed reports on the specified frequency\n        if (epoch + 1) % self.freq == 0:\n            # Print confusion matrix\n            print(\"\\nConfusion Matrix:\")\n            print(cm)\n            \n            # Print per-class accuracy\n            for i, (name, acc) in enumerate(zip(self.class_names, class_accuracies)):\n                print(f\"{name}: {acc:.4f}\", end=\"  \")\n                if (i + 1) % 4 == 0:\n                    print()  # New line for readability\n            print(\"\\n\")\n            \n            # Print class accuracy trends\n            print(\"Class Accuracy Trends:\")\n            for class_name in self.class_names:\n                history = self.class_metrics_history[class_name]\n                trend = \", \".join([f\"{acc:.4f}\" for acc in history[-5:]])  # Show last 5 epochs\n                print(f\"{class_name}: [{trend}]\")\n            print()\n            \n            # Save confusion matrix visualization\n            plt.figure(figsize=(10, 8))\n            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                       xticklabels=self.class_names,\n                       yticklabels=self.class_names)\n            plt.xlabel('Predicted')\n            plt.ylabel('True')\n            plt.title(f'Confusion Matrix - {self.model_name} - Epoch {epoch+1}')\n            plt.tight_layout()\n            \n            try:\n                plt.savefig(f'{self.log_dir}/confusion_matrix_epoch_{epoch+1}.png')\n            except Exception as e:\n                print(f\"Warning: Could not save confusion matrix plot: {e}\")\n            \n            plt.close()\n\n# =============================================================================\n# FIXED: Create Ensemble Model Architecture with Internal Preprocessing\n# =============================================================================\ndef create_ensemble_model(num_classes=8, freeze_base=True):\n    \"\"\"\n    Create an ensemble with model-specific preprocessing layers.\n    All preprocessing happens inside the model, which expects\n    a standard size input (224x224x3 normalized to [0,1]).\n    \n    Args:\n        num_classes: Number of emotion classes\n        freeze_base: Whether to freeze base models initially\n        \n    Returns:\n        Compiled Keras ensemble model\n    \"\"\"\n    # Create inputs for consistently sized images\n    inputs = keras.layers.Input(shape=(224, 224, 3), name='image_input')\n    \n    # === MobileNetV2 Branch ===\n    # Resize and normalize for MobileNetV2\n    mobilenet_preprocess = Lambda(\n        lambda x: tf.image.resize(x*255.0, [96, 96]) / 127.5 - 1,  # Scale back to [0,255] then normalize to [-1,1]\n        name='mobilenet_preprocess'\n    )(inputs)\n    \n    mobilenet_base = MobileNetV2(\n        include_top=False, \n        weights='imagenet',\n        input_tensor=mobilenet_preprocess,\n        alpha=1.0,\n        name='mobilenet_base'\n    )\n    \n    if freeze_base:\n        for layer in mobilenet_base.layers:\n            layer.trainable = False\n            \n    mobilenet_features = GlobalAveragePooling2D(name='mobilenet_gap')(mobilenet_base.output)\n    mobilenet_features = Dense(128, name='mobilenet_projection')(mobilenet_features)\n    mobilenet_features = BatchNormalization()(mobilenet_features)\n    mobilenet_features = Activation('relu')(mobilenet_features)\n    \n    # === Xception Branch ===\n    # Resize and normalize for Xception\n    xception_preprocess = Lambda(\n        lambda x: tf.keras.applications.xception.preprocess_input(\n            tf.image.resize(x*255.0, [299, 299])\n        ),\n        name='xception_preprocess'\n    )(inputs)\n    \n    xception_base = Xception(\n        include_top=False,\n        weights='imagenet',\n        input_tensor=xception_preprocess,\n        name='efficientnet_base'\n    )\n    \n    if freeze_base:\n        for layer in xception_base.layers:\n            layer.trainable = False\n            \n    xception_features = GlobalAveragePooling2D(name='xception_gap')(xception_base.output)\n    xception_features = Dense(128, name='xception_projection')(xception_features)\n    xception_features = BatchNormalization()(xception_features)\n    xception_features = Activation('relu')(xception_features)\n    \n    # === EfficientNetB0 Branch ===\n    # Normalize for EfficientNetB0 (already 224x224 size)\n    efficientnet_preprocess = Lambda(\n        lambda x: tf.keras.applications.efficientnet.preprocess_input(x*255.0),\n        name='efficientnet_preprocess'\n    )(inputs)\n    \n    efficientnet_base = EfficientNetB0(\n        include_top=False,\n        weights='imagenet',\n        input_tensor=efficientnet_preprocess\n    )\n    \n    if freeze_base:\n        for layer in efficientnet_base.layers:\n            layer.trainable = False\n            \n    efficientnet_features = GlobalAveragePooling2D(name='efficientnet_gap')(efficientnet_base.output)\n    efficientnet_features = Dense(128, name='efficientnet_projection')(efficientnet_features)\n    efficientnet_features = BatchNormalization()(efficientnet_features)\n    efficientnet_features = Activation('relu')(efficientnet_features)\n    \n    # === Feature Fusion ===\n    # Combine features with concatenation\n    merged_features = Concatenate(name='feature_fusion')(\n        [mobilenet_features, xception_features, efficientnet_features]\n    )\n    \n    # Classification head\n    x = Dense(256, name='fusion_dense1')(merged_features)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.5)(x)\n    \n    x = Dense(128, name='fusion_dense2')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.3)(x)\n    \n    # Output layer with softmax\n    outputs = Dense(num_classes, activation='softmax', dtype='float32', name='emotion_output')(x)\n    \n    # Create model\n    model = keras.Model(inputs=inputs, outputs=outputs, name='emotion_ensemble')\n    \n    # Cosine decay learning rate\n    initial_learning_rate = 1e-3\n    lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n        initial_learning_rate, \n        decay_steps=10000  # Adjust based on epochs * steps_per_epoch\n    )\n    \n    # Optimizer with loss scaling for mixed precision\n    optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n    optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n    \n    # Compile with focal loss\n    model.compile(\n        optimizer=optimizer,\n        loss=focal_loss(gamma=2.0),  # Using focal loss instead of label smoothing\n        metrics=['accuracy']\n    )\n    \n    return model\n\n# =============================================================================\n# Evaluation function\n# =============================================================================\ndef evaluate_model(model, test_ds, steps, class_names, log_dir, dataset_name=\"\"):\n    \"\"\"\n    Evaluate model with detailed metrics and visualizations.\n    \"\"\"\n    print(f\"\\nEvaluating model on {dataset_name} test set\")\n    \n    # Get predictions\n    y_true = []\n    y_pred = []\n    \n    # Loop through test batches\n    for i, (images, labels) in enumerate(test_ds):\n        if i >= steps:\n            break\n        batch_preds = model.predict(images, verbose=0)\n        y_pred.append(np.argmax(batch_preds, axis=1))\n        y_true.append(np.argmax(labels.numpy(), axis=1))\n    \n    # Concatenate\n    y_true = np.concatenate(y_true)\n    y_pred = np.concatenate(y_pred)\n    \n    # Calculate metrics\n    test_accuracy = np.mean(y_pred == y_true)\n    f1 = f1_score(y_true, y_pred, average='weighted')\n    \n    print(f\"{dataset_name} Test Accuracy: {test_accuracy:.4f}\")\n    print(f\"{dataset_name} Weighted F1-Score: {f1:.4f}\")\n    \n    # Calculate confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Visualize confusion matrix\n    plt.figure(figsize=(12, 10))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n               xticklabels=class_names,\n               yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title(f'Confusion Matrix - {dataset_name} Test Set')\n    plt.tight_layout()\n    \n    try:\n        plt.savefig(f'{log_dir}/confusion_matrix_{dataset_name}_test.png')\n    except Exception as e:\n        print(f\"Warning: Could not save confusion matrix plot: {e}\")\n        \n    plt.close()\n    \n    # Print classification report\n    print(f\"\\n{dataset_name} Classification Report:\")\n    report = classification_report(\n        y_true, \n        y_pred, \n        target_names=class_names,\n        zero_division=0\n    )\n    print(report)\n    \n    # Save report to file\n    with open(f'{log_dir}/classification_report_{dataset_name}.txt', 'w') as f:\n        f.write(report)\n    \n    return {\n        'accuracy': test_accuracy,\n        'f1_score': f1,\n        'confusion_matrix': cm\n    }\n\n# =============================================================================\n# Progressive Training Strategy for Ensemble\n# =============================================================================\ndef train_ensemble_with_progressive_strategy(model, train_ds, val_ds, \n                                           steps_per_epoch, val_steps,\n                                           total_epochs=30,\n                                           callbacks=None,\n                                           class_weights=None):\n    \"\"\"\n    Three-stage training approach for ensemble:\n    1. Train only the fusion layers (all base models frozen)\n    2. Unfreeze and train EfficientNet and MobileNet (keep Xception frozen)\n    3. Unfreeze and fine-tune all models\n    \n    Args:\n        model: The ensemble model\n        train_ds: Training dataset\n        val_ds: Validation dataset\n        steps_per_epoch: Steps per training epoch\n        val_steps: Validation steps\n        total_epochs: Total epochs across all stages\n        callbacks: List of callbacks\n        class_weights: Class weights for handling imbalance\n        \n    Returns:\n        Training history\n    \"\"\"\n    histories = []\n    \n    # Stage 1: Train only fusion layers (10% of total epochs)\n    stage1_epochs = max(3, int(total_epochs * 0.1))\n    print(f\"\\nStage 1: Training only fusion layers ({stage1_epochs} epochs)\")\n    \n    # Ensure base models are frozen\n    for layer in model.layers:\n        if any(base_name in layer.name for base_name in ['mobilenet_base', 'xception_base', 'efficientnet_base']):\n            for base_layer in layer.layers:\n                base_layer.trainable = False\n    \n    # Train fusion layers\n    history1 = model.fit(\n        train_ds,\n        epochs=stage1_epochs,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=val_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    histories.append(history1)\n    \n    # Stage 2: Unfreeze and train EfficientNet and MobileNet (30% of total epochs)\n    stage2_epochs = max(6, int(total_epochs * 0.3))\n    print(f\"\\nStage 2: Training EfficientNet and MobileNet branches ({stage2_epochs} epochs)\")\n    \n    # Unfreeze EfficientNet and MobileNet, keep Xception frozen\n    for layer in model.layers:\n        if layer.name in ['efficientnet_base', 'mobilenet_base']:\n            for base_layer in layer.layers[-30:]:  # Unfreeze last 30 layers\n                base_layer.trainable = True\n    \n    # Recompile with lower learning rate\n    optimizer = keras.optimizers.Adam(1e-4)  # Lower learning rate\n    optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n    \n    model.compile(\n        optimizer=optimizer,\n        loss=focal_loss(gamma=2.0),\n        metrics=['accuracy']\n    )\n    \n    # Train with partial unfreezing\n    history2 = model.fit(\n        train_ds,\n        epochs=stage2_epochs,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=val_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    histories.append(history2)\n    \n    # Stage 3: Unfreeze all models and fine-tune (remaining epochs)\n    stage3_epochs = total_epochs - stage1_epochs - stage2_epochs\n    print(f\"\\nStage 3: Fine-tuning all models ({stage3_epochs} epochs)\")\n    \n    # Unfreeze all models including Xception (which is more complex)\n    for layer in model.layers:\n        if any(base_name in layer.name for base_name in ['mobilenet_base', 'xception_base', 'efficientnet_base']):\n            for base_layer in layer.layers[-50:]:  # Unfreeze more layers\n                base_layer.trainable = True\n    \n    # Recompile with even lower learning rate\n    optimizer = keras.optimizers.Adam(5e-5)  # Very low learning rate for fine-tuning\n    optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n    \n    model.compile(\n        optimizer=optimizer,\n        loss=focal_loss(gamma=2.0),\n        metrics=['accuracy']\n    )\n    \n    # Final fine-tuning\n    history3 = model.fit(\n        train_ds,\n        epochs=stage3_epochs,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=val_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    histories.append(history3)\n    \n    return histories\n\n# =============================================================================\n# Main training pipeline with ensemble\n# =============================================================================\ndef train_emotion_ensemble(data_dir):\n    \"\"\"\n    Enhanced sequential training pipeline for emotion recognition ensemble.\n    \n    Args:\n        data_dir: Path to dataset directory\n        \n    Returns:\n        Trained ensemble model and evaluation metrics\n    \"\"\"\n    print(\"Starting enhanced ensemble training for emotion recognition\")\n    \n    # 1. Load and prepare data\n    print(\"\\n1. Loading datasets\")\n    train_dir = os.path.join(data_dir, \"Train\")\n    test_dir = os.path.join(data_dir, \"Test\")\n    \n    train_df_full = build_image_df(train_dir)\n    test_df = build_image_df(test_dir)\n    \n    # Show dataset distributions\n    print(\"\\nAffectNet training distribution:\")\n    print(train_df_full[train_df_full['source'] == 'affectnet']['label'].value_counts())\n    \n    print(\"\\nFER2013 training distribution:\")\n    print(train_df_full[train_df_full['source'] == 'fer2013']['label'].value_counts())\n    \n    # 2. Split test set by dataset source\n    test_affectnet_df = test_df[test_df['source'] == 'affectnet']\n    test_fer_df = test_df[test_df['source'] == 'fer2013']\n    \n    print(f\"\\nTest sets: AffectNet={len(test_affectnet_df)}, FER2013={len(test_fer_df)}\")\n    \n    # Get classes for later use\n    classes = sorted(train_df_full[\"label\"].unique())\n    num_classes = len(classes)\n    print(f\"Classes: {classes}\")\n    \n    # 3. Create validation splits\n    # For AffectNet\n    affectnet_train_df = train_df_full[train_df_full['source'] == 'affectnet']\n    affectnet_train_df, affectnet_val_df = train_test_split(\n        affectnet_train_df, \n        test_size=0.15, \n        stratify=affectnet_train_df[\"label\"], \n        random_state=42\n    )\n    \n    # For FER2013\n    fer_train_df = train_df_full[train_df_full['source'] == 'fer2013']\n    fer_train_df, fer_val_df = train_test_split(\n        fer_train_df, \n        test_size=0.15, \n        stratify=fer_train_df[\"label\"], \n        random_state=42\n    )\n    \n    print(f\"AffectNet: {len(affectnet_train_df)} train, {len(affectnet_val_df)} validation\")\n    print(f\"FER2013: {len(fer_train_df)} train, {len(fer_val_df)} validation\")\n    \n    # 4. Create datasets with emphasis on problematic classes and caching\n    print(\"\\n2. Creating enhanced data pipelines with caching\")\n    \n    # AffectNet datasets\n    affectnet_train_ds, class_indices = create_emphasis_dataset(\n        affectnet_train_df, is_training=True, cache=True)\n    \n    affectnet_val_ds, _ = create_dataset(\n        affectnet_val_df, is_training=False, \n        dataset_type='affectnet', cache=True)\n    \n    affectnet_test_ds, _ = create_dataset(\n        test_affectnet_df, is_training=False, \n        dataset_type='affectnet', cache=True)\n    \n    # FER2013 datasets\n    fer_train_ds, _ = create_emphasis_dataset(\n        fer_train_df, is_training=True, cache=True)\n    \n    fer_val_ds, _ = create_dataset(\n        fer_val_df, is_training=False, \n        dataset_type='fer2013', cache=True)\n    \n    fer_test_ds, _ = create_dataset(\n        test_fer_df, is_training=False, \n        dataset_type='fer2013', cache=True)\n    \n    # Create combined test dataset\n    combined_test_ds, _ = create_dataset(\n        test_df, is_training=False, cache=True)\n    \n    # 5. Calculate steps with increased batch size\n    affectnet_steps_per_epoch = len(affectnet_train_df) // BATCH_SIZE\n    affectnet_val_steps = len(affectnet_val_df) // BATCH_SIZE\n    affectnet_test_steps = len(test_affectnet_df) // BATCH_SIZE\n    \n    fer_steps_per_epoch = len(fer_train_df) // BATCH_SIZE\n    fer_val_steps = len(fer_val_df) // BATCH_SIZE\n    fer_test_steps = len(test_fer_df) // BATCH_SIZE\n    \n    combined_test_steps = len(test_df) // BATCH_SIZE\n    \n    # 6. Create ensemble model\n    print(\"\\n3. Creating ensemble model architecture\")\n    ensemble_model = create_ensemble_model(num_classes=num_classes, freeze_base=True)\n    print(f\"Ensemble model created with {ensemble_model.count_params():,} parameters\")\n    \n    # 7. Compute class weights for each dataset with adjustments\n    print(\"\\n4. Computing class weights with adjustments for problematic classes\")\n    \n    # AffectNet class weights\n    affectnet_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(affectnet_train_df[\"label\"].values),\n        y=affectnet_train_df[\"label\"].values\n    )\n    affectnet_class_weights = {class_indices[label]: weight for label, weight in \n                     zip(np.unique(affectnet_train_df[\"label\"].values), affectnet_weights)}\n    \n    # FER2013 class weights\n    fer_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(fer_train_df[\"label\"].values),\n        y=fer_train_df[\"label\"].values\n    )\n    fer_class_weights = {class_indices[label]: weight for label, weight in \n                zip(np.unique(fer_train_df[\"label\"].values), fer_weights)}\n    \n    # Increase weights for problematic classes\n    for problem_class in PROBLEMATIC_CLASSES:\n        if problem_class in class_indices:\n            class_idx = class_indices[problem_class]\n            # Increase the weight by 20%\n            if class_idx in affectnet_class_weights:\n                affectnet_class_weights[class_idx] *= 1.2\n            if class_idx in fer_class_weights:\n                fer_class_weights[class_idx] *= 1.2\n    \n    print(\"Enhanced AffectNet class weights:\", affectnet_class_weights)\n    print(\"Enhanced FER2013 class weights:\", fer_class_weights)\n    \n    # 8. Setup callbacks with enhanced monitoring\n    print(\"\\n5. Setting up enhanced callbacks\")\n    \n    # Base callbacks shared across training phases\n    base_callbacks = [\n        # Early stopping\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=8,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        # TensorBoard\n        tf.keras.callbacks.TensorBoard(\n            log_dir=LOG_DIR + '/ensemble',\n            histogram_freq=1,\n            update_freq='epoch'\n        )\n    ]\n    \n    # AffectNet-specific callbacks\n    affectnet_callbacks = base_callbacks + [\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'model_checkpoints/affectnet_ensemble_best.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        ),\n        # Enhanced confusion matrix monitoring\n        EnhancedConfusionMatrixCallback(\n            affectnet_val_ds, \n            classes, \n            log_dir=LOG_DIR + '/affectnet',\n            model_name=\"AffectNet Ensemble\",\n            freq=3\n        ),\n        # CSV Logger\n        tf.keras.callbacks.CSVLogger(\n            'affectnet_ensemble_training_log.csv', \n            append=True\n        )\n    ]\n    \n    # FER2013-specific callbacks\n    fer_callbacks = base_callbacks + [\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'model_checkpoints/fer2013_ensemble_best.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        ),\n        # Enhanced confusion matrix monitoring\n        EnhancedConfusionMatrixCallback(\n            fer_val_ds, \n            classes, \n            log_dir=LOG_DIR + '/fer2013',\n            model_name=\"FER2013 Ensemble\",\n            freq=3\n        ),\n        # CSV Logger\n        tf.keras.callbacks.CSVLogger(\n            'fer2013_ensemble_training_log.csv', \n            append=True\n        )\n    ]\n    \n    # 9. STAGE 1: Train ensemble on AffectNet using progressive strategy\n    print(\"\\n6. STAGE 1: Training ensemble on AffectNet with progressive strategy\")\n    \n    affectnet_histories = train_ensemble_with_progressive_strategy(\n        ensemble_model,\n        affectnet_train_ds, affectnet_val_ds,\n        affectnet_steps_per_epoch, affectnet_val_steps,\n        total_epochs=20,  # Adjust as needed\n        callbacks=affectnet_callbacks,\n        class_weights=affectnet_class_weights\n    )\n    \n    # Save AffectNet model\n    ensemble_model.save(\"affectnet_ensemble_model.keras\")\n    print(\"AffectNet ensemble model saved to 'affectnet_ensemble_model.keras'\")\n    \n    # 10. Evaluate on AffectNet test set\n    affectnet_metrics = evaluate_model(\n        ensemble_model, \n        affectnet_test_ds, \n        affectnet_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"AffectNet\"\n    )\n    \n    # 11. STAGE 2: Fine-tune on FER2013 with progressive strategy\n    print(\"\\n7. STAGE 2: Fine-tuning ensemble on FER2013 with progressive strategy\")\n    \n    fer_histories = train_ensemble_with_progressive_strategy(\n        ensemble_model,\n        fer_train_ds, fer_val_ds,\n        fer_steps_per_epoch, fer_val_steps,\n        total_epochs=15,  # Adjust as needed\n        callbacks=fer_callbacks,\n        class_weights=fer_class_weights\n    )\n    \n    # 12. Evaluate on FER2013 test set\n    fer_metrics = evaluate_model(\n        ensemble_model, \n        fer_test_ds, \n        fer_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"FER2013\"\n    )\n    \n    # 13. Evaluate on combined test set\n    combined_metrics = evaluate_model(\n        ensemble_model, \n        combined_test_ds, \n        combined_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"Combined\"\n    )\n    \n    # 14. Save the final model\n    ensemble_model.save(\"final_emotion_ensemble.keras\")\n    print(\"Final ensemble model saved to 'final_emotion_ensemble.keras'\")\n    \n    # Return model and metrics\n    return ensemble_model, {\n        'affectnet': affectnet_metrics,\n        'fer2013': fer_metrics,\n        'combined': combined_metrics\n    }\n\n# =============================================================================\n# Main entry point\n# =============================================================================\nif __name__ == \"__main__\":\n    # Set data directory path\n    data_dir = \"/kaggle/input/custom-fer2013affectnet/Custom_ferAffect2013net\"\n    \n    # Train ensemble model with all improvements\n    model, metrics = train_emotion_ensemble(data_dir)\n    \n    # Print final results\n    print(\"\\n=== FINAL RESULTS ===\")\n    print(f\"AffectNet Test Accuracy: {metrics['affectnet']['accuracy']:.4f}\")\n    print(f\"AffectNet F1 Score: {metrics['affectnet']['f1_score']:.4f}\")\n    print(f\"FER2013 Test Accuracy: {metrics['fer2013']['accuracy']:.4f}\")\n    print(f\"FER2013 F1 Score: {metrics['fer2013']['f1_score']:.4f}\")\n    print(f\"Combined Test Accuracy: {metrics['combined']['accuracy']:.4f}\")\n    print(f\"Combined F1 Score: {metrics['combined']['f1_score']:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# customized \n\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom tensorflow.keras.applications import MobileNetV2, Xception, EfficientNetB0\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\nfrom tensorflow.keras.layers import Concatenate, Activation, Lambda, Input\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\n\n# =============================================================================\n# Configure GPU and enable mixed precision\n# =============================================================================\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(f\"Found {len(gpus)} GPUs: Memory growth enabled\")\n    except RuntimeError as e:\n        print(f\"GPU error: {e}\")\n\n# Enable mixed precision training\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled\")\n\n# =============================================================================\n# Key parameters\n# =============================================================================\nBATCH_SIZE = 64  # Increased from 32 to 64 for better GPU utilization\nAUTOTUNE = tf.data.AUTOTUNE\nLOG_DIR = \"./emotion_logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\n# Create all required directories\ndef ensure_dir(directory):\n    \"\"\"Make sure a directory exists, creating it if necessary\"\"\"\n    if not os.path.exists(directory):\n        os.makedirs(directory, exist_ok=True)\n\n# Create main log directories\nensure_dir(LOG_DIR)\nensure_dir(LOG_DIR + '/affectnet')\nensure_dir(LOG_DIR + '/fer2013')\nensure_dir(LOG_DIR + '/combined')\nensure_dir(LOG_DIR + '/ensemble')\nensure_dir(\"./model_checkpoints\")\n\n# Define problematic classes for targeted augmentation\nPROBLEMATIC_CLASSES = ['surprise', 'sad', 'disgust']\n\n# =============================================================================\n# Focal Loss for better handling of class imbalance\n# =============================================================================\ndef focal_loss(gamma=2.0, alpha=None):\n    \"\"\"\n    Focal loss implementation for better handling of class imbalance.\n    Focuses training on hard examples by down-weighting easy examples.\n    \n    Args:\n        gamma: Focusing parameter (higher = more focus on hard examples)\n        alpha: Optional class weight factors\n        \n    Returns:\n        Loss function\n    \"\"\"\n    def loss_fn(y_true, y_pred):\n        # Add small epsilon to avoid log(0)\n        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0)\n        \n        # Basic cross entropy\n        cross_entropy = -y_true * tf.math.log(y_pred)\n        \n        # Apply class weighting if provided\n        if alpha is not None:\n            # Convert alpha to proper shape if it's a dict\n            if isinstance(alpha, dict):\n                # Create a tensor of appropriate shape filled with ones\n                alpha_tensor = tf.ones_like(y_true)\n                \n                # For each class index in the alpha dict, update the corresponding\n                # position in alpha_tensor with the weight value\n                for class_idx, weight in alpha.items():\n                    # Create a mask for the current class\n                    class_mask = tf.cast(tf.equal(tf.argmax(y_true, axis=-1), class_idx), tf.float32)\n                    \n                    # Reshape to broadcast properly\n                    class_mask = tf.expand_dims(class_mask, axis=-1)\n                    \n                    # Update weights for this class\n                    alpha_tensor = alpha_tensor * (1 - class_mask) + weight * class_mask\n                \n                cross_entropy = alpha_tensor * cross_entropy\n            else:\n                cross_entropy = alpha * cross_entropy\n        \n        # Apply focusing parameter\n        focal_weight = tf.pow(1 - y_pred, gamma)\n        focal_loss = focal_weight * cross_entropy\n        \n        # Sum over classes\n        return tf.reduce_sum(focal_loss, axis=-1)\n    \n    return loss_fn\n\n# =============================================================================\n# Enhanced Model-specific Image Preprocessing\n# =============================================================================\ndef preprocess_image(file_path, label, source, training=True):\n    \"\"\"\n    Enhanced preprocessing with model-specific handling.\n    \n    Args:\n        file_path: Path to the image file\n        label: Emotion label (as index)\n        source: Dataset source ('fer2013' or 'affectnet')\n        training: Whether to apply augmentation\n        \n    Returns:\n        Preprocessed image and one-hot encoded label\n    \"\"\"\n    # Read the file\n    img = tf.io.read_file(file_path)\n    \n    # Decode image with proper error handling\n    def decode_image():\n        try:\n            decoded = tf.image.decode_image(img, channels=3, expand_animations=False)\n            decoded = tf.ensure_shape(decoded, [None, None, 3])\n            return decoded\n        except:\n            # Return blank image if decoding fails\n            return tf.zeros([224, 224, 3], dtype=tf.uint8)\n    \n    img = decode_image()\n    img = tf.cast(img, tf.float32)\n    \n    # Dataset-specific preprocessing\n    if source == 'fer2013':\n        # Handle grayscale conversion correctly\n        if tf.shape(img)[-1] == 1:\n            # Already grayscale\n            img = tf.tile(img, [1, 1, 3])\n        else:\n            # Convert to grayscale then back to 3 channels\n            img = tf.image.rgb_to_grayscale(img)\n            img = tf.tile(img, [1, 1, 3])\n    \n    # Apply basic augmentation during training\n    if training:\n        # Random flip - works in graph mode\n        img = tf.image.random_flip_left_right(img)\n        \n        # Basic brightness and contrast\n        img = tf.image.random_brightness(img, 0.2)\n        img = tf.image.random_contrast(img, 0.8, 1.2)\n            \n        # Add random noise to improve robustness\n        noise = tf.random.normal(shape=tf.shape(img), mean=0.0, stddev=0.01)\n        img = img + noise\n        \n        # Additional augmentation for problematic classes\n        # Note: We need a more sophisticated approach outside this function\n        # as we can't check label values directly in a graph-compatible way\n    \n    # One-hot encode label\n    label = tf.one_hot(label, depth=8)  # 8 emotion classes\n    \n    return img, label\n\n# =============================================================================\n# Build DataFrame from dataset directory structure\n# =============================================================================\ndef build_image_df(root_dir, subfolders=[\"fer2013\", \"affectnet\"]):\n    \"\"\"\n    Scans the directory and returns a DataFrame with file paths and labels.\n    \"\"\"\n    data = []\n    emotions = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n    \n    print(f\"Found {len(emotions)} emotion categories: {emotions}\")\n    \n    for emotion in emotions:\n        emotion_path = os.path.join(root_dir, emotion)\n        for sub in subfolders:\n            sub_path = os.path.join(emotion_path, sub)\n            if os.path.exists(sub_path):\n                img_files = [f for f in os.listdir(sub_path) \n                            if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n                \n                print(f\"Found {len(img_files)} images in {emotion}/{sub}\")\n                \n                for img_file in img_files:\n                    data.append({\n                        \"filepath\": os.path.join(sub_path, img_file),\n                        \"label\": emotion,\n                        \"source\": sub\n                    })\n    \n    df = pd.DataFrame(data)\n    print(f\"Total images: {len(df)}\")\n    return df\n\n# =============================================================================\n# Enhanced dataset creation with caching\n# =============================================================================\ndef create_dataset(dataframe, is_training=True, dataset_type=None, cache=True):\n    \"\"\"\n    Creates enhanced tf.data.Dataset with caching.\n    \n    Args:\n        dataframe: DataFrame with filepath, label, and source columns\n        is_training: Whether this is for training (includes augmentation)\n        dataset_type: Optional filter for specific dataset ('affectnet' or 'fer2013')\n        cache: Whether to cache the dataset\n        \n    Returns:\n        tf.data.Dataset and class mapping\n    \"\"\"\n    # Optionally filter to specific dataset\n    if dataset_type is not None:\n        dataframe = dataframe[dataframe['source'] == dataset_type].reset_index(drop=True)\n        print(f\"Filtered to {len(dataframe)} {dataset_type} images\")\n    \n    # Create class indices\n    class_indices = {cls: i for i, cls in enumerate(sorted(dataframe[\"label\"].unique()))}\n    labels = [class_indices[label] for label in dataframe[\"label\"]]\n    \n    # Create dataset\n    ds = tf.data.Dataset.from_tensor_slices((\n        dataframe[\"filepath\"].values,\n        labels,\n        dataframe[\"source\"].values\n    ))\n    \n    # Apply preprocessing with training flag\n    training_value = tf.constant(is_training)\n    ds = ds.map(\n        lambda path, label, source: preprocess_image(path, label, source, training=training_value),\n        num_parallel_calls=AUTOTUNE\n    )\n    \n    if is_training:\n        # Training pipeline with shuffle\n        ds = ds.shuffle(buffer_size=min(10000, len(dataframe)))\n    \n    # Cache the dataset if requested (major speed improvement)\n    if cache:\n        ds = ds.cache()\n    \n    # Batch and prefetch\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(AUTOTUNE)\n    \n    return ds, class_indices\n\n# =============================================================================\n# Create balanced dataset with emphasis classes\n# =============================================================================\ndef create_emphasis_dataset(dataframe, is_training=True, emphasis_classes=PROBLEMATIC_CLASSES, cache=True):\n    \"\"\"\n    Creates a balanced dataset with emphasis on problematic classes.\n    \n    Args:\n        dataframe: Input DataFrame\n        is_training: Whether to apply training augmentations\n        emphasis_classes: List of classes to emphasize (oversample)\n        cache: Whether to cache the dataset\n        \n    Returns:\n        Balanced tf.data.Dataset with emphasis on specified classes\n    \"\"\"\n    balanced_data = []\n    \n    # Sample from each class with emphasis on problematic ones\n    for class_name in sorted(dataframe[\"label\"].unique()):\n        class_df = dataframe[dataframe[\"label\"] == class_name]\n        samples_per_class = 400  # Base sampling\n        \n        # Increase samples for emphasis classes\n        if class_name in emphasis_classes:\n            samples_per_class = 600  # 50% more samples for problematic classes\n            \n        # Sample with replacement if needed\n        if len(class_df) <= samples_per_class:\n            sampled = class_df.sample(n=samples_per_class, replace=True)\n        else:\n            sampled = class_df.sample(n=samples_per_class, replace=False)\n            \n        balanced_data.append(sampled)\n    \n    # Combine all balanced samples\n    balanced_df = pd.concat(balanced_data, ignore_index=True)\n    print(f\"Created balanced dataset with {len(balanced_df)} samples (with emphasis on {emphasis_classes})\")\n    \n    # Create dataset with caching\n    return create_dataset(balanced_df, is_training=is_training, cache=cache)\n\n# =============================================================================\n# Enhanced Confusion Matrix Callback with Class-Specific Monitoring\n# =============================================================================\nclass EnhancedConfusionMatrixCallback(tf.keras.callbacks.Callback):\n    \"\"\"\n    Enhanced callback to monitor class-specific metrics during training.\n    \"\"\"\n    def __init__(self, validation_data, class_names, log_dir, model_name=\"model\", freq=5):\n        super(EnhancedConfusionMatrixCallback, self).__init__()\n        self.validation_data = validation_data\n        self.class_names = class_names\n        self.freq = freq\n        self.log_dir = log_dir\n        self.model_name = model_name\n        self.zero_prediction_classes = set()  # Track classes with zero predictions\n        self.class_metrics_history = {cls: [] for cls in class_names}  # Track per-class metrics\n        \n        # Ensure log directory exists\n        ensure_dir(self.log_dir)\n        \n    def on_epoch_end(self, epoch, logs=None):\n        # Calculate and log class-specific metrics every epoch\n        val_steps = 30  # Limit computation\n        y_true = []\n        y_pred = []\n        \n        # Get predictions for validation data\n        for i, (images, labels) in enumerate(self.validation_data):\n            if i >= val_steps:\n                break\n            batch_preds = self.model.predict(images, verbose=0)\n            y_pred.append(np.argmax(batch_preds, axis=1))\n            y_true.append(np.argmax(labels.numpy(), axis=1))\n        \n        # Flatten the lists\n        y_true = np.concatenate(y_true)\n        y_pred = np.concatenate(y_pred)\n        \n        # Calculate confusion matrix\n        cm = confusion_matrix(y_true, y_pred)\n        \n        # Calculate per-class metrics\n        class_accuracies = np.zeros(len(self.class_names))\n        for i in range(len(self.class_names)):\n            if np.sum(y_true == i) > 0:  # Avoid division by zero\n                class_accuracies[i] = cm[i, i] / np.sum(y_true == i)\n                \n            # Track metrics history\n            self.class_metrics_history[self.class_names[i]].append(class_accuracies[i])\n        \n        # Check for classes with zero predictions\n        zero_pred_classes = []\n        for i, class_name in enumerate(self.class_names):\n            if np.sum(cm[:, i]) == 0:\n                zero_pred_classes.append(class_name)\n                self.zero_prediction_classes.add(class_name)\n        \n        # Log warnings for zero prediction classes\n        if zero_pred_classes:\n            warning_msg = f\"\\n⚠️ WARNING: Zero predictions for classes: {', '.join(zero_pred_classes)}\"\n            print(warning_msg)\n            \n            # Save warning to log file\n            with open(f\"{self.log_dir}/warnings.txt\", \"a\") as f:\n                f.write(f\"Epoch {epoch+1}: {warning_msg}\\n\")\n        \n        # Save visualizations and detailed reports on the specified frequency\n        if (epoch + 1) % self.freq == 0:\n            # Print confusion matrix\n            print(\"\\nConfusion Matrix:\")\n            print(cm)\n            \n            # Print per-class accuracy\n            for i, (name, acc) in enumerate(zip(self.class_names, class_accuracies)):\n                print(f\"{name}: {acc:.4f}\", end=\"  \")\n                if (i + 1) % 4 == 0:\n                    print()  # New line for readability\n            print(\"\\n\")\n            \n            # Print class accuracy trends\n            print(\"Class Accuracy Trends:\")\n            for class_name in self.class_names:\n                history = self.class_metrics_history[class_name]\n                trend = \", \".join([f\"{acc:.4f}\" for acc in history[-5:]])  # Show last 5 epochs\n                print(f\"{class_name}: [{trend}]\")\n            print()\n            \n            # Save confusion matrix visualization\n            plt.figure(figsize=(10, 8))\n            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                       xticklabels=self.class_names,\n                       yticklabels=self.class_names)\n            plt.xlabel('Predicted')\n            plt.ylabel('True')\n            plt.title(f'Confusion Matrix - {self.model_name} - Epoch {epoch+1}')\n            plt.tight_layout()\n            \n            try:\n                plt.savefig(f'{self.log_dir}/confusion_matrix_epoch_{epoch+1}.png')\n            except Exception as e:\n                print(f\"Warning: Could not save confusion matrix plot: {e}\")\n            \n            plt.close()\n\n# =============================================================================\n# Create Ensemble Model Architecture\n# =============================================================================\ndef create_ensemble_model(num_classes=8, freeze_base=True):\n    \"\"\"\n    Create an ensemble of MobileNetV2, Xception, and EfficientNetB0\n    with shared input but model-specific preprocessing.\n    \n    Args:\n        num_classes: Number of emotion classes\n        freeze_base: Whether to freeze base models initially\n        \n    Returns:\n        Compiled Keras ensemble model\n    \"\"\"\n    # Create inputs\n    inputs = keras.layers.Input(shape=(None, None, 3), name='image_input')\n    \n    # === MobileNetV2 Branch ===\n    mobilenet_preprocess = Lambda(\n        lambda x: tf.image.resize(x, [96, 96]) / 127.5 - 1,\n        name='mobilenet_preprocess'\n    )(inputs)\n    \n    mobilenet_base = MobileNetV2(\n        include_top=False, \n        weights='imagenet',\n        input_tensor=mobilenet_preprocess,\n        alpha=1.0\n    )\n    \n    if freeze_base:\n        for layer in mobilenet_base.layers:\n            layer.trainable = False\n            \n    mobilenet_features = GlobalAveragePooling2D(name='mobilenet_gap')(mobilenet_base.output)\n    mobilenet_features = Dense(128, name='mobilenet_projection')(mobilenet_features)\n    mobilenet_features = BatchNormalization()(mobilenet_features)\n    mobilenet_features = Activation('relu')(mobilenet_features)\n    \n    # === Xception Branch ===\n    xception_preprocess = Lambda(\n        lambda x: tf.keras.applications.xception.preprocess_input(\n            tf.image.resize(x, [299, 299])\n        ),\n        name='xception_preprocess'\n    )(inputs)\n    \n    xception_base = Xception(\n        include_top=False,\n        weights='imagenet',\n        input_tensor=xception_preprocess\n    )\n    \n    if freeze_base:\n        for layer in xception_base.layers:\n            layer.trainable = False\n            \n    xception_features = GlobalAveragePooling2D(name='xception_gap')(xception_base.output)\n    xception_features = Dense(128, name='xception_projection')(xception_features)\n    xception_features = BatchNormalization()(xception_features)\n    xception_features = Activation('relu')(xception_features)\n    \n    # === EfficientNetB0 Branch ===\n    efficientnet_preprocess = Lambda(\n        lambda x: tf.keras.applications.efficientnet.preprocess_input(\n            tf.image.resize(x, [224, 224])\n        ),\n        name='efficientnet_preprocess'\n    )(inputs)\n    \n    efficientnet_base = EfficientNetB0(\n        include_top=False,\n        weights='imagenet',\n        input_tensor=efficientnet_preprocess\n    )\n    \n    if freeze_base:\n        for layer in efficientnet_base.layers:\n            layer.trainable = False\n            \n    efficientnet_features = GlobalAveragePooling2D(name='efficientnet_gap')(efficientnet_base.output)\n    efficientnet_features = Dense(128, name='efficientnet_projection')(efficientnet_features)\n    efficientnet_features = BatchNormalization()(efficientnet_features)\n    efficientnet_features = Activation('relu')(efficientnet_features)\n    \n    # === Feature Fusion ===\n    # Combine features with concatenation\n    merged_features = Concatenate(name='feature_fusion')(\n        [mobilenet_features, xception_features, efficientnet_features]\n    )\n    \n    # Classification head\n    x = Dense(256, name='fusion_dense1')(merged_features)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.5)(x)\n    \n    x = Dense(128, name='fusion_dense2')(x)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.3)(x)\n    \n    # Output layer with softmax\n    outputs = Dense(num_classes, activation='softmax', dtype='float32', name='emotion_output')(x)\n    \n    # Create model\n    model = keras.Model(inputs=inputs, outputs=outputs, name='emotion_ensemble')\n    \n    # Cosine decay learning rate\n    initial_learning_rate = 1e-3\n    lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n        initial_learning_rate, \n        decay_steps=10000  # Adjust based on epochs * steps_per_epoch\n    )\n    \n    # Optimizer with loss scaling for mixed precision\n    optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n    optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n    \n    # Compile with focal loss\n    model.compile(\n        optimizer=optimizer,\n        loss=focal_loss(gamma=2.0),  # Using focal loss instead of label smoothing\n        metrics=['accuracy']\n    )\n    \n    return model\n\n# =============================================================================\n# Evaluation function\n# =============================================================================\ndef evaluate_model(model, test_ds, steps, class_names, log_dir, dataset_name=\"\"):\n    \"\"\"\n    Evaluate model with detailed metrics and visualizations.\n    \"\"\"\n    print(f\"\\nEvaluating model on {dataset_name} test set\")\n    \n    # Get predictions\n    y_true = []\n    y_pred = []\n    \n    # Loop through test batches\n    for i, (images, labels) in enumerate(test_ds):\n        if i >= steps:\n            break\n        batch_preds = model.predict(images, verbose=0)\n        y_pred.append(np.argmax(batch_preds, axis=1))\n        y_true.append(np.argmax(labels.numpy(), axis=1))\n    \n    # Concatenate\n    y_true = np.concatenate(y_true)\n    y_pred = np.concatenate(y_pred)\n    \n    # Calculate metrics\n    test_accuracy = np.mean(y_pred == y_true)\n    f1 = f1_score(y_true, y_pred, average='weighted')\n    \n    print(f\"{dataset_name} Test Accuracy: {test_accuracy:.4f}\")\n    print(f\"{dataset_name} Weighted F1-Score: {f1:.4f}\")\n    \n    # Calculate confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Visualize confusion matrix\n    plt.figure(figsize=(12, 10))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n               xticklabels=class_names,\n               yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title(f'Confusion Matrix - {dataset_name} Test Set')\n    plt.tight_layout()\n    \n    try:\n        plt.savefig(f'{log_dir}/confusion_matrix_{dataset_name}_test.png')\n    except Exception as e:\n        print(f\"Warning: Could not save confusion matrix plot: {e}\")\n        \n    plt.close()\n    \n    # Print classification report\n    print(f\"\\n{dataset_name} Classification Report:\")\n    report = classification_report(\n        y_true, \n        y_pred, \n        target_names=class_names,\n        zero_division=0\n    )\n    print(report)\n    \n    # Save report to file\n    with open(f'{log_dir}/classification_report_{dataset_name}.txt', 'w') as f:\n        f.write(report)\n    \n    return {\n        'accuracy': test_accuracy,\n        'f1_score': f1,\n        'confusion_matrix': cm\n    }\n\n# =============================================================================\n# Progressive Training Strategy for Ensemble\n# =============================================================================\ndef train_ensemble_with_progressive_strategy(model, train_ds, val_ds, \n                                           steps_per_epoch, val_steps,\n                                           total_epochs=30,\n                                           callbacks=None,\n                                           class_weights=None):\n    \"\"\"\n    Three-stage training approach for ensemble:\n    1. Train only the fusion layers (all base models frozen)\n    2. Unfreeze and train EfficientNet and MobileNet (keep Xception frozen)\n    3. Unfreeze and fine-tune all models\n    \n    Args:\n        model: The ensemble model\n        train_ds: Training dataset\n        val_ds: Validation dataset\n        steps_per_epoch: Steps per training epoch\n        val_steps: Validation steps\n        total_epochs: Total epochs across all stages\n        callbacks: List of callbacks\n        class_weights: Class weights for handling imbalance\n        \n    Returns:\n        Training history\n    \"\"\"\n    histories = []\n    \n    # Stage 1: Train only fusion layers (10% of total epochs)\n    stage1_epochs = max(3, int(total_epochs * 0.1))\n    print(f\"\\nStage 1: Training only fusion layers ({stage1_epochs} epochs)\")\n    \n    # Ensure base models are frozen\n    for layer in model.layers:\n        if any(base_name in layer.name for base_name in ['mobilenet_base', 'xception_base', 'efficientnet_base']):\n            for base_layer in layer.layers:\n                base_layer.trainable = False\n    \n    # Train fusion layers\n    history1 = model.fit(\n        train_ds,\n        epochs=stage1_epochs,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=val_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    histories.append(history1)\n    \n    # Stage 2: Unfreeze and train EfficientNet and MobileNet (30% of total epochs)\n    stage2_epochs = max(6, int(total_epochs * 0.3))\n    print(f\"\\nStage 2: Training EfficientNet and MobileNet branches ({stage2_epochs} epochs)\")\n    \n    # Unfreeze EfficientNet and MobileNet, keep Xception frozen\n    for layer in model.layers:\n        if layer.name in ['efficientnet_base', 'mobilenet_base']:\n            for base_layer in layer.layers[-30:]:  # Unfreeze last 30 layers\n                base_layer.trainable = True\n    \n    # Recompile with lower learning rate\n    optimizer = keras.optimizers.Adam(1e-4)  # Lower learning rate\n    optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n    \n    model.compile(\n        optimizer=optimizer,\n        loss=focal_loss(gamma=2.0),\n        metrics=['accuracy']\n    )\n    \n    # Train with partial unfreezing\n    history2 = model.fit(\n        train_ds,\n        epochs=stage2_epochs,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=val_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    histories.append(history2)\n    \n    # Stage 3: Unfreeze all models and fine-tune (remaining epochs)\n    stage3_epochs = total_epochs - stage1_epochs - stage2_epochs\n    print(f\"\\nStage 3: Fine-tuning all models ({stage3_epochs} epochs)\")\n    \n    # Unfreeze all models including Xception (which is more complex)\n    for layer in model.layers:\n        if any(base_name in layer.name for base_name in ['mobilenet_base', 'xception_base', 'efficientnet_base']):\n            for base_layer in layer.layers[-50:]:  # Unfreeze more layers\n                base_layer.trainable = True\n    \n    # Recompile with even lower learning rate\n    optimizer = keras.optimizers.Adam(5e-5)  # Very low learning rate for fine-tuning\n    optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n    \n    model.compile(\n        optimizer=optimizer,\n        loss=focal_loss(gamma=2.0),\n        metrics=['accuracy']\n    )\n    \n    # Final fine-tuning\n    history3 = model.fit(\n        train_ds,\n        epochs=stage3_epochs,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=val_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    histories.append(history3)\n    \n    return histories\n\n# =============================================================================\n# Main training pipeline with ensemble\n# =============================================================================\ndef train_emotion_ensemble(data_dir):\n    \"\"\"\n    Enhanced sequential training pipeline for emotion recognition ensemble.\n    \n    Args:\n        data_dir: Path to dataset directory\n        \n    Returns:\n        Trained ensemble model and evaluation metrics\n    \"\"\"\n    print(\"Starting enhanced ensemble training for emotion recognition\")\n    \n    # 1. Load and prepare data\n    print(\"\\n1. Loading datasets\")\n    train_dir = os.path.join(data_dir, \"Train\")\n    test_dir = os.path.join(data_dir, \"Test\")\n    \n    train_df_full = build_image_df(train_dir)\n    test_df = build_image_df(test_dir)\n    \n    # Show dataset distributions\n    print(\"\\nAffectNet training distribution:\")\n    print(train_df_full[train_df_full['source'] == 'affectnet']['label'].value_counts())\n    \n    print(\"\\nFER2013 training distribution:\")\n    print(train_df_full[train_df_full['source'] == 'fer2013']['label'].value_counts())\n    \n    # 2. Split test set by dataset source\n    test_affectnet_df = test_df[test_df['source'] == 'affectnet']\n    test_fer_df = test_df[test_df['source'] == 'fer2013']\n    \n    print(f\"\\nTest sets: AffectNet={len(test_affectnet_df)}, FER2013={len(test_fer_df)}\")\n    \n    # Get classes for later use\n    classes = sorted(train_df_full[\"label\"].unique())\n    num_classes = len(classes)\n    print(f\"Classes: {classes}\")\n    \n    # 3. Create validation splits\n    # For AffectNet\n    affectnet_train_df = train_df_full[train_df_full['source'] == 'affectnet']\n    affectnet_train_df, affectnet_val_df = train_test_split(\n        affectnet_train_df, \n        test_size=0.15, \n        stratify=affectnet_train_df[\"label\"], \n        random_state=42\n    )\n    \n    # For FER2013\n    fer_train_df = train_df_full[train_df_full['source'] == 'fer2013']\n    fer_train_df, fer_val_df = train_test_split(\n        fer_train_df, \n        test_size=0.15, \n        stratify=fer_train_df[\"label\"], \n        random_state=42\n    )\n    \n    print(f\"AffectNet: {len(affectnet_train_df)} train, {len(affectnet_val_df)} validation\")\n    print(f\"FER2013: {len(fer_train_df)} train, {len(fer_val_df)} validation\")\n    \n    # 4. Create datasets with emphasis on problematic classes and caching\n    print(\"\\n2. Creating enhanced data pipelines with caching\")\n    \n    # AffectNet datasets\n    affectnet_train_ds, class_indices = create_emphasis_dataset(\n        affectnet_train_df, is_training=True, cache=True)\n    \n    affectnet_val_ds, _ = create_dataset(\n        affectnet_val_df, is_training=False, \n        dataset_type='affectnet', cache=True)\n    \n    affectnet_test_ds, _ = create_dataset(\n        test_affectnet_df, is_training=False, \n        dataset_type='affectnet', cache=True)\n    \n    # FER2013 datasets\n    fer_train_ds, _ = create_emphasis_dataset(\n        fer_train_df, is_training=True, cache=True)\n    \n    fer_val_ds, _ = create_dataset(\n        fer_val_df, is_training=False, \n        dataset_type='fer2013', cache=True)\n    \n    fer_test_ds, _ = create_dataset(\n        test_fer_df, is_training=False, \n        dataset_type='fer2013', cache=True)\n    \n    # Create combined test dataset\n    combined_test_ds, _ = create_dataset(\n        test_df, is_training=False, cache=True)\n    \n    # 5. Calculate steps with increased batch size\n    affectnet_steps_per_epoch = len(affectnet_train_df) // BATCH_SIZE\n    affectnet_val_steps = len(affectnet_val_df) // BATCH_SIZE\n    affectnet_test_steps = len(test_affectnet_df) // BATCH_SIZE\n    \n    fer_steps_per_epoch = len(fer_train_df) // BATCH_SIZE\n    fer_val_steps = len(fer_val_df) // BATCH_SIZE\n    fer_test_steps = len(test_fer_df) // BATCH_SIZE\n    \n    combined_test_steps = len(test_df) // BATCH_SIZE\n    \n    # 6. Create ensemble model\n    print(\"\\n3. Creating ensemble model architecture\")\n    ensemble_model = create_ensemble_model(num_classes=num_classes, freeze_base=True)\n    print(f\"Ensemble model created with {ensemble_model.count_params():,} parameters\")\n    \n    # 7. Compute class weights for each dataset with adjustments\n    print(\"\\n4. Computing class weights with adjustments for problematic classes\")\n    \n    # AffectNet class weights\n    affectnet_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(affectnet_train_df[\"label\"].values),\n        y=affectnet_train_df[\"label\"].values\n    )\n    affectnet_class_weights = {class_indices[label]: weight for label, weight in \n                     zip(np.unique(affectnet_train_df[\"label\"].values), affectnet_weights)}\n    \n    # FER2013 class weights\n    fer_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(fer_train_df[\"label\"].values),\n        y=fer_train_df[\"label\"].values\n    )\n    fer_class_weights = {class_indices[label]: weight for label, weight in \n                zip(np.unique(fer_train_df[\"label\"].values), fer_weights)}\n    \n    # Increase weights for problematic classes\n    for problem_class in PROBLEMATIC_CLASSES:\n        if problem_class in class_indices:\n            class_idx = class_indices[problem_class]\n            # Increase the weight by 20%\n            if class_idx in affectnet_class_weights:\n                affectnet_class_weights[class_idx] *= 1.2\n            if class_idx in fer_class_weights:\n                fer_class_weights[class_idx] *= 1.2\n    \n    print(\"Enhanced AffectNet class weights:\", affectnet_class_weights)\n    print(\"Enhanced FER2013 class weights:\", fer_class_weights)\n    \n    # 8. Setup callbacks with enhanced monitoring\n    print(\"\\n5. Setting up enhanced callbacks\")\n    \n    # Base callbacks shared across training phases\n    base_callbacks = [\n        # Early stopping\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=8,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        # TensorBoard\n        tf.keras.callbacks.TensorBoard(\n            log_dir=LOG_DIR + '/ensemble',\n            histogram_freq=1,\n            update_freq='epoch'\n        )\n    ]\n    \n    # AffectNet-specific callbacks\n    affectnet_callbacks = base_callbacks + [\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'model_checkpoints/affectnet_ensemble_best.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        ),\n        # Enhanced confusion matrix monitoring\n        EnhancedConfusionMatrixCallback(\n            affectnet_val_ds, \n            classes, \n            log_dir=LOG_DIR + '/affectnet',\n            model_name=\"AffectNet Ensemble\",\n            freq=3\n        ),\n        # CSV Logger\n        tf.keras.callbacks.CSVLogger(\n            'affectnet_ensemble_training_log.csv', \n            append=True\n        )\n    ]\n    \n    # FER2013-specific callbacks\n    fer_callbacks = base_callbacks + [\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'model_checkpoints/fer2013_ensemble_best.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        ),\n        # Enhanced confusion matrix monitoring\n        EnhancedConfusionMatrixCallback(\n            fer_val_ds, \n            classes, \n            log_dir=LOG_DIR + '/fer2013',\n            model_name=\"FER2013 Ensemble\",\n            freq=3\n        ),\n        # CSV Logger\n        tf.keras.callbacks.CSVLogger(\n            'fer2013_ensemble_training_log.csv', \n            append=True\n        )\n    ]\n    \n    # 9. STAGE 1: Train ensemble on AffectNet using progressive strategy\n    print(\"\\n6. STAGE 1: Training ensemble on AffectNet with progressive strategy\")\n    \n    affectnet_histories = train_ensemble_with_progressive_strategy(\n        ensemble_model,\n        affectnet_train_ds, affectnet_val_ds,\n        affectnet_steps_per_epoch, affectnet_val_steps,\n        total_epochs=20,  # Adjust as needed\n        callbacks=affectnet_callbacks,\n        class_weights=affectnet_class_weights\n    )\n    \n    # Save AffectNet model\n    ensemble_model.save(\"affectnet_ensemble_model.keras\")\n    print(\"AffectNet ensemble model saved to 'affectnet_ensemble_model.keras'\")\n    \n    # 10. Evaluate on AffectNet test set\n    affectnet_metrics = evaluate_model(\n        ensemble_model, \n        affectnet_test_ds, \n        affectnet_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"AffectNet\"\n    )\n    \n    # 11. STAGE 2: Fine-tune on FER2013 with progressive strategy\n    print(\"\\n7. STAGE 2: Fine-tuning ensemble on FER2013 with progressive strategy\")\n    \n    fer_histories = train_ensemble_with_progressive_strategy(\n        ensemble_model,\n        fer_train_ds, fer_val_ds,\n        fer_steps_per_epoch, fer_val_steps,\n        total_epochs=15,  # Adjust as needed\n        callbacks=fer_callbacks,\n        class_weights=fer_class_weights\n    )\n    \n    # 12. Evaluate on FER2013 test set\n    fer_metrics = evaluate_model(\n        ensemble_model, \n        fer_test_ds, \n        fer_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"FER2013\"\n    )\n    \n    # 13. Evaluate on combined test set\n    combined_metrics = evaluate_model(\n        ensemble_model, \n        combined_test_ds, \n        combined_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"Combined\"\n    )\n    \n    # 14. Save the final model\n    ensemble_model.save(\"final_emotion_ensemble.keras\")\n    print(\"Final ensemble model saved to 'final_emotion_ensemble.keras'\")\n    \n    # Return model and metrics\n    return ensemble_model, {\n        'affectnet': affectnet_metrics,\n        'fer2013': fer_metrics,\n        'combined': combined_metrics\n    }\n\n# =============================================================================\n# Main entry point\n# =============================================================================\nif __name__ == \"__main__\":\n    # Set data directory path\n    data_dir = \"/kaggle/input/custom-fer2013affectnet/Custom_ferAffect2013net\"\n    \n    # Train ensemble model with all improvements\n    model, metrics = train_emotion_ensemble(data_dir)\n    \n    # Print final results\n    print(\"\\n=== FINAL RESULTS ===\")\n    print(f\"AffectNet Test Accuracy: {metrics['affectnet']['accuracy']:.4f}\")\n    print(f\"AffectNet F1 Score: {metrics['affectnet']['f1_score']:.4f}\")\n    print(f\"FER2013 Test Accuracy: {metrics['fer2013']['accuracy']:.4f}\")\n    print(f\"FER2013 F1 Score: {metrics['fer2013']['f1_score']:.4f}\")\n    print(f\"Combined Test Accuracy: {metrics['combined']['accuracy']:.4f}\")\n    print(f\"Combined F1 Score: {metrics['combined']['f1_score']:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Version 6o current accuracy\n#=== FINAL RESULTS === 96x96\n#AffectNet Test Accuracy: 0.4461\n#AffectNet F1 Score: 0.4446\n#FER2013 Test Accuracy: 0.2203\n#FER2013 F1 Score: 0.1875\n#Combined Test Accuracy: 0.3168\n#Combined F1 Score: 0.3050\n\n#=== FINAL RESULTS === 224x224 \n#AffectNet Test Accuracy: 0.4669\n#AffectNet F1 Score: 0.4799\n#FER2013 Test Accuracy: 0.2953\n#FER2013 F1 Score: 0.2474\n#Combined Test Accuracy: 0.3050\n#Combined F1 Score: 0.2910\n\n#=== FINAL RESULTS === 112x112\n#AffectNet Test Accuracy: 0.4738\n#AffectNet F1 Score: 0.4748\n#FER2013 Test Accuracy: 0.3175\n#FER2013 F1 Score: 0.3021\n#Combined Test Accuracy: 0.3431\n#Combined F1 Score: 0.3168\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom tensorflow.keras.applications import MobileNetV2\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\n\n# =============================================================================\n# Configure GPU and enable mixed precision\n# =============================================================================\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(f\"Found {len(gpus)} GPUs: Memory growth enabled\")\n    except RuntimeError as e:\n        print(f\"GPU error: {e}\")\n\n# Enable mixed precision training\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled\")\n\n# =============================================================================\n# Key parameters\n# =============================================================================\nIMG_SIZE = 112  # 96 48 112 224\nBATCH_SIZE = 32\nAUTOTUNE = tf.data.AUTOTUNE\nLOG_DIR = \"./emotion_logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\n# Create all required directories\ndef ensure_dir(directory):\n    \"\"\"Make sure a directory exists, creating it if necessary\"\"\"\n    if not os.path.exists(directory):\n        os.makedirs(directory, exist_ok=True)\n\n# Create main log directories\nensure_dir(LOG_DIR)\nensure_dir(LOG_DIR + '/affectnet')\nensure_dir(LOG_DIR + '/fer2013')\nensure_dir(LOG_DIR + '/combined')\nensure_dir(\"./model_checkpoints\")\n\n# Define problematic classes for targeted augmentation\nPROBLEMATIC_CLASSES = ['surprise', 'sad', 'disgust']\n\n# =============================================================================\n# Custom Label Smoothing Loss\n# =============================================================================\ndef label_smoothing_loss(epsilon=0.1):\n    \"\"\"\n    Cross entropy loss with label smoothing to prevent model from being too confident.\n    \n    Args:\n        epsilon: Smoothing factor (0 = no smoothing, 1 = complete smoothing)\n        \n    Returns:\n        Loss function\n    \"\"\"\n    def loss_fn(y_true, y_pred):\n        num_classes = tf.cast(tf.shape(y_true)[-1], tf.float32)\n        \n        # Apply label smoothing\n        y_true = y_true * (1.0 - epsilon) + (epsilon / num_classes)\n        \n        # Calculate cross entropy with extra small epsilon to prevent log(0)\n        return -tf.reduce_sum(y_true * tf.math.log(y_pred + 1e-7), axis=-1)\n    \n    return loss_fn\n\n# =============================================================================\n# Build DataFrame from dataset directory structure\n# =============================================================================\ndef build_image_df(root_dir, subfolders=[\"fer2013\", \"affectnet\"]):\n    \"\"\"\n    Scans the directory and returns a DataFrame with file paths and labels.\n    \"\"\"\n    data = []\n    emotions = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n    \n    print(f\"Found {len(emotions)} emotion categories: {emotions}\")\n    \n    for emotion in emotions:\n        emotion_path = os.path.join(root_dir, emotion)\n        for sub in subfolders:\n            sub_path = os.path.join(emotion_path, sub)\n            if os.path.exists(sub_path):\n                img_files = [f for f in os.listdir(sub_path) \n                            if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n                \n                print(f\"Found {len(img_files)} images in {emotion}/{sub}\")\n                \n                for img_file in img_files:\n                    data.append({\n                        \"filepath\": os.path.join(sub_path, img_file),\n                        \"label\": emotion,\n                        \"source\": sub\n                    })\n    \n    df = pd.DataFrame(data)\n    print(f\"Total images: {len(df)}\")\n    return df\n\n# =============================================================================\n# Fixed graph-compatible preprocessing function\n# =============================================================================\ndef preprocess_image(file_path, label, source, training=True):\n    \"\"\"\n    Fixed graph-compatible preprocessing with class-specific augmentation.\n    \n    Args:\n        file_path: Path to the image file\n        label: Emotion label (as index)\n        source: Dataset source ('fer2013' or 'affectnet')\n        training: Whether to apply augmentation\n        \n    Returns:\n        Preprocessed image and one-hot encoded label\n    \"\"\"\n    # Read the file\n    img = tf.io.read_file(file_path)\n    \n    # Decode image with proper error handling\n    def decode_image():\n        try:\n            decoded = tf.image.decode_image(img, channels=3, expand_animations=False)\n            decoded = tf.ensure_shape(decoded, [None, None, 3])\n            return decoded\n        except:\n            # Return blank image if decoding fails\n            return tf.zeros([IMG_SIZE, IMG_SIZE, 3], dtype=tf.uint8)\n    \n    img = decode_image()\n    \n    # Resize to target size\n    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE], method='bilinear')\n    \n    # Normalize pixel values using MobileNet standard preprocessing\n    img = tf.cast(img, tf.float32)\n    img = img / 127.5 - 1.0  # Scale to [-1, 1]\n    \n    # Apply basic augmentation during training\n    if training:\n        # Random flip - works in graph mode\n        img = tf.image.random_flip_left_right(img)\n        \n        # Basic brightness and contrast\n        img = tf.image.random_brightness(img, 0.2)\n        img = tf.image.random_contrast(img, 0.8, 1.2)\n            \n        # Add random noise to improve robustness\n        noise = tf.random.normal(shape=tf.shape(img), mean=0.0, stddev=0.01)\n        img = img + noise\n        \n        # Ensure values stay in valid range\n        img = tf.clip_by_value(img, -1.0, 1.0)\n    \n    # One-hot encode label\n    label = tf.one_hot(label, depth=8)  # 8 emotion classes\n    \n    return img, label\n\n# =============================================================================\n# Fixed dataset creation function\n# =============================================================================\ndef create_dataset(dataframe, is_training=True, dataset_type=None):\n    \"\"\"\n    Creates a tf.data.Dataset with fixed preprocessing.\n    \n    Args:\n        dataframe: DataFrame with filepath, label, and source columns\n        is_training: Whether this is for training (includes augmentation)\n        dataset_type: Optional filter for specific dataset ('affectnet' or 'fer2013')\n        \n    Returns:\n        tf.data.Dataset and class mapping\n    \"\"\"\n    # Optionally filter to specific dataset\n    if dataset_type is not None:\n        dataframe = dataframe[dataframe['source'] == dataset_type].reset_index(drop=True)\n        print(f\"Filtered to {len(dataframe)} {dataset_type} images\")\n    \n    # Create class indices\n    class_indices = {cls: i for i, cls in enumerate(sorted(dataframe[\"label\"].unique()))}\n    labels = [class_indices[label] for label in dataframe[\"label\"]]\n    \n    # Create dataset\n    ds = tf.data.Dataset.from_tensor_slices((\n        dataframe[\"filepath\"].values,\n        labels,\n        dataframe[\"source\"].values\n    ))\n    \n    # Apply preprocessing with training flag\n    training_value = tf.constant(is_training)\n    ds = ds.map(\n        lambda path, label, source: preprocess_image(path, label, source, training=training_value),\n        num_parallel_calls=AUTOTUNE\n    )\n    \n    if is_training:\n        # Training pipeline\n        ds = ds.shuffle(buffer_size=min(10000, len(dataframe)))\n        \n    # Repeat dataset for multiple epochs\n    ds = ds.repeat()\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(AUTOTUNE)\n    \n    return ds, class_indices\n\n# =============================================================================\n# Create balanced dataset with emphasis classes\n# =============================================================================\ndef create_emphasis_dataset(dataframe, is_training=True, emphasis_classes=PROBLEMATIC_CLASSES):\n    \"\"\"\n    Creates a balanced dataset with emphasis on problematic classes.\n    \n    Args:\n        dataframe: Input DataFrame\n        is_training: Whether to apply training augmentations\n        emphasis_classes: List of classes to emphasize (oversample)\n        \n    Returns:\n        Balanced tf.data.Dataset with emphasis on specified classes\n    \"\"\"\n    balanced_data = []\n    \n    # Sample from each class with emphasis on problematic ones\n    for class_name in sorted(dataframe[\"label\"].unique()):\n        class_df = dataframe[dataframe[\"label\"] == class_name]\n        samples_per_class = 400  # Base sampling\n        \n        # Increase samples for emphasis classes\n        if class_name in emphasis_classes:\n            samples_per_class = 600  # 50% more samples for problematic classes\n            \n        # Sample with replacement if needed\n        if len(class_df) <= samples_per_class:\n            sampled = class_df.sample(n=samples_per_class, replace=True)\n        else:\n            sampled = class_df.sample(n=samples_per_class, replace=False)\n            \n        balanced_data.append(sampled)\n    \n    # Combine all balanced samples\n    balanced_df = pd.concat(balanced_data, ignore_index=True)\n    print(f\"Created balanced dataset with {len(balanced_df)} samples (with emphasis on {emphasis_classes})\")\n    \n    # Create dataset\n    return create_dataset(balanced_df, is_training=is_training)\n\n# =============================================================================\n# Enhanced Confusion Matrix Callback with Class-Specific Monitoring\n# =============================================================================\nclass EnhancedConfusionMatrixCallback(tf.keras.callbacks.Callback):\n    \"\"\"\n    Enhanced callback to monitor class-specific metrics during training.\n    \"\"\"\n    def __init__(self, validation_data, class_names, log_dir, model_name=\"model\", freq=5):\n        super(EnhancedConfusionMatrixCallback, self).__init__()\n        self.validation_data = validation_data\n        self.class_names = class_names\n        self.freq = freq\n        self.log_dir = log_dir\n        self.model_name = model_name\n        self.zero_prediction_classes = set()  # Track classes with zero predictions\n        self.class_metrics_history = {cls: [] for cls in class_names}  # Track per-class metrics\n        \n        # Ensure log directory exists\n        ensure_dir(self.log_dir)\n        \n    def on_epoch_end(self, epoch, logs=None):\n        # Calculate and log class-specific metrics every epoch\n        val_steps = 30  # Limit computation\n        y_true = []\n        y_pred = []\n        \n        # Get predictions for validation data\n        for i, (images, labels) in enumerate(self.validation_data):\n            if i >= val_steps:\n                break\n            batch_preds = self.model.predict(images, verbose=0)\n            y_pred.append(np.argmax(batch_preds, axis=1))\n            y_true.append(np.argmax(labels.numpy(), axis=1))\n        \n        # Flatten the lists\n        y_true = np.concatenate(y_true)\n        y_pred = np.concatenate(y_pred)\n        \n        # Calculate confusion matrix\n        cm = confusion_matrix(y_true, y_pred)\n        \n        # Calculate per-class metrics\n        class_accuracies = np.zeros(len(self.class_names))\n        for i in range(len(self.class_names)):\n            if np.sum(y_true == i) > 0:  # Avoid division by zero\n                class_accuracies[i] = cm[i, i] / np.sum(y_true == i)\n                \n            # Track metrics history\n            self.class_metrics_history[self.class_names[i]].append(class_accuracies[i])\n        \n        # Check for classes with zero predictions\n        zero_pred_classes = []\n        for i, class_name in enumerate(self.class_names):\n            if np.sum(cm[:, i]) == 0:\n                zero_pred_classes.append(class_name)\n                self.zero_prediction_classes.add(class_name)\n        \n        # Log warnings for zero prediction classes\n        if zero_pred_classes:\n            warning_msg = f\"\\n⚠️ WARNING: Zero predictions for classes: {', '.join(zero_pred_classes)}\"\n            print(warning_msg)\n            \n            # Save warning to log file\n            with open(f\"{self.log_dir}/warnings.txt\", \"a\") as f:\n                f.write(f\"Epoch {epoch+1}: {warning_msg}\\n\")\n        \n        # Save visualizations and detailed reports on the specified frequency\n        if (epoch + 1) % self.freq == 0:\n            # Print confusion matrix\n            print(\"\\nConfusion Matrix:\")\n            print(cm)\n            \n            # Print per-class accuracy\n            for i, (name, acc) in enumerate(zip(self.class_names, class_accuracies)):\n                print(f\"{name}: {acc:.4f}\", end=\"  \")\n                if (i + 1) % 4 == 0:\n                    print()  # New line for readability\n            print(\"\\n\")\n            \n            # Print class accuracy trends instead of plotting them\n            print(\"Class Accuracy Trends:\")\n            for class_name in self.class_names:\n                history = self.class_metrics_history[class_name]\n                trend = \", \".join([f\"{acc:.4f}\" for acc in history[-5:]])  # Show last 5 epochs\n                print(f\"{class_name}: [{trend}]\")\n            print()\n            \n            # Save confusion matrix visualization (still useful)\n            plt.figure(figsize=(10, 8))\n            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                       xticklabels=self.class_names,\n                       yticklabels=self.class_names)\n            plt.xlabel('Predicted')\n            plt.ylabel('True')\n            plt.title(f'Confusion Matrix - {self.model_name} - Epoch {epoch+1}')\n            plt.tight_layout()\n            \n            try:\n                plt.savefig(f'{self.log_dir}/confusion_matrix_epoch_{epoch+1}.png')\n            except Exception as e:\n                print(f\"Warning: Could not save confusion matrix plot: {e}\")\n            \n            plt.close()\n\n# =============================================================================\n# Create emotion recognition model with additional MLP head\n# =============================================================================\ndef create_emotion_model(num_classes):\n    \"\"\"\n    Create a facial emotion recognition model with enhanced classification head.\n    \n    Args:\n        num_classes: Number of emotion classes\n        \n    Returns:\n        Compiled Keras model and base model\n    \"\"\"\n    # Input shape\n    input_shape = (IMG_SIZE, IMG_SIZE, 3)\n    \n    # Create input layer\n    inputs = keras.layers.Input(shape=input_shape)\n    \n    # Use MobileNetV2 as base\n    base_model = MobileNetV2(\n        include_top=False,\n        weights='imagenet',\n        input_tensor=inputs,\n        alpha=1.0  # Controls model width\n    )\n    print(\"Using MobileNetV2 base model\")\n    \n    # Freeze base model layers\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    # Add custom head with dropout and batch normalization\n    x = base_model.output\n    x = keras.layers.GlobalAveragePooling2D()(x)\n    \n    # First dense block\n    x = keras.layers.Dense(256)(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.Dropout(0.4)(x)\n    \n    # Second dense block\n    x = keras.layers.Dense(128)(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.Dropout(0.3)(x)\n    \n    # Output layer with label smoothing\n    outputs = keras.layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n    \n    # Create model\n    model = keras.Model(inputs=inputs, outputs=outputs)\n    \n    # Compile with label smoothing loss\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n        loss=label_smoothing_loss(epsilon=0.1),\n        metrics=['accuracy']\n    )\n    \n    return model, base_model\n\n# =============================================================================\n# Evaluation function\n# =============================================================================\ndef evaluate_model(model, test_ds, steps, class_names, log_dir, dataset_name=\"\"):\n    \"\"\"\n    Evaluate model with detailed metrics and visualizations.\n    \"\"\"\n    print(f\"\\nEvaluating model on {dataset_name} test set\")\n    \n    # Get predictions\n    y_true = []\n    y_pred = []\n    \n    # Loop through test batches\n    for i, (images, labels) in enumerate(test_ds):\n        if i >= steps:\n            break\n        batch_preds = model.predict(images, verbose=0)\n        y_pred.append(np.argmax(batch_preds, axis=1))\n        y_true.append(np.argmax(labels.numpy(), axis=1))\n    \n    # Concatenate\n    y_true = np.concatenate(y_true)\n    y_pred = np.concatenate(y_pred)\n    \n    # Calculate metrics\n    test_accuracy = np.mean(y_pred == y_true)\n    f1 = f1_score(y_true, y_pred, average='weighted')\n    \n    print(f\"{dataset_name} Test Accuracy: {test_accuracy:.4f}\")\n    print(f\"{dataset_name} Weighted F1-Score: {f1:.4f}\")\n    \n    # Calculate confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Visualize confusion matrix\n    plt.figure(figsize=(12, 10))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n               xticklabels=class_names,\n               yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title(f'Confusion Matrix - {dataset_name} Test Set')\n    plt.tight_layout()\n    \n    try:\n        plt.savefig(f'{log_dir}/confusion_matrix_{dataset_name}_test.png')\n    except Exception as e:\n        print(f\"Warning: Could not save confusion matrix plot: {e}\")\n        \n    plt.close()\n    \n    # Print classification report\n    print(f\"\\n{dataset_name} Classification Report:\")\n    report = classification_report(\n        y_true, \n        y_pred, \n        target_names=class_names,\n        zero_division=0\n    )\n    print(report)\n    \n    # Save report to file\n    with open(f'{log_dir}/classification_report_{dataset_name}.txt', 'w') as f:\n        f.write(report)\n    \n    return {\n        'accuracy': test_accuracy,\n        'f1_score': f1,\n        'confusion_matrix': cm\n    }\n\n# =============================================================================\n# Two-Stage Fine-Tuning with Progressive Unfreezing\n# =============================================================================\ndef train_with_progressive_unfreezing(model, base_model, train_ds, val_ds, \n                                    steps_per_epoch, val_steps, \n                                    epochs_head=10, epochs_finetune=20,\n                                    callbacks=None, class_weights=None):\n    \"\"\"\n    Two-stage training approach: first train only the head, then progressively unfreeze layers.\n    \n    Args:\n        model: The model to train\n        base_model: The base model part (for unfreezing)\n        train_ds: Training dataset\n        val_ds: Validation dataset\n        steps_per_epoch: Steps per training epoch\n        val_steps: Validation steps\n        epochs_head: Epochs for head-only training\n        epochs_finetune: Epochs for fine-tuning\n        callbacks: List of callbacks\n        class_weights: Class weights for handling imbalance\n        \n    Returns:\n        Training history\n    \"\"\"\n    print(f\"\\nStage 1: Training only the classification head ({epochs_head} epochs)\")\n    \n    # Ensure base model is frozen\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    # Compile with higher learning rate for head training\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n        loss=label_smoothing_loss(epsilon=0.1),\n        metrics=['accuracy']\n    )\n    \n    # Train head only\n    history_head = model.fit(\n        train_ds,\n        epochs=epochs_head,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=val_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    \n    print(f\"\\nStage 2: Fine-tuning with progressive unfreezing ({epochs_finetune} epochs)\")\n    \n    # Progressively unfreeze layers in groups\n    fine_tuning_history = []\n    \n    # Groups of layers to unfreeze (from last to first)\n    layer_groups = [\n        # Unfreeze last layers first (deeper = more specific features)\n        base_model.layers[-15:],  # Last block\n        base_model.layers[-30:-15],  # Second-to-last block\n        base_model.layers[-50:-30]   # Third-to-last block\n    ]\n    \n    for i, group in enumerate(layer_groups):\n        print(f\"\\nUnfreezing group {i+1}/{len(layer_groups)} ({len(group)} layers)\")\n        \n        # Unfreeze current group\n        for layer in group:\n            layer.trainable = True\n            \n        # Recompile with lower learning rate as we go deeper\n        lr = 1e-4 / (i + 1)  # Decrease learning rate for deeper layers\n        \n        model.compile(\n            optimizer=keras.optimizers.Adam(learning_rate=lr),\n            loss=label_smoothing_loss(epsilon=0.1),\n            metrics=['accuracy']\n        )\n        \n        # Train for a few epochs\n        epochs_per_group = max(5, epochs_finetune // len(layer_groups))\n        \n        history = model.fit(\n            train_ds,\n            epochs=epochs_per_group,\n            steps_per_epoch=steps_per_epoch,\n            validation_data=val_ds,\n            validation_steps=val_steps,\n            callbacks=callbacks,\n            class_weight=class_weights,\n            verbose=1\n        )\n        \n        fine_tuning_history.append(history)\n    \n    # Return combined history\n    return history_head, fine_tuning_history\n\n# =============================================================================\n# Sequential Training Pipeline\n# =============================================================================\ndef train_enhanced_emotion_model(data_dir):\n    \"\"\"\n    Enhanced sequential training with all improvements.\n    \n    Args:\n        data_dir: Path to dataset directory\n        \n    Returns:\n        Trained model and evaluation metrics\n    \"\"\"\n    print(\"Starting enhanced sequential emotion recognition training\")\n    \n    # 1. Load and prepare data\n    print(\"\\n1. Loading datasets\")\n    train_dir = os.path.join(data_dir, \"Train\")\n    test_dir = os.path.join(data_dir, \"Test\")\n    \n    train_df_full = build_image_df(train_dir)\n    test_df = build_image_df(test_dir)\n    \n    # Show dataset distributions\n    print(\"\\nAffectNet training distribution:\")\n    print(train_df_full[train_df_full['source'] == 'affectnet']['label'].value_counts())\n    \n    print(\"\\nFER2013 training distribution:\")\n    print(train_df_full[train_df_full['source'] == 'fer2013']['label'].value_counts())\n    \n    # 2. Split test set by dataset source\n    test_affectnet_df = test_df[test_df['source'] == 'affectnet']\n    test_fer_df = test_df[test_df['source'] == 'fer2013']\n    \n    print(f\"\\nTest sets: AffectNet={len(test_affectnet_df)}, FER2013={len(test_fer_df)}\")\n    \n    # Get classes for later use\n    classes = sorted(train_df_full[\"label\"].unique())\n    num_classes = len(classes)\n    print(f\"Classes: {classes}\")\n    \n    # 3. Create validation splits\n    # For AffectNet\n    affectnet_train_df = train_df_full[train_df_full['source'] == 'affectnet']\n    affectnet_train_df, affectnet_val_df = train_test_split(\n        affectnet_train_df, \n        test_size=0.15, \n        stratify=affectnet_train_df[\"label\"], \n        random_state=42\n    )\n    \n    # For FER2013\n    fer_train_df = train_df_full[train_df_full['source'] == 'fer2013']\n    fer_train_df, fer_val_df = train_test_split(\n        fer_train_df, \n        test_size=0.15, \n        stratify=fer_train_df[\"label\"], \n        random_state=42\n    )\n    \n    print(f\"AffectNet: {len(affectnet_train_df)} train, {len(affectnet_val_df)} validation\")\n    print(f\"FER2013: {len(fer_train_df)} train, {len(fer_val_df)} validation\")\n    \n    # 4. Create datasets with emphasis on problematic classes\n    print(\"\\n2. Creating enhanced data pipelines\")\n    \n    # AffectNet datasets\n    affectnet_train_ds, class_indices = create_emphasis_dataset(\n        affectnet_train_df, is_training=True)\n    \n    affectnet_val_ds, _ = create_dataset(\n        affectnet_val_df, is_training=False, \n        dataset_type='affectnet')\n    \n    affectnet_test_ds, _ = create_dataset(\n        test_affectnet_df, is_training=False, \n        dataset_type='affectnet')\n    \n    # FER2013 datasets\n    fer_train_ds, _ = create_emphasis_dataset(\n        fer_train_df, is_training=True)\n    \n    fer_val_ds, _ = create_dataset(\n        fer_val_df, is_training=False, \n        dataset_type='fer2013')\n    \n    fer_test_ds, _ = create_dataset(\n        test_fer_df, is_training=False, \n        dataset_type='fer2013')\n    \n    # Create combined test dataset\n    combined_test_ds, _ = create_dataset(\n        test_df, is_training=False)\n    \n    # 5. Calculate steps\n    affectnet_steps_per_epoch = len(affectnet_train_df) // BATCH_SIZE\n    affectnet_val_steps = len(affectnet_val_df) // BATCH_SIZE\n    affectnet_test_steps = len(test_affectnet_df) // BATCH_SIZE\n    \n    fer_steps_per_epoch = len(fer_train_df) // BATCH_SIZE\n    fer_val_steps = len(fer_val_df) // BATCH_SIZE\n    fer_test_steps = len(test_fer_df) // BATCH_SIZE\n    \n    combined_test_steps = len(test_df) // BATCH_SIZE\n    \n    # 6. Create enhanced model\n    print(\"\\n3. Creating enhanced model\")\n    model, base_model = create_emotion_model(num_classes)\n    \n    # 7. Compute class weights for each dataset with adjustments\n    print(\"\\n4. Computing class weights with adjustments for problematic classes\")\n    \n    # AffectNet class weights\n    affectnet_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(affectnet_train_df[\"label\"]),\n        y=affectnet_train_df[\"label\"]\n    )\n    affectnet_class_weights = {class_indices[label]: weight for label, weight in \n                     zip(np.unique(affectnet_train_df[\"label\"]), affectnet_weights)}\n    \n    # FER2013 class weights\n    fer_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(fer_train_df[\"label\"]),\n        y=fer_train_df[\"label\"]\n    )\n    fer_class_weights = {class_indices[label]: weight for label, weight in \n                zip(np.unique(fer_train_df[\"label\"]), fer_weights)}\n    \n    # Increase weights for problematic classes\n    for problem_class in PROBLEMATIC_CLASSES:\n        if problem_class in class_indices:\n            class_idx = class_indices[problem_class]\n            # Increase the weight by 20%\n            if class_idx in affectnet_class_weights:\n                affectnet_class_weights[class_idx] *= 1.2\n            if class_idx in fer_class_weights:\n                fer_class_weights[class_idx] *= 1.2\n    \n    print(\"Enhanced AffectNet class weights:\", affectnet_class_weights)\n    print(\"Enhanced FER2013 class weights:\", fer_class_weights)\n    \n    # 8. Setup callbacks with enhanced monitoring\n    print(\"\\n5. Setting up enhanced callbacks\")\n    \n    # Base callbacks shared across training phases\n    base_callbacks = [\n        # Early stopping\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=10,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        # Learning rate scheduler\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.5,\n            patience=5,\n            min_lr=1e-6,\n            verbose=1\n        ),\n        # TensorBoard\n        tf.keras.callbacks.TensorBoard(\n            log_dir=LOG_DIR,\n            histogram_freq=1,\n            update_freq='epoch'\n        )\n    ]\n    \n    # AffectNet-specific callbacks\n    affectnet_callbacks = base_callbacks + [\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'model_checkpoints/affectnet_best.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        ),\n        # Enhanced confusion matrix monitoring\n        EnhancedConfusionMatrixCallback(\n            affectnet_val_ds, \n            classes, \n            log_dir=LOG_DIR + '/affectnet',\n            model_name=\"AffectNet\",\n            freq=3\n        ),\n        # CSV Logger\n        tf.keras.callbacks.CSVLogger(\n            'affectnet_training_log.csv', \n            append=True\n        )\n    ]\n    \n    # FER2013-specific callbacks\n    fer_callbacks = base_callbacks + [\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'model_checkpoints/fer2013_best.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        ),\n        # Enhanced confusion matrix monitoring\n        EnhancedConfusionMatrixCallback(\n            fer_val_ds, \n            classes, \n            log_dir=LOG_DIR + '/fer2013',\n            model_name=\"FER2013\",\n            freq=3\n        ),\n        # CSV Logger\n        tf.keras.callbacks.CSVLogger(\n            'fer2013_training_log.csv', \n            append=True\n        )\n    ]\n    \n    # 9. STAGE 1: Train on AffectNet using progressive unfreezing\n    print(\"\\n6. STAGE 1: Training on AffectNet with progressive unfreezing\")\n    \n    history_affectnet_head, history_affectnet_finetune = train_with_progressive_unfreezing(\n        model, base_model,\n        affectnet_train_ds, affectnet_val_ds,\n        affectnet_steps_per_epoch, affectnet_val_steps,\n        epochs_head=10, epochs_finetune=15,\n        callbacks=affectnet_callbacks,\n        class_weights=affectnet_class_weights\n    )\n    \n    # Save AffectNet model\n    model.save(\"affectnet_model.keras\")\n    print(\"AffectNet model saved to 'affectnet_model.keras'\")\n    \n    # 10. Evaluate on AffectNet test set\n    affectnet_metrics = evaluate_model(\n        model, \n        affectnet_test_ds, \n        affectnet_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"AffectNet\"\n    )\n    \n    # 11. STAGE 2: Fine-tune on FER2013 with progressive unfreezing\n    print(\"\\n7. STAGE 2: Fine-tuning on FER2013 with progressive unfreezing\")\n    \n    history_fer_head, history_fer_finetune = train_with_progressive_unfreezing(\n        model, base_model,\n        fer_train_ds, fer_val_ds,\n        fer_steps_per_epoch, fer_val_steps,\n        epochs_head=8, epochs_finetune=12,\n        callbacks=fer_callbacks,\n        class_weights=fer_class_weights\n    )\n    \n    # 12. Evaluate on FER2013 test set\n    fer_metrics = evaluate_model(\n        model, \n        fer_test_ds, \n        fer_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"FER2013\"\n    )\n    \n    # 13. Evaluate on combined test set\n    combined_metrics = evaluate_model(\n        model, \n        combined_test_ds, \n        combined_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"Combined\"\n    )\n    \n    # 14. Save the final model\n    model.save(\"final_enhanced_emotion_model.keras\")\n    print(\"Final model saved to 'final_enhanced_emotion_model.keras'\")\n    \n    # Return models and metrics\n    return model, {\n        'affectnet': affectnet_metrics,\n        'fer2013': fer_metrics,\n        'combined': combined_metrics\n    }\n\n# =============================================================================\n# Main entry point\n# =============================================================================\nif __name__ == \"__main__\":\n    # Set data directory path\n    data_dir = \"/kaggle/input/custom-fer2013affectnet/Custom_ferAffect2013net\"\n    \n    # Train model with all improvements\n    model, metrics = train_enhanced_emotion_model(data_dir)\n    \n    # Print final results\n    print(\"\\n=== FINAL RESULTS ===\")\n    print(f\"AffectNet Test Accuracy: {metrics['affectnet']['accuracy']:.4f}\")\n    print(f\"AffectNet F1 Score: {metrics['affectnet']['f1_score']:.4f}\")\n    print(f\"FER2013 Test Accuracy: {metrics['fer2013']['accuracy']:.4f}\")\n    print(f\"FER2013 F1 Score: {metrics['fer2013']['f1_score']:.4f}\")\n    print(f\"Combined Test Accuracy: {metrics['combined']['accuracy']:.4f}\")\n    print(f\"Combined F1 Score: {metrics['combined']['f1_score']:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Version 6v accuracy 0.2294\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom tensorflow.keras.applications import MobileNetV2\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\n\n# =============================================================================\n# Configure GPU and enable mixed precision\n# =============================================================================\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(f\"Found {len(gpus)} GPUs: Memory growth enabled\")\n    except RuntimeError as e:\n        print(f\"GPU error: {e}\")\n\n# Enable mixed precision training\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled\")\n\n# =============================================================================\n# Key parameters\n# =============================================================================\nIMG_SIZE = 96  # Keep at 96x96 as specified\nBATCH_SIZE = 128\nAUTOTUNE = tf.data.AUTOTUNE\nLOG_DIR = \"./emotion_logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\n# Create all required directories\ndef ensure_dir(directory):\n    \"\"\"Make sure a directory exists, creating it if necessary\"\"\"\n    if not os.path.exists(directory):\n        os.makedirs(directory, exist_ok=True)\n\n# Create main log directories\nensure_dir(LOG_DIR)\nensure_dir(LOG_DIR + '/affectnet')\nensure_dir(LOG_DIR + '/fer2013')\nensure_dir(LOG_DIR + '/combined')\nensure_dir(\"./model_checkpoints\")\n\n# Define problematic classes for targeted augmentation\nPROBLEMATIC_CLASSES = ['surprise', 'sad', 'disgust']\n\n# =============================================================================\n# Custom Label Smoothing Loss\n# =============================================================================\ndef label_smoothing_loss(epsilon=0.1):\n    \"\"\"\n    Cross entropy loss with label smoothing to prevent model from being too confident.\n    \n    Args:\n        epsilon: Smoothing factor (0 = no smoothing, 1 = complete smoothing)\n        \n    Returns:\n        Loss function\n    \"\"\"\n    def loss_fn(y_true, y_pred):\n        num_classes = tf.cast(tf.shape(y_true)[-1], tf.float32)\n        \n        # Apply label smoothing\n        y_true = y_true * (1.0 - epsilon) + (epsilon / num_classes)\n        \n        # Calculate cross entropy with extra small epsilon to prevent log(0)\n        return -tf.reduce_sum(y_true * tf.math.log(y_pred + 1e-7), axis=-1)\n    \n    return loss_fn\n\n# =============================================================================\n# Build DataFrame from dataset directory structure\n# =============================================================================\ndef build_image_df(root_dir, subfolders=[\"fer2013\", \"affectnet\"]):\n    \"\"\"\n    Scans the directory and returns a DataFrame with file paths and labels.\n    \"\"\"\n    data = []\n    emotions = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n    \n    print(f\"Found {len(emotions)} emotion categories: {emotions}\")\n    \n    for emotion in emotions:\n        emotion_path = os.path.join(root_dir, emotion)\n        for sub in subfolders:\n            sub_path = os.path.join(emotion_path, sub)\n            if os.path.exists(sub_path):\n                img_files = [f for f in os.listdir(sub_path) \n                            if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n                \n                print(f\"Found {len(img_files)} images in {emotion}/{sub}\")\n                \n                for img_file in img_files:\n                    data.append({\n                        \"filepath\": os.path.join(sub_path, img_file),\n                        \"label\": emotion,\n                        \"source\": sub\n                    })\n    \n    df = pd.DataFrame(data)\n    print(f\"Total images: {len(df)}\")\n    return df\n\n# =============================================================================\n# Fixed graph-compatible preprocessing function with stronger augmentation\n# =============================================================================\ndef preprocess_image(file_path, label, source, training=True):\n    \"\"\"\n    Fixed graph-compatible preprocessing with stronger augmentation.\n    \n    Args:\n        file_path: Path to the image file\n        label: Emotion label (as index)\n        source: Dataset source ('fer2013' or 'affectnet')\n        training: Whether to apply augmentation\n        \n    Returns:\n        Preprocessed image and one-hot encoded label\n    \"\"\"\n    # Read the file\n    img = tf.io.read_file(file_path)\n    \n    # Decode image with proper error handling\n    def decode_image():\n        try:\n            decoded = tf.image.decode_image(img, channels=3, expand_animations=False)\n            decoded = tf.ensure_shape(decoded, [None, None, 3])\n            return decoded\n        except:\n            # Return blank image if decoding fails\n            return tf.zeros([IMG_SIZE, IMG_SIZE, 3], dtype=tf.uint8)\n    \n    img = decode_image()\n    \n    # Resize to target size\n    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE], method='bilinear')\n    \n    # Normalize pixel values using MobileNet standard preprocessing\n    img = tf.cast(img, tf.float32)\n    img = img / 127.5 - 1.0  # Scale to [-1, 1]\n    \n    # Apply enhanced augmentation during training\n    if training:\n        # Random flip - works in graph mode\n        img = tf.image.random_flip_left_right(img)\n        \n        # Enhanced brightness and contrast (stronger than before)\n        img = tf.image.random_brightness(img, 0.3)  # Increased from 0.2\n        img = tf.image.random_contrast(img, 0.7, 1.3)  # Increased range\n        \n        # Add saturation variation\n        img = tf.image.random_saturation(img, 0.8, 1.5)\n        \n        # Apply random crop and resize for shape variation\n        # This simulates zoom/scale augmentation\n        crop_size = tf.random.uniform([], 0.8, 1.0, dtype=tf.float32)\n        scaled_size = tf.cast(tf.cast(tf.shape(img)[:2], tf.float32) * crop_size, tf.int32)\n        img = tf.image.random_crop(img, [scaled_size[0], scaled_size[1], 3])\n        img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n            \n        # Add random noise to improve robustness\n        noise = tf.random.normal(shape=tf.shape(img), mean=0.0, stddev=0.02)  # Increased noise\n        img = img + noise\n        \n        # Ensure values stay in valid range\n        img = tf.clip_by_value(img, -1.0, 1.0)\n    \n    # One-hot encode label\n    label = tf.one_hot(label, depth=8)  # 8 emotion classes\n    \n    return img, label\n\n# =============================================================================\n# Fixed dataset creation function\n# =============================================================================\ndef create_dataset(dataframe, is_training=True, dataset_type=None):\n    \"\"\"\n    Creates a tf.data.Dataset with fixed preprocessing.\n    \n    Args:\n        dataframe: DataFrame with filepath, label, and source columns\n        is_training: Whether this is for training (includes augmentation)\n        dataset_type: Optional filter for specific dataset ('affectnet' or 'fer2013')\n        \n    Returns:\n        tf.data.Dataset and class mapping\n    \"\"\"\n    # Optionally filter to specific dataset\n    if dataset_type is not None:\n        dataframe = dataframe[dataframe['source'] == dataset_type].reset_index(drop=True)\n        print(f\"Filtered to {len(dataframe)} {dataset_type} images\")\n    \n    # Create class indices\n    class_indices = {cls: i for i, cls in enumerate(sorted(dataframe[\"label\"].unique()))}\n    labels = [class_indices[label] for label in dataframe[\"label\"]]\n    \n    # Create dataset\n    ds = tf.data.Dataset.from_tensor_slices((\n        dataframe[\"filepath\"].values,\n        labels,\n        dataframe[\"source\"].values\n    ))\n    \n    # Apply preprocessing with training flag\n    training_value = tf.constant(is_training)\n    ds = ds.map(\n        lambda path, label, source: preprocess_image(path, label, source, training=training_value),\n        num_parallel_calls=AUTOTUNE\n    )\n    \n    if is_training:\n        # Training pipeline\n        ds = ds.shuffle(buffer_size=min(10000, len(dataframe)))\n        \n    # Repeat dataset for multiple epochs\n    ds = ds.repeat()\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(AUTOTUNE)\n    \n    return ds, class_indices\n\n# =============================================================================\n# Create balanced dataset with emphasis classes\n# =============================================================================\ndef create_emphasis_dataset(dataframe, is_training=True, emphasis_classes=PROBLEMATIC_CLASSES):\n    \"\"\"\n    Creates a balanced dataset with emphasis on problematic classes.\n    \n    Args:\n        dataframe: Input DataFrame\n        is_training: Whether to apply training augmentations\n        emphasis_classes: List of classes to emphasize (oversample)\n        \n    Returns:\n        Balanced tf.data.Dataset with emphasis on specified classes\n    \"\"\"\n    balanced_data = []\n    \n    # Sample from each class with emphasis on problematic ones\n    for class_name in sorted(dataframe[\"label\"].unique()):\n        class_df = dataframe[dataframe[\"label\"] == class_name]\n        samples_per_class = 400  # Base sampling\n        \n        # Increase samples for emphasis classes\n        if class_name in emphasis_classes:\n            samples_per_class = 600  # 50% more samples for problematic classes\n            \n        # Sample with replacement if needed\n        if len(class_df) <= samples_per_class:\n            sampled = class_df.sample(n=samples_per_class, replace=True)\n        else:\n            sampled = class_df.sample(n=samples_per_class, replace=False)\n            \n        balanced_data.append(sampled)\n    \n    # Combine all balanced samples\n    balanced_df = pd.concat(balanced_data, ignore_index=True)\n    print(f\"Created balanced dataset with {len(balanced_df)} samples (with emphasis on {emphasis_classes})\")\n    \n    # Create dataset\n    return create_dataset(balanced_df, is_training=is_training)\n\n# =============================================================================\n# Fixed Confusion Matrix Callback without plotting errors\n# =============================================================================\nclass EnhancedConfusionMatrixCallback(tf.keras.callbacks.Callback):\n    \"\"\"\n    Enhanced callback to monitor class-specific metrics during training.\n    \"\"\"\n    def __init__(self, validation_data, class_names, log_dir, model_name=\"model\", freq=5):\n        super(EnhancedConfusionMatrixCallback, self).__init__()\n        self.validation_data = validation_data\n        self.class_names = class_names\n        self.freq = freq\n        self.log_dir = log_dir\n        self.model_name = model_name\n        self.zero_prediction_classes = set()  # Track classes with zero predictions\n        self.class_metrics_history = {cls: [] for cls in class_names}  # Track per-class metrics\n        \n        # Ensure log directory exists\n        ensure_dir(self.log_dir)\n        \n    def on_epoch_end(self, epoch, logs=None):\n        # Calculate and log class-specific metrics every epoch\n        val_steps = 30  # Limit computation\n        y_true = []\n        y_pred = []\n        \n        # Get predictions for validation data\n        for i, (images, labels) in enumerate(self.validation_data):\n            if i >= val_steps:\n                break\n            batch_preds = self.model.predict(images, verbose=0)\n            y_pred.append(np.argmax(batch_preds, axis=1))\n            y_true.append(np.argmax(labels.numpy(), axis=1))\n        \n        # Flatten the lists\n        y_true = np.concatenate(y_true)\n        y_pred = np.concatenate(y_pred)\n        \n        # Calculate confusion matrix\n        cm = confusion_matrix(y_true, y_pred)\n        \n        # Calculate per-class metrics\n        class_accuracies = np.zeros(len(self.class_names))\n        for i in range(len(self.class_names)):\n            if np.sum(y_true == i) > 0:  # Avoid division by zero\n                class_accuracies[i] = cm[i, i] / np.sum(y_true == i)\n                \n            # Track metrics history\n            self.class_metrics_history[self.class_names[i]].append(class_accuracies[i])\n        \n        # Check for classes with zero predictions\n        zero_pred_classes = []\n        for i, class_name in enumerate(self.class_names):\n            if np.sum(cm[:, i]) == 0:\n                zero_pred_classes.append(class_name)\n                self.zero_prediction_classes.add(class_name)\n        \n        # Log warnings for zero prediction classes\n        if zero_pred_classes:\n            warning_msg = f\"\\n⚠️ WARNING: Zero predictions for classes: {', '.join(zero_pred_classes)}\"\n            print(warning_msg)\n            \n            # Save warning to log file\n            with open(f\"{self.log_dir}/warnings.txt\", \"a\") as f:\n                f.write(f\"Epoch {epoch+1}: {warning_msg}\\n\")\n        \n        # Save visualizations and detailed reports on the specified frequency\n        if (epoch + 1) % self.freq == 0:\n            # Print confusion matrix\n            print(\"\\nConfusion Matrix:\")\n            print(cm)\n            \n            # Print per-class accuracy\n            for i, (name, acc) in enumerate(zip(self.class_names, class_accuracies)):\n                print(f\"{name}: {acc:.4f}\", end=\"  \")\n                if (i + 1) % 4 == 0:\n                    print()  # New line for readability\n            print(\"\\n\")\n            \n            # Print class accuracy trends instead of plotting them\n            print(\"Class Accuracy Trends:\")\n            for class_name in self.class_names:\n                history = self.class_metrics_history[class_name]\n                trend = \", \".join([f\"{acc:.4f}\" for acc in history[-5:]])  # Show last 5 epochs\n                print(f\"{class_name}: [{trend}]\")\n            print()\n            \n            # Save confusion matrix visualization (still useful)\n            plt.figure(figsize=(10, 8))\n            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                       xticklabels=self.class_names,\n                       yticklabels=self.class_names)\n            plt.xlabel('Predicted')\n            plt.ylabel('True')\n            plt.title(f'Confusion Matrix - {self.model_name} - Epoch {epoch+1}')\n            plt.tight_layout()\n            \n            try:\n                plt.savefig(f'{self.log_dir}/confusion_matrix_epoch_{epoch+1}.png')\n            except Exception as e:\n                print(f\"Warning: Could not save confusion matrix plot: {e}\")\n            \n            plt.close()\n\n# =============================================================================\n# Create emotion recognition model with additional MLP head\n# =============================================================================\ndef create_emotion_model(num_classes):\n    \"\"\"\n    Create a facial emotion recognition model with enhanced classification head.\n    \n    Args:\n        num_classes: Number of emotion classes\n        \n    Returns:\n        Compiled Keras model and base model\n    \"\"\"\n    # Input shape\n    input_shape = (IMG_SIZE, IMG_SIZE, 3)\n    \n    # Create input layer\n    inputs = keras.layers.Input(shape=input_shape)\n    \n    # Use MobileNetV2 as base\n    base_model = MobileNetV2(\n        include_top=False,\n        weights='imagenet',\n        input_tensor=inputs,\n        alpha=1.0  # Controls model width\n    )\n    print(\"Using MobileNetV2 base model\")\n    \n    # Freeze base model layers\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    # Add custom head with dropout and batch normalization\n    x = base_model.output\n    x = keras.layers.GlobalAveragePooling2D()(x)\n    \n    # First dense block - wider layers for better capacity\n    x = keras.layers.Dense(512)(x)  # Increased from 256\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.Dropout(0.4)(x)\n    \n    # Second dense block\n    x = keras.layers.Dense(256)(x)  # Increased from 128\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.Dropout(0.3)(x)\n    \n    # New third dense block for better capacity\n    x = keras.layers.Dense(128)(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.Dropout(0.2)(x)\n    \n    # Output layer with label smoothing\n    outputs = keras.layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n    \n    # Create model\n    model = keras.Model(inputs=inputs, outputs=outputs)\n    \n    # Compile with label smoothing loss\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n        loss=label_smoothing_loss(epsilon=0.2),  # Increased from 0.1\n        metrics=['accuracy']\n    )\n    \n    return model, base_model\n\n# =============================================================================\n# Evaluation function\n# =============================================================================\ndef evaluate_model(model, test_ds, steps, class_names, log_dir, dataset_name=\"\"):\n    \"\"\"\n    Evaluate model with detailed metrics and visualizations.\n    \"\"\"\n    print(f\"\\nEvaluating model on {dataset_name} test set\")\n    \n    # Get predictions\n    y_true = []\n    y_pred = []\n    \n    # Loop through test batches\n    for i, (images, labels) in enumerate(test_ds):\n        if i >= steps:\n            break\n        batch_preds = model.predict(images, verbose=0)\n        y_pred.append(np.argmax(batch_preds, axis=1))\n        y_true.append(np.argmax(labels.numpy(), axis=1))\n    \n    # Concatenate\n    y_true = np.concatenate(y_true)\n    y_pred = np.concatenate(y_pred)\n    \n    # Calculate metrics\n    test_accuracy = np.mean(y_pred == y_true)\n    f1 = f1_score(y_true, y_pred, average='weighted')\n    \n    print(f\"{dataset_name} Test Accuracy: {test_accuracy:.4f}\")\n    print(f\"{dataset_name} Weighted F1-Score: {f1:.4f}\")\n    \n    # Calculate confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Visualize confusion matrix\n    plt.figure(figsize=(12, 10))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n               xticklabels=class_names,\n               yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title(f'Confusion Matrix - {dataset_name} Test Set')\n    plt.tight_layout()\n    \n    try:\n        plt.savefig(f'{log_dir}/confusion_matrix_{dataset_name}_test.png')\n    except Exception as e:\n        print(f\"Warning: Could not save confusion matrix plot: {e}\")\n        \n    plt.close()\n    \n    # Print classification report\n    print(f\"\\n{dataset_name} Classification Report:\")\n    report = classification_report(\n        y_true, \n        y_pred, \n        target_names=class_names,\n        zero_division=0\n    )\n    print(report)\n    \n    # Save report to file\n    with open(f'{log_dir}/classification_report_{dataset_name}.txt', 'w') as f:\n        f.write(report)\n    \n    return {\n        'accuracy': test_accuracy,\n        'f1_score': f1,\n        'confusion_matrix': cm\n    }\n\n# =============================================================================\n# Two-Stage Fine-Tuning with Progressive Unfreezing\n# =============================================================================\ndef train_with_progressive_unfreezing(model, base_model, train_ds, val_ds, \n                                    steps_per_epoch, val_steps, \n                                    epochs_head=10, epochs_finetune=20,\n                                    callbacks=None, class_weights=None):\n    \"\"\"\n    Two-stage training approach: first train only the head, then progressively unfreeze layers.\n    \n    Args:\n        model: The model to train\n        base_model: The base model part (for unfreezing)\n        train_ds: Training dataset\n        val_ds: Validation dataset\n        steps_per_epoch: Steps per training epoch\n        val_steps: Validation steps\n        epochs_head: Epochs for head-only training\n        epochs_finetune: Epochs for fine-tuning\n        callbacks: List of callbacks\n        class_weights: Class weights for handling imbalance\n        \n    Returns:\n        Training history\n    \"\"\"\n    print(f\"\\nStage 1: Training only the classification head ({epochs_head} epochs)\")\n    \n    # Ensure base model is frozen\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    # Compile with higher learning rate for head training\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n        loss=label_smoothing_loss(epsilon=0.2),\n        metrics=['accuracy']\n    )\n    \n    # Train head only\n    history_head = model.fit(\n        train_ds,\n        epochs=epochs_head,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=val_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    \n    print(f\"\\nStage 2: Fine-tuning with progressive unfreezing ({epochs_finetune} epochs)\")\n    \n    # Progressively unfreeze layers in groups\n    fine_tuning_history = []\n    \n    # Groups of layers to unfreeze (from last to first)\n    layer_groups = [\n        # Unfreeze last layers first (deeper = more specific features)\n        base_model.layers[-15:],  # Last block\n        base_model.layers[-30:-15],  # Second-to-last block\n        base_model.layers[-50:-30]   # Third-to-last block\n    ]\n    \n    for i, group in enumerate(layer_groups):\n        print(f\"\\nUnfreezing group {i+1}/{len(layer_groups)} ({len(group)} layers)\")\n        \n        # Unfreeze current group\n        for layer in group:\n            layer.trainable = True\n            \n        # Recompile with lower learning rate as we go deeper\n        lr = 1e-4 / (i + 1)  # Decrease learning rate for deeper layers\n        \n        model.compile(\n            optimizer=keras.optimizers.Adam(learning_rate=lr),\n            loss=label_smoothing_loss(epsilon=0.2),  # Keep consistent\n            metrics=['accuracy']\n        )\n        \n        # Train for a few epochs\n        epochs_per_group = max(5, epochs_finetune // len(layer_groups))\n        \n        history = model.fit(\n            train_ds,\n            epochs=epochs_per_group,\n            steps_per_epoch=steps_per_epoch,\n            validation_data=val_ds,\n            validation_steps=val_steps,\n            callbacks=callbacks,\n            class_weight=class_weights,\n            verbose=1\n        )\n        \n        fine_tuning_history.append(history)\n    \n    # Return combined history\n    return history_head, fine_tuning_history\n\n# =============================================================================\n# Sequential Training Pipeline\n# =============================================================================\ndef train_enhanced_emotion_model(data_dir):\n    \"\"\"\n    Enhanced sequential training with all improvements.\n    \n    Args:\n        data_dir: Path to dataset directory\n        \n    Returns:\n        Trained model and evaluation metrics\n    \"\"\"\n    print(\"Starting enhanced sequential emotion recognition training\")\n    \n    # 1. Load and prepare data\n    print(\"\\n1. Loading datasets\")\n    train_dir = os.path.join(data_dir, \"Train\")\n    test_dir = os.path.join(data_dir, \"Test\")\n    \n    train_df_full = build_image_df(train_dir)\n    test_df = build_image_df(test_dir)\n    \n    # Show dataset distributions\n    print(\"\\nAffectNet training distribution:\")\n    print(train_df_full[train_df_full['source'] == 'affectnet']['label'].value_counts())\n    \n    print(\"\\nFER2013 training distribution:\")\n    print(train_df_full[train_df_full['source'] == 'fer2013']['label'].value_counts())\n    \n    # 2. Split test set by dataset source\n    test_affectnet_df = test_df[test_df['source'] == 'affectnet']\n    test_fer_df = test_df[test_df['source'] == 'fer2013']\n    \n    print(f\"\\nTest sets: AffectNet={len(test_affectnet_df)}, FER2013={len(test_fer_df)}\")\n    \n    # Get classes for later use\n    classes = sorted(train_df_full[\"label\"].unique())\n    num_classes = len(classes)\n    print(f\"Classes: {classes}\")\n    \n    # 3. Create validation splits\n    # For AffectNet\n    affectnet_train_df = train_df_full[train_df_full['source'] == 'affectnet']\n    affectnet_train_df, affectnet_val_df = train_test_split(\n        affectnet_train_df, \n        test_size=0.15, \n        stratify=affectnet_train_df[\"label\"], \n        random_state=42\n    )\n    \n    # For FER2013\n    fer_train_df = train_df_full[train_df_full['source'] == 'fer2013']\n    fer_train_df, fer_val_df = train_test_split(\n        fer_train_df, \n        test_size=0.15, \n        stratify=fer_train_df[\"label\"], \n        random_state=42\n    )\n    \n    print(f\"AffectNet: {len(affectnet_train_df)} train, {len(affectnet_val_df)} validation\")\n    print(f\"FER2013: {len(fer_train_df)} train, {len(fer_val_df)} validation\")\n    \n    # 4. Create datasets with emphasis on problematic classes\n    print(\"\\n2. Creating enhanced data pipelines\")\n    \n    # AffectNet datasets\n    affectnet_train_ds, class_indices = create_emphasis_dataset(\n        affectnet_train_df, is_training=True)\n    \n    affectnet_val_ds, _ = create_dataset(\n        affectnet_val_df, is_training=False, \n        dataset_type='affectnet')\n    \n    affectnet_test_ds, _ = create_dataset(\n        test_affectnet_df, is_training=False, \n        dataset_type='affectnet')\n    \n    # FER2013 datasets\n    fer_train_ds, _ = create_emphasis_dataset(\n        fer_train_df, is_training=True)\n    \n    fer_val_ds, _ = create_dataset(\n        fer_val_df, is_training=False, \n        dataset_type='fer2013')\n    \n    fer_test_ds, _ = create_dataset(\n        test_fer_df, is_training=False, \n        dataset_type='fer2013')\n    \n    # Create combined test dataset\n    combined_test_ds, _ = create_dataset(\n        test_df, is_training=False)\n    \n    # 5. Calculate steps\n    affectnet_steps_per_epoch = len(affectnet_train_df) // BATCH_SIZE\n    affectnet_val_steps = len(affectnet_val_df) // BATCH_SIZE\n    affectnet_test_steps = len(test_affectnet_df) // BATCH_SIZE\n    \n    fer_steps_per_epoch = len(fer_train_df) // BATCH_SIZE\n    fer_val_steps = len(fer_val_df) // BATCH_SIZE\n    fer_test_steps = len(test_fer_df) // BATCH_SIZE\n    \n    combined_test_steps = len(test_df) // BATCH_SIZE\n    \n    # 6. Create enhanced model\n    print(\"\\n3. Creating enhanced model\")\n    model, base_model = create_emotion_model(num_classes)\n    \n    # 7. Compute class weights for each dataset with adjustments\n    print(\"\\n4. Computing class weights with adjustments for problematic classes\")\n    \n    # AffectNet class weights\n    affectnet_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(affectnet_train_df[\"label\"]),\n        y=affectnet_train_df[\"label\"]\n    )\n    affectnet_class_weights = {class_indices[label]: weight for label, weight in \n                     zip(np.unique(affectnet_train_df[\"label\"]), affectnet_weights)}\n    \n    # FER2013 class weights\n    fer_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(fer_train_df[\"label\"]),\n        y=fer_train_df[\"label\"]\n    )\n    fer_class_weights = {class_indices[label]: weight for label, weight in \n                zip(np.unique(fer_train_df[\"label\"]), fer_weights)}\n    \n    # Increase weights for problematic classes\n    for problem_class in PROBLEMATIC_CLASSES:\n        if problem_class in class_indices:\n            class_idx = class_indices[problem_class]\n            # Increase the weight by 20%\n            if class_idx in affectnet_class_weights:\n                affectnet_class_weights[class_idx] *= 1.2\n            if class_idx in fer_class_weights:\n                fer_class_weights[class_idx] *= 1.2\n    \n    print(\"Enhanced AffectNet class weights:\", affectnet_class_weights)\n    print(\"Enhanced FER2013 class weights:\", fer_class_weights)\n    \n    # 8. Setup callbacks with enhanced monitoring\n    print(\"\\n5. Setting up enhanced callbacks\")\n    \n    # Base callbacks shared across training phases\n    base_callbacks = [\n        # Early stopping\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=10,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        # Learning rate scheduler\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.5,\n            patience=5,\n            min_lr=1e-6,\n            verbose=1\n        ),\n        # TensorBoard\n        tf.keras.callbacks.TensorBoard(\n            log_dir=LOG_DIR,\n            histogram_freq=1,\n            update_freq='epoch'\n        )\n    ]\n    \n    # AffectNet-specific callbacks\n    affectnet_callbacks = base_callbacks + [\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'model_checkpoints/affectnet_best.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        ),\n        # Enhanced confusion matrix monitoring (fixed version)\n        EnhancedConfusionMatrixCallback(\n            affectnet_val_ds, \n            classes, \n            log_dir=LOG_DIR + '/affectnet',\n            model_name=\"AffectNet\",\n            freq=3\n        ),\n        # CSV Logger\n        tf.keras.callbacks.CSVLogger(\n            'affectnet_training_log.csv', \n            append=True\n        )\n    ]\n    \n    # FER2013-specific callbacks\n    fer_callbacks = base_callbacks + [\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'model_checkpoints/fer2013_best.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        ),\n        # Enhanced confusion matrix monitoring (fixed version)\n        EnhancedConfusionMatrixCallback(\n            fer_val_ds, \n            classes, \n            log_dir=LOG_DIR + '/fer2013',\n            model_name=\"FER2013\",\n            freq=3\n        ),\n        # CSV Logger\n        tf.keras.callbacks.CSVLogger(\n            'fer2013_training_log.csv', \n            append=True\n        )\n    ]\n    \n    # 9. STAGE 1: Train on AffectNet using progressive unfreezing\n    print(\"\\n6. STAGE 1: Training on AffectNet with progressive unfreezing\")\n    \n    history_affectnet_head, history_affectnet_finetune = train_with_progressive_unfreezing(\n        model, base_model,\n        affectnet_train_ds, affectnet_val_ds,\n        affectnet_steps_per_epoch, affectnet_val_steps,\n        epochs_head=10, epochs_finetune=15,\n        callbacks=affectnet_callbacks,\n        class_weights=affectnet_class_weights\n    )\n    \n    # Save AffectNet model\n    model.save(\"affectnet_model.keras\")\n    print(\"AffectNet model saved to 'affectnet_model.keras'\")\n    \n    # 10. Evaluate on AffectNet test set\n    affectnet_metrics = evaluate_model(\n        model, \n        affectnet_test_ds, \n        affectnet_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"AffectNet\"\n    )\n    \n    # 11. STAGE 2: Fine-tune on FER2013 with progressive unfreezing\n    print(\"\\n7. STAGE 2: Fine-tuning on FER2013 with progressive unfreezing\")\n    \n    history_fer_head, history_fer_finetune = train_with_progressive_unfreezing(\n        model, base_model,\n        fer_train_ds, fer_val_ds,\n        fer_steps_per_epoch, fer_val_steps,\n        epochs_head=8, epochs_finetune=12,\n        callbacks=fer_callbacks,\n        class_weights=fer_class_weights\n    )\n    \n    # 12. Evaluate on FER2013 test set\n    fer_metrics = evaluate_model(\n        model, \n        fer_test_ds, \n        fer_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"FER2013\"\n    )\n    \n    # 13. Evaluate on combined test set\n    combined_metrics = evaluate_model(\n        model, \n        combined_test_ds, \n        combined_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"Combined\"\n    )\n    \n    # 14. Save the final model\n    model.save(\"final_enhanced_emotion_model.keras\")\n    print(\"Final model saved to 'final_enhanced_emotion_model.keras'\")\n    \n    # Return models and metrics\n    return model, {\n        'affectnet': affectnet_metrics,\n        'fer2013': fer_metrics,\n        'combined': combined_metrics\n    }\n\n# =============================================================================\n# Main entry point\n# =============================================================================\nif __name__ == \"__main__\":\n    # Set data directory path\n    data_dir = \"/kaggle/input/custom-fer2013affectnet/Custom_ferAffect2013net\"\n    \n    # Train model with all improvements\n    model, metrics = train_enhanced_emotion_model(data_dir)\n    \n    # Print final results\n    print(\"\\n=== FINAL RESULTS ===\")\n    print(f\"AffectNet Test Accuracy: {metrics['affectnet']['accuracy']:.4f}\")\n    print(f\"AffectNet F1 Score: {metrics['affectnet']['f1_score']:.4f}\")\n    print(f\"FER2013 Test Accuracy: {metrics['fer2013']['accuracy']:.4f}\")\n    print(f\"FER2013 F1 Score: {metrics['fer2013']['f1_score']:.4f}\")\n    print(f\"Combined Test Accuracy: {metrics['combined']['accuracy']:.4f}\")\n    print(f\"Combined F1 Score: {metrics['combined']['f1_score']:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Version 6.0z accuracy 0.1882 class balance deficit \n\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom sklearn.model_selection import train_test_split\n\n# =============================================================================\n# Enable memory growth and mixed precision\n# =============================================================================\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        print(e)\n\n# Enable mixed precision\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\n\n# =============================================================================\n# Key parameters\n# =============================================================================\nIMG_SIZE = 96  # Keep at 96x96 as requested\nBATCH_SIZE = 128  # Moderate batch size\nEPOCHS = 50\nAUTOTUNE = tf.data.AUTOTUNE\n\n# =============================================================================\n# Custom Focal Loss Implementation\n# =============================================================================\ndef focal_loss(gamma=2.0, alpha=0.25):\n    \"\"\"\n    Focal Loss implementation for multi-class classification.\n    Focal Loss is designed to address class imbalance by down-weighting easy examples.\n    \n    Args:\n        gamma: Focusing parameter. Higher values mean more focus on hard examples.\n        alpha: Class weight factor. Higher values give more weight to minority classes.\n        \n    Returns:\n        Focal loss function\n    \"\"\"\n    def focal_loss_fn(y_true, y_pred):\n        epsilon = 1e-7\n        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n        \n        # Calculate cross entropy\n        cross_entropy = -y_true * K.log(y_pred)\n        \n        # Apply focal weight\n        weight = alpha * K.pow(1 - y_pred, gamma) * y_true\n        \n        # Sum over classes\n        focal_loss = K.sum(weight * cross_entropy, axis=-1)\n        return K.mean(focal_loss)\n    \n    return focal_loss_fn\n\n# =============================================================================\n# Build DataFrame from dataset directory structure\n# =============================================================================\ndef build_image_df(root_dir, subfolders=[\"fer2013\", \"affectnet\"]):\n    \"\"\"\n    Scans the given root directory and returns a DataFrame with file paths and labels.\n    \"\"\"\n    data = []\n    emotions = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n    for emotion in emotions:\n        emotion_path = os.path.join(root_dir, emotion)\n        for sub in subfolders:\n            sub_path = os.path.join(emotion_path, sub)\n            if os.path.exists(sub_path):\n                for img_file in os.listdir(sub_path):\n                    if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n                        data.append({\n                            \"filepath\": os.path.join(sub_path, img_file),\n                            \"label\": emotion,\n                            \"source\": sub\n                        })\n    return pd.DataFrame(data)\n\n# =============================================================================\n# Data Augmentation for Minority Classes\n# =============================================================================\ndef augment_minority_classes(df, target_count=5000, minority_classes=None):\n    \"\"\"\n    Augment minority classes by duplicating samples to achieve more balanced class distribution.\n    \n    Args:\n        df: DataFrame with image paths and labels\n        target_count: Target number of samples per class\n        minority_classes: List of specific classes to augment (if None, determined automatically)\n        \n    Returns:\n        Augmented DataFrame\n    \"\"\"\n    print(\"Class distribution before augmentation:\")\n    print(df['label'].value_counts())\n    \n    if minority_classes is None:\n        # Identify classes with fewer than target_count samples\n        class_counts = df['label'].value_counts()\n        minority_classes = class_counts[class_counts < target_count].index.tolist()\n    \n    augmented_data = []\n    for cls in minority_classes:\n        class_df = df[df['label'] == cls]\n        needed = target_count - len(class_df)\n        if needed <= 0:\n            continue\n            \n        # Sample with replacement if needed\n        print(f\"Augmenting class '{cls}': Adding {needed} samples\")\n        samples = class_df.sample(n=needed, replace=True)\n        augmented_data.append(samples)\n    \n    # Combine augmented data with original\n    augmented_df = pd.concat([df] + augmented_data, ignore_index=True)\n    \n    print(\"Class distribution after augmentation:\")\n    print(augmented_df['label'].value_counts())\n    \n    return augmented_df\n\n# =============================================================================\n# Improved preprocessing function\n# =============================================================================\ndef preprocess_image(file_path, label, source):\n    \"\"\"\n    Unified preprocessing function with consistent augmentation for both datasets.\n    \n    Args:\n        file_path: Path to the image file\n        label: Emotion label (as index)\n        source: Dataset source ('fer2013' or 'affectnet')\n        \n    Returns:\n        Preprocessed image and one-hot encoded label\n    \"\"\"\n    # Read the file\n    img = tf.io.read_file(file_path)\n    \n    # Decode with better error handling\n    try:\n        img = tf.image.decode_image(img, channels=3, expand_animations=False)\n    except tf.errors.InvalidArgumentError:\n        try:\n            img = tf.image.decode_image(img, channels=1, expand_animations=False)\n            img = tf.image.grayscale_to_rgb(img)\n        except:\n            # Create a blank image if decoding fails\n            img = tf.zeros([IMG_SIZE, IMG_SIZE, 3], dtype=tf.uint8)\n            print(f\"Warning: Failed to decode image at {file_path}\")\n    \n    # Ensure the image has the right shape and type\n    img = tf.ensure_shape(img, [None, None, 3])\n    \n    # Resize to target size\n    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE], method='bilinear')\n    \n    # Normalize to [0, 1]\n    img = tf.cast(img, tf.float32) / 255.0\n    \n    # Apply consistent augmentation for both datasets\n    if tf.random.uniform([], 0, 1) > 0.5:\n        # Standard horizontal flipping\n        img = tf.image.random_flip_left_right(img)\n        \n        # Color augmentations\n        img = tf.image.random_brightness(img, 0.2)\n        img = tf.image.random_contrast(img, 0.8, 1.2)\n        img = tf.image.random_saturation(img, 0.8, 1.2)\n        \n        # Slight rotation (maximum 15 degrees)\n        angle = tf.random.uniform([], -0.25, 0.25)  # in radians\n        img = tf.image.rot90(img, k=tf.cast(angle * 2 / 3.14159, tf.int32))\n    \n    # Convert label to one-hot encoding\n    label = tf.one_hot(label, depth=8)  # Assuming 8 emotion classes\n    \n    return img, label\n\n# =============================================================================\n# Fixed dataset creation function\n# =============================================================================\ndef create_dataset(dataframe, is_training=True):\n    \"\"\"\n    Create an optimized tf.data.Dataset from a DataFrame with fixed repeating.\n    \n    Args:\n        dataframe: DataFrame with filepath, label, and source columns\n        is_training: Whether to apply augmentations and shuffling\n        \n    Returns:\n        tf.data.Dataset\n    \"\"\"\n    # Convert labels to indices\n    class_indices = {cls: i for i, cls in enumerate(sorted(dataframe[\"label\"].unique()))}\n    labels = [class_indices[label] for label in dataframe[\"label\"]]\n    \n    # Create dataset from file paths, labels, and sources\n    ds = tf.data.Dataset.from_tensor_slices((\n        dataframe[\"filepath\"].values,\n        labels,\n        dataframe[\"source\"].values\n    ))\n    \n    # Apply preprocessing\n    ds = ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)\n    \n    if is_training:\n        # Training pipeline with augmentation\n        ds = ds.shuffle(buffer_size=min(10000, len(dataframe)))\n        \n    # Important: Always repeat the dataset for multiple epochs\n    ds = ds.repeat()\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(AUTOTUNE)\n    \n    return ds, class_indices\n\n# =============================================================================\n# Confusion Matrix Callback\n# =============================================================================\nclass ConfusionMatrixCallback(tf.keras.callbacks.Callback):\n    \"\"\"\n    Callback to display confusion matrix during training.\n    \"\"\"\n    def __init__(self, validation_data, class_names, freq=5):\n        super(ConfusionMatrixCallback, self).__init__()\n        self.validation_data = validation_data\n        self.class_names = class_names\n        self.freq = freq\n        \n    def on_epoch_end(self, epoch, logs=None):\n        if (epoch + 1) % self.freq == 0:\n            # Get a batch of validation data\n            validation_steps = 30  # Limit to prevent too much computation\n            y_true = []\n            y_pred = []\n            \n            # Get predictions for validation data\n            for i, (images, labels) in enumerate(self.validation_data):\n                if i >= validation_steps:\n                    break\n                batch_preds = self.model.predict(images, verbose=0)\n                y_pred.append(np.argmax(batch_preds, axis=1))\n                y_true.append(np.argmax(labels.numpy(), axis=1))\n            \n            # Flatten the lists\n            y_true = np.concatenate(y_true)\n            y_pred = np.concatenate(y_pred)\n            \n            # Calculate confusion matrix\n            cm = confusion_matrix(y_true, y_pred)\n            \n            # Print confusion matrix\n            print(\"\\nConfusion Matrix:\")\n            print(cm)\n            \n            # Calculate per-class accuracy\n            class_acc = cm.diagonal() / cm.sum(axis=1)\n            for i, (name, acc) in enumerate(zip(self.class_names, class_acc)):\n                print(f\"{name}: {acc:.4f}\", end=\"  \")\n                if (i + 1) % 4 == 0:\n                    print()  # New line for readability\n            print()\n\n# =============================================================================\n# Model Creation\n# =============================================================================\ndef create_simplified_model(num_classes):\n    \"\"\"\n    Create a simplified EfficientNetB0 model with a smaller head.\n    \n    Args:\n        num_classes: Number of emotion classes\n        \n    Returns:\n        Compiled Keras model\n    \"\"\"\n    # Input layer\n    inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n    \n    # Load pre-trained model with imagenet weights\n    base_model = EfficientNetB0(\n        include_top=False, \n        weights=\"imagenet\", \n        input_tensor=inputs\n    )\n    \n    # Initially freeze all layers\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    # Add custom classification head\n    x = base_model.output\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(0.4)(x)\n    \n    # Ensure final layer uses float32 for numerical stability\n    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n    \n    # Create model\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    \n    # Compile with focal loss\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n        loss=focal_loss(gamma=2.0, alpha=0.25),\n        metrics=[\"accuracy\"]\n    )\n    \n    return model, base_model\n\n# =============================================================================\n# Main Training Function\n# =============================================================================\ndef train_emotion_recognition_model(data_dir):\n    \"\"\"\n    Complete training pipeline incorporating all improvements.\n    \n    Args:\n        data_dir: Path to the dataset directory\n        \n    Returns:\n        Trained model and evaluation metrics\n    \"\"\"\n    print(\"Starting improved facial emotion recognition training\")\n    \n    # 1. Load and prepare data\n    print(\"\\n1. Loading dataset\")\n    train_dir = os.path.join(data_dir, \"Train\")\n    test_dir = os.path.join(data_dir, \"Test\")\n    \n    train_df_full = build_image_df(train_dir)\n    test_df = build_image_df(test_dir)\n    \n    print(f\"Original training data: {train_df_full.shape}\")\n    print(f\"Test data: {test_df.shape}\")\n    \n    # 2. Apply class balancing through augmentation\n    print(\"\\n2. Balancing class distribution\")\n    train_df_balanced = augment_minority_classes(train_df_full, target_count=5000)\n    \n    # 3. Split into train and validation sets\n    print(\"\\n3. Creating train/validation split\")\n    train_df, val_df = train_test_split(\n        train_df_balanced, \n        test_size=0.15, \n        stratify=train_df_balanced[\"label\"], \n        random_state=42\n    )\n    \n    print(f\"Training samples: {len(train_df)}\")\n    print(f\"Validation samples: {len(val_df)}\")\n    print(f\"Test samples: {len(test_df)}\")\n    \n    # 4. Create fixed tf.data datasets\n    print(\"\\n4. Creating data pipelines\")\n    train_ds, class_indices = create_dataset(train_df, is_training=True)\n    val_ds, _ = create_dataset(val_df, is_training=False)\n    test_ds, _ = create_dataset(test_df, is_training=False)\n    \n    # Get class names in order\n    classes = sorted(train_df[\"label\"].unique())\n    num_classes = len(classes)\n    print(f\"Classes: {classes}\")\n    \n    # Calculate steps\n    steps_per_epoch = len(train_df) // BATCH_SIZE\n    validation_steps = len(val_df) // BATCH_SIZE\n    \n    # 5. Create model\n    print(\"\\n5. Creating simplified model\")\n    model, base_model = create_simplified_model(num_classes)\n    print(\"Model created\")\n    \n    # 6. Calculate proper class weights\n    print(\"\\n6. Computing class weights\")\n    class_weights_array = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(train_df[\"label\"]),\n        y=train_df[\"label\"]\n    )\n    class_weights = {class_indices[label]: weight for label, weight in \n                     zip(np.unique(train_df[\"label\"]), class_weights_array)}\n    print(\"Class weights:\", class_weights)\n    \n    # 7. Setup callbacks\n    print(\"\\n7. Setting up training callbacks\")\n    callbacks = [\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'best_emotion_model.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        ),\n        # Early stopping\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=7,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        # Learning rate scheduler\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.5,\n            patience=3,\n            min_lr=1e-6,\n            verbose=1\n        ),\n        # Logging\n        tf.keras.callbacks.CSVLogger('training_log.csv', append=True),\n        # Confusion matrix\n        ConfusionMatrixCallback(val_ds, classes, freq=3)\n    ]\n    \n    # 8. Progressive training approach\n    print(\"\\n8. Stage 1: Training only the model head\")\n    history_stage1 = model.fit(\n        train_ds,\n        epochs=10,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=validation_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    \n    # 9. Fine-tune the upper layers\n    print(\"\\n9. Stage 2: Fine-tuning upper layers\")\n    # Unfreeze the top layers of the base model\n    for layer in base_model.layers[-30:]:\n        layer.trainable = True\n        \n    # Recompile with a lower learning rate\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n        loss=focal_loss(gamma=2.0, alpha=0.25),\n        metrics=[\"accuracy\"]\n    )\n    \n    history_stage2 = model.fit(\n        train_ds,\n        epochs=20,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=validation_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    \n    # 10. Evaluate on test set\n    print(\"\\n10. Final evaluation\")\n    # Update test steps\n    test_steps = len(test_df) // BATCH_SIZE\n    \n    # Get predictions\n    all_predictions = []\n    all_labels = []\n    \n    # Loop through batches\n    for i, (images, labels) in enumerate(test_ds):\n        if i >= test_steps:\n            break\n        batch_preds = model.predict(images, verbose=0)\n        all_predictions.append(np.argmax(batch_preds, axis=1))\n        all_labels.append(np.argmax(labels.numpy(), axis=1))\n    \n    # Concatenate\n    all_predictions = np.concatenate(all_predictions)\n    all_labels = np.concatenate(all_labels)\n    \n    # Calculate metrics\n    test_accuracy = np.mean(all_predictions == all_labels)\n    f1 = f1_score(all_labels, all_predictions, average='weighted')\n    \n    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n    print(f\"Weighted F1-Score: {f1:.4f}\")\n    \n    # Print classification report\n    print(\"\\nClassification Report:\")\n    print(classification_report(\n        all_labels, \n        all_predictions, \n        target_names=classes,\n        zero_division=0\n    ))\n    \n    # Print confusion matrix\n    cm = confusion_matrix(all_labels, all_predictions)\n    print(\"\\nConfusion Matrix:\")\n    print(cm)\n    \n    # 11. Save the final model\n    model.save(\"final_improved_emotion_model.keras\")\n    print(\"Model saved to 'final_improved_emotion_model.keras'\")\n    \n    return model, {'accuracy': test_accuracy, 'f1_score': f1}\n\n# =============================================================================\n# Main entry point\n# =============================================================================\nif __name__ == \"__main__\":\n    # Set data directory path\n    data_dir = \"/kaggle/input/custom-fer2013affectnet/Custom_ferAffect2013net\"\n    \n    # Train model\n    model, metrics = train_emotion_recognition_model(data_dir)\n    \n    print(\"Training completed successfully!\")\n    print(f\"Final Test Accuracy: {metrics['accuracy']:.4f}\")\n    print(f\"Final F1 Score: {metrics['f1_score']:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Version 6.0 accuracy 0.1832 \n\nimport os\nimport math\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\nfrom sklearn.model_selection import train_test_split\n\n# Enable memory growth to prevent TF from allocating all GPU memory at once\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        print(e)\n\n# Enable mixed precision for faster training\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\n\n# Memory cleanup callback\nclass MemoryCleanupCallback(keras.callbacks.Callback):\n    \"\"\"Callback to clear TensorFlow session after each epoch to free memory.\"\"\"\n    def on_epoch_end(self, epoch, logs=None):\n        tf.keras.backend.clear_session()\n\n# =============================================================================\n# Define key parameters\n# =============================================================================\nIMG_SIZE = 96  # Unified image size for both datasets\nBATCH_SIZE = 32  # Start with a conservative value\nEPOCHS = 30\nAUTOTUNE = tf.data.AUTOTUNE\n\n# Try to determine optimal batch size based on available GPU memory\n# Start with default batch size\noptimal_batch_size = BATCH_SIZE\n\n# Try to detect available GPU memory and adjust batch size\ntry:\n    gpus = tf.config.experimental.list_physical_devices('GPU')\n    if gpus:\n        # Get GPU memory info if possible (works on some systems)\n        gpu_details = tf.config.experimental.get_device_details(gpus[0])\n        if 'memory_limit' in gpu_details:\n            # Memory in bytes, convert to GB\n            gpu_memory_gb = gpu_details['memory_limit'] / (1024**3)\n            \n            # Simple heuristic: 1GB supports batch size of ~16 for this model\n            if gpu_memory_gb > 14:  # High-end GPU (16GB+)\n                optimal_batch_size = 128\n            elif gpu_memory_gb > 7:  # Mid-range GPU (8GB)\n                optimal_batch_size = 64\n            else:  # Lower memory GPU\n                optimal_batch_size = 32\n                \n            print(f\"Detected {gpu_memory_gb:.1f}GB GPU memory, setting batch size to {optimal_batch_size}\")\n        else:\n            # If we can't detect memory, try a reasonable default for Kaggle\n            optimal_batch_size = 64\n            print(f\"Could not detect GPU memory, using default batch size of {optimal_batch_size}\")\nexcept Exception:\n    # If anything fails, stay with the default\n    print(f\"Using default batch size of {optimal_batch_size}\")\n\n# Update batch size to optimal value\nBATCH_SIZE = optimal_batch_size\n\n# =============================================================================\n# 1. Build a DataFrame from the dataset directory structure - Keeping your original function\n# =============================================================================\ndef build_image_df(root_dir, subfolders=[\"fer2013\", \"affectnet\"]):\n    \"\"\"\n    Scans the given root directory and returns a DataFrame with file paths and labels.\n    \"\"\"\n    data = []\n    emotions = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n    for emotion in emotions:\n        emotion_path = os.path.join(root_dir, emotion)\n        for sub in subfolders:\n            sub_path = os.path.join(emotion_path, sub)\n            if os.path.exists(sub_path):\n                for img_file in os.listdir(sub_path):\n                    if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n                        data.append({\n                            \"filepath\": os.path.join(sub_path, img_file),\n                            \"label\": emotion,\n                            \"source\": sub\n                        })\n    return pd.DataFrame(data)\n\n# =============================================================================\n# 2. Dataset Paths & DataFrame Creation\n# =============================================================================\ndata_dir = \"/kaggle/input/custom-fer2013affectnet/Custom_ferAffect2013net\"\ntrain_dir = os.path.join(data_dir, \"Train\")\ntest_dir = os.path.join(data_dir, \"Test\")\n\ntrain_df_full = build_image_df(train_dir)\ntest_df = build_image_df(test_dir)\n\nprint(\"Train DataFrame shape:\", train_df_full.shape)\nprint(\"Test DataFrame shape:\", test_df.shape)\n\n# Add data augmentation specifically for underrepresented classes\ndef augment_minority_classes(df, target_count=5000, minority_classes=None):\n    if minority_classes is None:\n        # Identify classes with fewer than target_count samples\n        class_counts = df['label'].value_counts()\n        minority_classes = class_counts[class_counts < target_count].index.tolist()\n    \n    augmented_data = []\n    for cls in minority_classes:\n        class_df = df[df['label'] == cls]\n        needed = target_count - len(class_df)\n        if needed <= 0:\n            continue\n            \n        # Sample with replacement if needed\n        samples = class_df.sample(n=needed, replace=True)\n        augmented_data.append(samples)\n    \n    # Combine augmented data with original\n    return pd.concat([df] + augmented_data, ignore_index=True)\n\n# Use this before train/val split\ntrain_df_full = augment_minority_classes(train_df_full)\n\n# =============================================================================\n# 3. Split Training Data into Train & Validation Sets\n# =============================================================================\ntrain_df, val_df = train_test_split(\n    train_df_full, \n    test_size=0.2, \n    stratify=train_df_full[\"label\"], \n    random_state=42\n)\n\n# Get class names and create mapping\nclasses = sorted(train_df_full[\"label\"].unique())\nclass_indices = {cls: i for i, cls in enumerate(classes)}\nnum_classes = len(classes)\n\n# =============================================================================\n# 4. Create an optimized tf.data pipeline\n# =============================================================================\ndef preprocess_image(file_path, label, source):\n    \"\"\"\n    Unified preprocessing function that handles both FER2013 and AffectNet images.\n    \n    Args:\n        file_path: Path to the image file\n        label: Emotion label (as index)\n        source: Dataset source ('fer2013' or 'affectnet')\n        \n    Returns:\n        Preprocessed image and one-hot encoded label\n    \"\"\"\n    # Read the file\n    img = tf.io.read_file(file_path)\n    \n    # Decode with error handling\n    try:\n        img = tf.image.decode_image(img, channels=3, expand_animations=False)\n    except:\n        img = tf.zeros([IMG_SIZE, IMG_SIZE, 3], dtype=tf.uint8)\n    \n    # Ensure shape and resize\n    img = tf.ensure_shape(img, [None, None, 3])\n    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE], method='bilinear')\n    \n    # Apply consistent preprocessing for both datasets\n    img = tf.cast(img, tf.float32) / 255.0\n    \n    # Apply the same augmentation regardless of source\n    if tf.random.uniform([], 0, 1) > 0.5:\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_brightness(img, 0.2)\n        img = tf.image.random_contrast(img, 0.8, 1.2)\n    \n    # One-hot encode label\n    label = tf.one_hot(label, depth=num_classes)\n    \n    return img, label\n\ndef create_dataset(dataframe, is_training=True): # , cache=True\n    \"\"\"\n    Create an optimized tf.data.Dataset from a DataFrame.\n    \n    Args:\n        dataframe: DataFrame with filepath, label, and source columns\n        is_training: Whether to apply augmentations\n        cache: Whether to cache the dataset (disable for very large datasets)\n        \n    Returns:\n        tf.data.Dataset\n    \"\"\"\n    # Convert labels to indices\n    labels = [class_indices[label] for label in dataframe[\"label\"]]\n    \n    # Create dataset\n    ds = tf.data.Dataset.from_tensor_slices((\n        dataframe[\"filepath\"].values,\n        labels,\n        dataframe[\"source\"].values\n    ))\n    \n    # Apply preprocessing and batching\n    ds = ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)\n    \n    if is_training:\n        ds = ds.shuffle(buffer_size=min(10000, len(dataframe)))\n        \n    # Make sure to repeat the dataset for multiple epochs\n    ds = ds.repeat()  # This is crucial\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(AUTOTUNE)\n    \n    return ds\n\n# Create datasets\ntrain_ds = create_dataset(train_df, is_training=True)\nval_ds = create_dataset(val_df, is_training=False)\ntest_ds = create_dataset(test_df, is_training=False)\n\n# Calculate steps\nsteps_per_epoch = len(train_df) // BATCH_SIZE\nvalidation_steps = min(len(val_df) // BATCH_SIZE, 100)  # Limit validation steps\n\n# Sanity check - inspect a batch to verify the dataset pipeline\ndef inspect_dataset(dataset, name):\n    \"\"\"Inspect a dataset to verify it's created correctly.\"\"\"\n    print(f\"\\nInspecting {name} dataset:\")\n    \n    try:\n        # Get one batch\n        for images, labels in dataset.take(1):\n            print(f\"  Batch shape: {images.shape}\")\n            print(f\"  Labels shape: {labels.shape}\")\n            print(f\"  Data type: {images.dtype}\")\n            print(f\"  Min/Max values: {tf.reduce_min(images).numpy():.4f}/{tf.reduce_max(images).numpy():.4f}\")\n            \n            # Check for NaNs\n            has_nans = tf.math.reduce_any(tf.math.is_nan(images))\n            print(f\"  Contains NaNs: {has_nans.numpy()}\")\n            \n            # Verify one-hot labels\n            label_sums = tf.reduce_sum(labels, axis=1)\n            all_ones = tf.reduce_all(tf.equal(label_sums, 1))\n            print(f\"  Labels are valid one-hot: {all_ones.numpy()}\")\n            \n            # All checks passed\n            print(f\"  ✅ {name} dataset looks good!\")\n            return True\n    except Exception as e:\n        print(f\"  ❌ Error inspecting {name} dataset: {str(e)}\")\n        return False\n\n# Run sanity checks\ntrain_ok = inspect_dataset(train_ds, \"Training\")\nval_ok = inspect_dataset(val_ds, \"Validation\")\ntest_ok = inspect_dataset(test_ds, \"Test\")\n\n# Abort if datasets are not created correctly\nif not (train_ok and val_ok and test_ok):\n    print(\"\\n⚠️ Dataset sanity check failed! Please check the error messages above.\")\n    print(\"You can continue but training might fail.\")\n\n# =============================================================================\n# 5. Compute Class Weights to handle imbalance\n# =============================================================================\nclass_weights_array = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.unique(train_df[\"label\"]),\n    y=train_df[\"label\"]\n)\nclass_weights = {class_indices[label]: weight for label, weight in \n                 zip(np.unique(train_df[\"label\"]), class_weights_array)}\n\n# =============================================================================\n# 6. Model Architecture with Optimized Transfer Learning\n# =============================================================================\ndef create_model():\n    \"\"\"\n    Create an EfficientNetB0 model with frozen layers and custom top.\n    \n    Returns:\n        Compiled Keras model\n    \"\"\"\n    # Create input layer with the correct shape\n    input_tensor = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n    \n    # Load pre-trained model with imagenet weights\n    base_model = EfficientNetB0(\n        include_top=False, \n        weights=\"imagenet\", \n        input_tensor=input_tensor\n    )\n    \n    # Freeze the first 70% of layers\n    freeze_until = int(len(base_model.layers) * 0.7)\n    for layer in base_model.layers[:freeze_until]:\n        layer.trainable = False\n    \n    # Add custom classification head\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dropout(0.5)(x)\n    x = Dense(256, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01))(x)\n    x = Dropout(0.4)(x)\n    # Ensure final layer uses float32 for numerical stability with softmax\n    output = Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n    \n    # Create model\n    model = Model(inputs=input_tensor, outputs=output)\n    \n    # Compile with Adam optimizer\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    \n    return model\n\n# =============================================================================\n# 7. Learning Rate Scheduler and Callbacks\n# =============================================================================\ndef cosine_decay_schedule(epoch, lr):\n    \"\"\"\n    Cosine decay learning rate schedule.\n    \n    Args:\n        epoch: Current epoch\n        lr: Current learning rate\n        \n    Returns:\n        New learning rate\n    \"\"\"\n    initial_lr = 1e-4\n    return initial_lr * (1 + math.cos(math.pi * epoch / EPOCHS)) / 2\n\n# Create callbacks\ncallbacks = [\n    # Save checkpoints (using proper file extension for weights)\n    keras.callbacks.ModelCheckpoint(\n        'best_model.weights.h5',\n        monitor='val_accuracy',\n        save_best_only=True,\n        save_weights_only=True,  # Save only weights to reduce I/O\n        verbose=1\n    ),\n    # Early stopping\n    keras.callbacks.EarlyStopping(\n        monitor='val_loss',\n        patience=5,\n        restore_best_weights=True,\n        verbose=1\n    ),\n    # Learning rate scheduling\n    keras.callbacks.ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.5,\n        patience=3,\n        min_lr=1e-6,\n        verbose=1\n    ),\n    # Log training metrics\n    keras.callbacks.CSVLogger('training_log.csv', append=True),\n    # Memory cleanup after each epoch\n    MemoryCleanupCallback()\n\n]\n\n# =============================================================================\n# 8. Training\n# =============================================================================\ndef train_model(custom_callbacks=None, existing_model=None, quick_test=False):\n    \"\"\"\n    Train the model with the optimized pipeline.\n    \n    Args:\n        custom_callbacks: Additional callbacks to use during training\n        existing_model: Continue training this model if provided\n        quick_test: Whether this is a quick test run\n        \n    Returns:\n        Trained model and history\n    \"\"\"\n    # Create new model or use existing one\n    if existing_model is None:\n        model = create_model()\n        # Print model summary\n        model.summary()\n    else:\n        model = existing_model\n        print(\"Continuing training with existing model\")\n    \n    # Use custom callbacks if provided, otherwise use default callbacks\n    training_callbacks = custom_callbacks if custom_callbacks else callbacks\n    \n    # Adjust epochs and steps for quick test\n    current_epochs = 2 if quick_test else EPOCHS\n    current_steps = min(20, steps_per_epoch) if quick_test else steps_per_epoch\n    current_val_steps = min(10, validation_steps) if quick_test else validation_steps\n    \n    if quick_test:\n        print(f\"Quick test mode: {current_epochs} epochs, {current_steps} steps/epoch\")\n    \n    # Train model\n    history = model.fit(\n        train_ds,\n        epochs=current_epochs,\n        steps_per_epoch=current_steps,\n        validation_data=val_ds,\n        validation_steps=current_val_steps,\n        callbacks=training_callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    \n    return model, history\n\n# =============================================================================\n# 9. LR Finder - Fixed version with termination condition\n# =============================================================================\nclass LRFinder(keras.callbacks.Callback):\n    \"\"\"\n    Learning rate finder callback.\n    \n    This callback helps find the optimal learning rate by exponentially\n    increasing the learning rate during training and recording the loss.\n    \"\"\"\n    def __init__(self, min_lr=1e-7, max_lr=1e-2, steps=100, max_batches=1000):\n        super(LRFinder, self).__init__()\n        self.min_lr = min_lr\n        self.max_lr = max_lr\n        self.steps = steps\n        self.max_batches = max_batches  # Safety limit\n        self.lrs = []\n        self.losses = []\n        self.batch_counter = 0\n        \n    def on_train_begin(self, logs=None):\n        # Store original learning rate\n        self.original_lr = tf.keras.backend.get_value(self.model.optimizer.learning_rate)\n        # Set initial learning rate to minimum\n        tf.keras.backend.set_value(self.model.optimizer.learning_rate, self.min_lr)\n        self.optimizer = self.model.optimizer\n    \n    def on_train_batch_end(self, batch, logs=None):\n        # Get current learning rate\n        lr = tf.keras.backend.get_value(self.optimizer.learning_rate)\n        self.lrs.append(lr)\n        self.losses.append(logs.get('loss'))\n        \n        # Calculate new learning rate\n        new_lr = lr * (self.max_lr / self.min_lr) ** (1/self.steps)\n        tf.keras.backend.set_value(self.optimizer.learning_rate, new_lr)\n        \n        # Increment counter and check for termination\n        self.batch_counter += 1\n        if batch >= self.steps or self.batch_counter >= self.max_batches:\n            self.model.stop_training = True\n            \n    def on_train_end(self, logs=None):\n        # Restore original learning rate\n        tf.keras.backend.set_value(self.optimizer.learning_rate, self.original_lr)\n        \n    def plot_lr_finder(self):\n        \"\"\"Plot the learning rate finder results.\"\"\"\n        try:\n            import matplotlib.pyplot as plt\n            \n            plt.figure(figsize=(10, 6))\n            plt.plot(self.lrs, self.losses)\n            plt.xscale('log')\n            plt.xlabel('Learning Rate')\n            plt.ylabel('Loss')\n            plt.title('Learning Rate Finder')\n            plt.savefig('lr_finder_results.png')\n        except ImportError:\n            print(\"Matplotlib not available for plotting. Saving results to CSV instead.\")\n            import csv\n            with open('lr_finder_results.csv', 'w', newline='') as f:\n                writer = csv.writer(f)\n                writer.writerow(['learning_rate', 'loss'])\n                for lr, loss in zip(self.lrs, self.losses):\n                    writer.writerow([lr, loss])\n\n# =============================================================================\n# 10. Training with LR Finder\n# =============================================================================\ndef find_optimal_lr():\n    \"\"\"\n    Find the optimal learning rate using the LR Finder.\n    \n    Returns:\n        Suggested learning rate\n    \"\"\"\n    # Create model\n    model = create_model()\n    \n    # Create LR Finder callback\n    lr_finder = LRFinder(min_lr=1e-7, max_lr=1e-2, steps=100, max_batches=100)\n    \n    # Fit model for a few batches to find optimal LR\n    model.fit(\n        train_ds,\n        epochs=1,\n        steps_per_epoch=100,\n        callbacks=[lr_finder],\n        verbose=1\n    )\n    \n    # Plot results\n    lr_finder.plot_lr_finder()\n    \n    # Find the learning rate with the steepest negative gradient\n    losses = lr_finder.losses\n    lrs = lr_finder.lrs\n    \n    # Smoothing\n    smooth_losses = []\n    for i in range(len(losses)):\n        if i < 2 or i >= len(losses) - 2:\n            smooth_losses.append(losses[i])\n        else:\n            smooth_losses.append(sum(losses[i-2:i+3]) / 5)\n    \n    # Calculate gradients\n    gradients = []\n    for i in range(1, len(smooth_losses)):\n        gradients.append((smooth_losses[i] - smooth_losses[i-1]) / (lrs[i] - lrs[i-1]))\n    \n    # Find the point with the steepest negative gradient\n    steepest_idx = np.argmin(gradients)\n    optimal_lr = lrs[steepest_idx + 1] / 10  # Division by 10 is common practice\n    \n    print(f\"Suggested learning rate: {optimal_lr:.2e}\")\n    return optimal_lr\n\n# =============================================================================\n# 11. Evaluation\n# =============================================================================\ndef evaluate_model(model):\n    \"\"\"\n    Evaluate the model on the test set.\n    \n    Args:\n        model: Trained Keras model\n        \n    Returns:\n        Evaluation metrics\n    \"\"\"\n    # Evaluate model\n    loss, accuracy = model.evaluate(test_ds)\n    print(f\"\\nTest Loss: {loss:.4f}\")\n    print(f\"Test Accuracy: {accuracy:.4f}\")\n    \n    # Get predictions\n    predictions = np.argmax(model.predict(test_ds), axis=-1)\n    \n    # Get true labels\n    true_labels = []\n    for _, y in test_ds.unbatch():\n        true_labels.append(np.argmax(y.numpy()))\n    true_labels = np.array(true_labels)\n    \n    # Calculate F1 score\n    f1 = f1_score(true_labels, predictions, average='weighted')\n    print(f\"\\nWeighted F1-Score: {f1:.4f}\")\n    \n    # Print classification report\n    print(\"\\nClassification Report:\")\n    print(classification_report(\n        true_labels, \n        predictions, \n        target_names=classes,\n        zero_division=0\n    ))\n    \n    return {\n        'loss': loss,\n        'accuracy': accuracy,\n        'f1_score': f1,\n        'predictions': predictions,\n        'true_labels': true_labels\n    }\n\n# =============================================================================\n# 12. Fine-tune Model\n# =============================================================================\ndef fine_tune_model(model, epochs=5, custom_callbacks=None, quick_test=False):\n    \"\"\"\n    Fine-tune the model by unfreezing all layers.\n    \n    Args:\n        model: Trained model\n        epochs: Number of fine-tuning epochs\n        custom_callbacks: Additional callbacks to use during fine-tuning\n        quick_test: Whether this is a quick test run\n        \n    Returns:\n        Fine-tuned model and history\n    \"\"\"\n    # Unfreeze all layers\n    for layer in model.layers:\n        layer.trainable = True\n    \n    # Recompile with a lower learning rate\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    \n    # Use custom callbacks if provided, otherwise use default callbacks\n    training_callbacks = custom_callbacks if custom_callbacks else callbacks\n    \n    # Adjust epochs and steps for quick test\n    current_epochs = 2 if quick_test else epochs\n    current_steps = min(20, steps_per_epoch) if quick_test else steps_per_epoch\n    current_val_steps = min(10, validation_steps) if quick_test else validation_steps\n    \n    if quick_test:\n        print(f\"Quick fine-tuning: {current_epochs} epochs, {current_steps} steps/epoch\")\n    \n    # Fine-tune\n    history = model.fit(\n        train_ds,\n        epochs=current_epochs,\n        steps_per_epoch=current_steps,\n        validation_data=val_ds,\n        validation_steps=current_val_steps,\n        callbacks=training_callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    \n    return model, history\n\n# =============================================================================\n# 13. Performance Monitoring\n# =============================================================================\nclass PerformanceMonitor(keras.callbacks.Callback):\n    \"\"\"\n    Monitor and log training performance metrics like time per step.\n    \"\"\"\n    def __init__(self):\n        super(PerformanceMonitor, self).__init__()\n        self.batch_times = []\n        self.epoch_start_time = None\n        \n    def on_epoch_begin(self, epoch, logs=None):\n        self.epoch_start_time = time.time()\n        self.batch_start_time = time.time()\n        self.batch_times = []\n        \n    def on_batch_end(self, batch, logs=None):\n        batch_time = time.time() - self.batch_start_time\n        self.batch_times.append(batch_time)\n        self.batch_start_time = time.time()\n        \n        # Log every 50 batches\n        if batch % 50 == 0:\n            avg_time = sum(self.batch_times[-50:]) / min(50, len(self.batch_times))\n            print(f\"\\nBatch {batch} - Avg time: {avg_time*1000:.2f}ms/step\")\n            \n            # Try to get GPU memory info if available\n            try:\n                import subprocess\n                gpu_info = subprocess.check_output(['nvidia-smi', '--query-gpu=memory.used', '--format=csv,noheader']).decode('utf-8')\n                print(f\"GPU Memory: {gpu_info.strip()}\")\n            except:\n                pass\n        \n    def on_epoch_end(self, epoch, logs=None):\n        epoch_time = time.time() - self.epoch_start_time\n        avg_batch_time = sum(self.batch_times) / len(self.batch_times)\n        print(f\"\\nEpoch {epoch+1} completed in {epoch_time:.2f}s - Avg: {avg_batch_time*1000:.2f}ms/step\")\n\n# =============================================================================\n# 14. Main training loop\n# =============================================================================\ndef main():\n    \"\"\"Main function to run the training pipeline.\"\"\"\n    # Print TF and GPU info\n    print(f\"TensorFlow version: {tf.__version__}\")\n    print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n    \n    # Print dataset info\n    print(f\"Train samples: {len(train_df)} ({len(train_df[train_df['source'] == 'fer2013'])} FER, {len(train_df[train_df['source'] == 'affectnet'])} AffectNet)\")\n    print(f\"Validation samples: {len(val_df)}\")\n    print(f\"Test samples: {len(test_df)}\")\n    print(f\"Classes: {classes}\")\n    print(f\"Steps per epoch: {steps_per_epoch}\")\n    print(f\"Batch size: {BATCH_SIZE}\")\n    \n    # Set to True to run a quick test first, or False for full training\n    run_quick_test = True  # Change this manually if needed\n    \n    if run_quick_test:\n        print(\"\\nRunning quick test (2 epochs with limited steps)...\")\n        # Define variables for testing\n        quick_test_epochs = 2\n        quick_test_steps = min(20, steps_per_epoch)\n        print(f\"Quick test settings: {quick_test_epochs} epochs, {quick_test_steps} steps per epoch\")\n    \n    # Create performance monitor\n    perf_monitor = PerformanceMonitor()\n    \n    # Add performance monitor to callbacks\n    training_callbacks = callbacks + [perf_monitor]\n    \n    try:\n        # Find optimal learning rate (optional)\n        # optimal_lr = find_optimal_lr()\n        \n        # Train model (with quick test if selected)\n        print(\"\\n=== Starting initial training phase ===\")\n        \n        if run_quick_test:\n            # Run a quick test first\n            print(\"\\n=== Running quick test ===\")\n            model, quick_history = train_model(\n                custom_callbacks=training_callbacks,\n                quick_test=True\n            )\n            \n            # After successful quick test, continue with full training\n            print(\"\\n=== Quick test complete, continuing with full training ===\")\n            model, history = train_model(\n                custom_callbacks=training_callbacks,\n                existing_model=model\n            )\n        else:\n            # Full training from the start\n            model, history = train_model(custom_callbacks=training_callbacks)\n            \n            # Evaluate model after initial training\n            print(\"\\n=== Evaluating after initial training ===\")\n            metrics = evaluate_model(model)\n            \n            # Fine-tune model (with quick test mode if enabled)\n            print(\"\\n=== Starting fine-tuning phase ===\")\n            model, ft_history = fine_tune_model(\n                model, \n                epochs=5, \n                custom_callbacks=training_callbacks,\n                quick_test=run_quick_test\n            )\n        \n        # Final evaluation\n        print(\"\\n=== Final evaluation ===\")\n        final_metrics = evaluate_model(model)\n        \n        # Save the final model\n        model.save(\"final_emotion_model.keras\")\n        \n        print(\"\\nTraining complete! Final model saved as 'final_emotion_model.keras'\")\n        \n    except Exception as e:\n        import traceback\n        print(\"\\n*** ERROR DURING TRAINING ***\")\n        print(traceback.format_exc())\n        print(\"\\nDetailed error:\", str(e))\n        \n        # Try to save the model if it exists\n        try:\n            if 'model' in locals():\n                print(\"Attempting to save the model before exiting...\")\n                model.save(\"emergency_save_model.keras\")\n                print(\"Model saved as emergency_save_model.keras\")\n        except Exception as save_error:\n            print(f\"Failed to save model: {save_error}\")\n    \nif __name__ == \"__main__\":\n    import time\n    start_time = time.time()\n    main()\n    total_time = time.time() - start_time\n    print(f\"\\nTotal execution time: {total_time/60:.2f} minutes\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Version 5.0 orginal working code slightly\n\nimport os\nimport glob\nimport math\nimport numpy as np\nimport pandas as pd\nimport itertools\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport time\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Input\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\n\nimport logging\nlogging.basicConfig(level=logging.INFO)\ntf.get_logger().setLevel(logging.INFO)\n\nimport gc\nclass MemoryCleanup(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        gc.collect()\n        tf.keras.backend.clear_session()\n\n\n# =============================================================================\n# Define key parameters\n# =============================================================================\nimg_size = 96         # We upscale FER images to 96x96\nbatch_size = 64\nepochs = 30\n\n# =============================================================================\n# Learning Rate Finder Callback (Fixed)\n# =============================================================================\nclass LRFinder(tf.keras.callbacks.Callback):\n    def __init__(self, min_lr=1e-6, max_lr=1e-2, steps=100):\n        super(LRFinder, self).__init__()\n        self.min_lr = min_lr\n        self.max_lr = max_lr\n        self.steps = steps\n        self.lrs = []\n        self.losses = []\n        \n    def on_train_begin(self, logs=None):\n        # Use optimizer.learning_rate (compatible with LossScaleOptimizer)\n        self.original_lr = tf.keras.backend.get_value(self.model.optimizer.learning_rate)\n        tf.keras.backend.set_value(self.model.optimizer.learning_rate, self.min_lr)\n        self.optimizer = self.model.optimizer\n    \n    def on_batch_end(self, batch, logs=None):\n        lr = tf.keras.backend.get_value(self.optimizer.learning_rate)\n        self.lrs.append(lr)\n        self.losses.append(logs.get('loss'))\n        new_lr = lr * (self.max_lr / self.min_lr) ** (1/self.steps)\n        tf.keras.backend.set_value(self.optimizer.learning_rate, new_lr)\n        if batch >= self.steps:\n            self.model.stop_training = True\n            \n    def on_train_end(self, logs=None):\n        tf.keras.backend.set_value(self.optimizer.learning_rate, self.original_lr)\n\n# =============================================================================\n# 1. Build a DataFrame from the dataset directory structure\n# =============================================================================\ndef build_image_df(root_dir, subfolders=[\"fer2013\", \"affectnet\"]):\n    \"\"\"\n    Scans the given root directory (Train or Test) and returns a DataFrame with columns:\n      - filepath: full path to the image file\n      - label: the emotion (parent folder name)\n      - source: the subfolder name (e.g., fer2013 or affectnet)\n    Assumes directory structure: root_dir/emotion/subfolder/image.jpg\n    \"\"\"\n    data = []\n    emotions = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n    for emotion in emotions:\n        emotion_path = os.path.join(root_dir, emotion)\n        for sub in subfolders:\n            sub_path = os.path.join(emotion_path, sub)\n            if os.path.exists(sub_path):\n                for img_file in os.listdir(sub_path):\n                    if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n                        data.append({\n                            \"filepath\": os.path.join(sub_path, img_file),\n                            \"label\": emotion,\n                            \"source\": sub\n                        })\n    return pd.DataFrame(data)\n\n# =============================================================================\n# 2. Dataset Paths & DataFrame Creation\n# =============================================================================\ndata_dir = \"/kaggle/input/custom-fer2013affectnet/Custom_ferAffect2013net\"\ntrain_dir = os.path.join(data_dir, \"Train\")   # Case-sensitive!\ntest_dir  = os.path.join(data_dir, \"Test\")\n\ntrain_df_full = build_image_df(train_dir)\ntest_df = build_image_df(test_dir)\n\nprint(\"Train DataFrame shape:\", train_df_full.shape)\nprint(\"Test DataFrame shape:\", test_df.shape)\n\n# Additional Plots: Separate by Source (Optional)\nfer_df = train_df_full[train_df_full[\"source\"] == \"fer2013\"]\naff_df = train_df_full[train_df_full[\"source\"] == \"affectnet\"]\n\nplt.figure(figsize=(14, 6))\nplt.subplot(1, 2, 1)\nsns.countplot(x=\"label\", data=fer_df, palette=\"coolwarm\")\nplt.title(\"FER2013 Training Data Volume\")\nplt.xlabel(\"Emotion Label\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=45)\n\nplt.subplot(1, 2, 2)\nsns.countplot(x=\"label\", data=aff_df, palette=\"Spectral\")\nplt.title(\"AffectNet Training Data Volume\")\nplt.xlabel(\"Emotion Label\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=45)\n\nplt.tight_layout()\nplt.show()\n\n\n# =============================================================================\n# 3. Split Training Data into Train & Validation Sets\n# =============================================================================\ntrain_df, val_df = train_test_split(train_df_full, test_size=0.2, stratify=train_df_full[\"label\"], random_state=42)\n\n# =============================================================================\n# X. Visualization Code for DataFrames\n# =============================================================================\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set Seaborn style for a beautiful design.\nsns.set(style=\"whitegrid\", context=\"talk\", palette=\"viridis\")\n\n# Plot 1: Training Data (Combined by Source)\nplt.figure(figsize=(16, 5))\nplt.subplot(1, 3, 1)\nsns.countplot(x=\"label\", hue=\"source\", data=train_df_full, palette=\"viridis\")\nplt.title(\"Training Data Volume (Combined)\")\nplt.xlabel(\"Emotion Label\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=45)\nplt.legend(title=\"Source\")\n\n# Plot 2: Validation Data (Combined by Source)\nplt.subplot(1, 3, 2)\nif \"source\" in val_df.columns:\n    sns.countplot(x=\"label\", hue=\"source\", data=val_df, palette=\"viridis\")\n    plt.legend(title=\"Source\")\nelse:\n    sns.countplot(x=\"label\", data=val_df, palette=\"viridis\")\nplt.title(\"Validation Data Volume\")\nplt.xlabel(\"Emotion Label\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=45)\n\n# Plot 3: Test Data\nplt.subplot(1, 3, 3)\nif \"source\" in test_df.columns:\n    sns.countplot(x=\"label\", hue=\"source\", data=test_df, palette=\"viridis\")\n    plt.legend(title=\"Source\")\nelse:\n    sns.countplot(x=\"label\", data=test_df, palette=\"viridis\")\nplt.title(\"Test Data Volume\")\nplt.xlabel(\"Emotion Label\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=45)\n\nplt.tight_layout()\nplt.show()\n\n# =============================================================================\n# 4. Source-Specific Augmentation Functions\n# =============================================================================\ndef apply_fer_augmentations(img):\n    # Gentle augmentations for low-res FER2013 images\n    img = tf.image.random_flip_left_right(img)\n    img = tf.image.random_brightness(img, max_delta=0.1)\n    return img\n\ndef apply_affectnet_augmentations(img):\n    # Stronger augmentations for high-res AffectNet images\n    img = tf.image.random_flip_left_right(img)\n    img = tf.image.random_brightness(img, max_delta=0.3)\n    img = tf.image.random_contrast(img, lower=0.8, upper=1.2)\n    return img\n\ndef augment_based_on_source(img, source):\n    # Source-aware augmentation: assume img is a tensor in [0,1]\n    if source == \"fer2013\":\n        img = tf.image.rgb_to_grayscale(img)  # Ensure it's grayscale\n        img = apply_fer_augmentations(img)\n    else:\n        img = apply_affectnet_augmentations(img)\n    return img\n\n# =============================================================================\n# 5. Create Separate Generators for FER2013 and AffectNet\n# =============================================================================\n# Create a simpler, more robust training loop\n# First, simplify your dataset creation\n\nclasses = sorted(train_df_full[\"label\"].unique())\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255\n    #preprocessing_function=lambda x: np.repeat(x, 3, axis=-1) if x.shape[-1] == 1 else x\n)\n\nsimple_train_gen = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=(img_size, img_size),\n    color_mode=\"rgb\",  # Use rgb for all images to simplify\n    class_mode=\"categorical\",\n    classes=classes,\n    batch_size=16,  # Reduced batch size\n    shuffle=True\n)\n\n# Split the training DataFrame by source\nfer_train_df = train_df[train_df[\"source\"] == \"fer2013\"]\naff_train_df = train_df[train_df[\"source\"] == \"affectnet\"]\n\n# For FER2013: load as grayscale with gentle augmentation.\nfer_aug_params = {\n    \"rescale\": 1./255,\n    \"rotation_range\": 15,\n    \"width_shift_range\": 0.1,\n    \"height_shift_range\": 0.1,\n    \"brightness_range\": [0.8, 1.2]\n}\nfer_datagen = ImageDataGenerator(**fer_aug_params)\nfer_gen = fer_datagen.flow_from_dataframe(\n    dataframe=fer_train_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=(img_size, img_size),\n    color_mode=\"grayscale\",\n    class_mode=\"categorical\",\n    classes=classes,\n    batch_size=64,\n    shuffle=True\n)\n\n# For AffectNet: load as RGB with stronger augmentation.\naff_aug_params = {\n    \"rescale\": 1./255,\n    \"rotation_range\": 30,  # Reduced from 40\n    \"brightness_range\": [0.7, 1.3],  # Reduced from [0.5, 1.5]\n    \"zoom_range\": 0.1  # Reduced from 0.2\n}\naff_datagen = ImageDataGenerator(**aff_aug_params)\naff_gen = aff_datagen.flow_from_dataframe(\n    dataframe=aff_train_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=(img_size, img_size),\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    classes=classes,\n    batch_size=64,\n    shuffle=True\n)\n\n#######################################################################################\n# If your images are grayscale and need to be converted to RGB, add this:\ndef convert_grayscale_to_rgb(batch_x, batch_y):\n    # If the last dimension is 1, repeat it 3 times\n    if batch_x.shape[-1] == 1:\n        batch_x = np.repeat(batch_x, 3, axis=-1)\n    return batch_x, batch_y\n\n# Create a wrapper for your generator\ndef rgb_generator_wrapper(gen):\n    for batch_x, batch_y in gen:\n        yield convert_grayscale_to_rgb(batch_x, batch_y)\n\n# Use the wrapped generator\nrgb_train_gen = rgb_generator_wrapper(simple_train_gen)\n\n#######################################################################################\n\n# Calculate steps for each dataset.\nsteps_fer = math.ceil(len(fer_train_df) / 64)  # 22986/32=719\nsteps_aff = math.ceil(len(aff_train_df) / 64)  # 23209/32=726\nsteps_per_epoch = steps_fer + steps_aff        # 1445\n\n#steps_fer = math.ceil(fer_train_df.shape[0] / 32)\n#steps_aff = math.ceil(aff_train_df.shape[0] / 32)\n#steps_per_epoch = steps_fer + steps_aff\n#print(f\"Steps per epoch: {steps_per_epoch}\")\n\n# After splitting in Section 3:\nprint(f\"Train samples: {len(train_df)}\")  # Should be ~36k (80% of 46k)\nprint(f\"FER samples: {len(fer_train_df)}\")  # ~18k (80% of 23k)\nprint(f\"AffectNet samples: {len(aff_train_df)}\")  # ~18k (80% of 23k)\n\n# =============================================================================\n# 6. Enhanced Upscaling for FER2013: Bicubic interpolation and channel replication.\n# =============================================================================\ndef preprocess_fer_batch(batch):\n    # Input: (batch_size, H, W, 1)\n    upscaled = tf.image.resize(batch, [img_size, img_size], method=\"bicubic\")\n    return tf.repeat(upscaled, repeats=3, axis=-1)  # Now shape: (batch_size, img_size, img_size, 3)\n\n# Wrap the FER generator into a tf.data.Dataset.\ndef fer_gen_wrapper():\n    for batch in fer_gen:\n        images, labels = batch\n        images = tf.convert_to_tensor(images)\n        images = preprocess_fer_batch(images)\n        yield (images, labels)\n\nds_fer = tf.data.Dataset.from_generator(\n    fer_gen_wrapper,\n    output_signature=(\n        tf.TensorSpec(shape=(None, img_size, img_size, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(None, len(fer_gen.class_indices)), dtype=tf.float32)\n    )\n)\n\n# For AffectNet, simply convert batches to tensors.\ndef aff_gen_wrapper():\n    for batch in aff_gen:\n        images, labels = batch\n        images = tf.convert_to_tensor(images)\n        yield (images, labels)\n\nds_aff = tf.data.Dataset.from_generator(\n    aff_gen_wrapper,\n    output_signature=(\n        tf.TensorSpec(shape=(None, img_size, img_size, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(None, len(aff_gen.class_indices)), dtype=tf.float32)\n    )\n)\n\n# =============================================================================\n# 7. Combine the Two Datasets and Optimize Pipeline\n# =============================================================================\n# Both ds_fer and ds_aff already yield batches, so do NOT apply an additional .batch() here.\ncombined_ds = ds_fer.concatenate(ds_aff)\ncombined_ds = combined_ds.shuffle(buffer_size=200).prefetch(2)\n\n#combined_ds = ds_fer.concatenate(ds_aff)\n#combined_ds = combined_ds.shuffle(500).prefetch(tf.data.AUTOTUNE)\n\n# =============================================================================\n# 8. Compute Class Weights\n# =============================================================================\nclass_weights = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.unique(train_df[\"label\"]),\n    y=train_df[\"label\"]\n)\nlabel_to_index = fer_gen.class_indices  # Assumes consistency across sources.\nclass_weights = {label_to_index[label]: weight for label, weight in zip(np.unique(train_df[\"label\"]), class_weights)}\n\n# =============================================================================\n# 9. Model Architecture\n# =============================================================================\n# (Optional) Enable mixed precision\npolicy = tf.keras.mixed_precision.Policy('mixed_float16')\ntf.keras.mixed_precision.set_global_policy(policy)\n\n#from tensorflow.keras.applications import MobileNetV2\n#base_model = MobileNetV2(include_top=False, weights=\"imagenet\", \n#                        input_tensor=input_tensor,\n#                        input_shape=(img_size, img_size, 3))\n\ninput_tensor = Input(shape=(img_size, img_size, 3))\nbase_model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_tensor=input_tensor)\nbase_model.trainable = True\n\nfreeze_until = int(len(base_model.layers) * 0.7)\nfor layer in base_model.layers[:freeze_until]:\n    layer.trainable = False\n\nx = GlobalAveragePooling2D()(base_model.output)\nx = Dropout(0.5)(x)\nx = Dense(256, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01))(x)\nx = Dropout(0.4)(x)\noutput = Dense(len(classes), activation=\"softmax\", dtype=\"float32\")(x)\nmodel = Model(inputs=input_tensor, outputs=output)\n\n# =============================================================================\n# 10. Focal Loss (Optional)\n# =============================================================================\ndef focal_loss(gamma=2.0, alpha=0.25):\n    def loss_fn(y_true, y_pred):\n        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0 - 1e-7)\n        cross_entropy = -y_true * tf.math.log(y_pred)\n        loss = alpha * tf.math.pow(1 - y_pred, gamma) * cross_entropy\n        return tf.reduce_mean(tf.reduce_sum(loss, axis=1))\n    return loss_fn\n\nloss_function = focal_loss()  # Or use \"categorical_crossentropy\"\n\nsimple_model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(len(classes), activation='softmax')\n])\n\nsimple_model.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-4),\n    loss=loss_function, #'categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# =============================================================================\n# 11. Training Configuration & Callbacks\n# =============================================================================\n\ndef cosine_annealing(epoch, lr):\n    initial_lr = 1e-4\n    return initial_lr * (1 + math.cos(math.pi * epoch / epochs)) / 2\n\n# Minimal callback list\nminimal_callbacks = [\n    tf.keras.callbacks.ModelCheckpoint('checkpoint.keras', save_best_only=True),\n    tf.keras.callbacks.CSVLogger('simple_training_log.csv', append=True)\n]\n\n# Create a validation dataset from val_df using a similar pipeline for FER images.\nval_datagen = ImageDataGenerator(rescale=1./255)\nval_generator = val_datagen.flow_from_dataframe(\n    dataframe=val_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=(img_size, img_size),\n    color_mode=\"grayscale\",\n    classes=classes,\n    batch_size=batch_size,\n    shuffle=False\n)\ndef val_gen_wrapper():\n    for batch in val_generator:\n        images, labels = batch\n        images = preprocess_fer_batch(images)\n        yield (images, labels)\n\nds_val = tf.data.Dataset.from_generator(\n    lambda: val_gen_wrapper(),\n    output_signature=(\n        tf.TensorSpec(shape=(None, img_size, img_size, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(None, len(classes)), dtype=tf.float32)\n    )\n).prefetch(tf.data.AUTOTUNE)\n\nstart_time = time.time()\nprint(\"Starting simplified training...\")\nsimple_history = simple_model.fit(\n    simple_train_gen,\n    epochs=2,\n    steps_per_epoch=50,  # Drastically reduced to test\n    validation_data=ds_val, #val_generator,\n    validation_steps=10,  # Also reduced\n    callbacks=minimal_callbacks\n)\nprint(\"Simplified training completed!\")\n\n# Save the trained model\nmodel.save(\"final_emotion_model.keras\")\n\n# =============================================================================\n# 12. Evaluation & Visualization on Test Data\n# =============================================================================\n# First, create a clean test generator without any preprocessing\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=(img_size, img_size),\n    color_mode=\"grayscale\",  # Load as grayscale first\n    class_mode=\"categorical\",\n    classes=classes,\n    batch_size=batch_size,\n    shuffle=False\n)\n\n# Then create a simpler wrapper that ensures exactly 3 channels\ndef test_wrapper():\n    for batch_x, batch_y in test_generator:\n        # Convert grayscale to RGB once - explicitly tracking shape\n        if batch_x.shape[-1] == 1:\n            # This creates exactly 3 channels\n            batch_x_rgb = np.concatenate([batch_x, batch_x, batch_x], axis=-1)\n            yield batch_x_rgb, batch_y\n        else:\n            yield batch_x, batch_y\n\n# Create the dataset with proper output signature\ntest_ds = tf.data.Dataset.from_generator(\n    test_wrapper,\n    output_signature=(\n        tf.TensorSpec(shape=(None, img_size, img_size, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(None, len(classes)), dtype=tf.float32)\n    )\n).batch(batch_size).prefetch(2)\n\n# Now evaluate with this clean dataset\nloss, accuracy = simple_model.evaluate(test_ds)\n\nprint(f\"\\nTest Loss: {loss:.4f}\")\nprint(f\"Test Accuracy: {accuracy:.4f}\")\n\npredictions = np.argmax(simple_model.predict(test_generator), axis=-1)\ntrue_labels = test_generator.classes\n\nprint(f\"\\nWeighted F1-Score: {f1_score(true_labels, predictions, average='weighted'):.4f}\")\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(confusion_matrix(true_labels, predictions), \n            annot=True, fmt=\"d\", \n            cmap=\"Blues\",\n            xticklabels=test_generator.class_indices.keys(),\n            yticklabels=test_generator.class_indices.keys())\nplt.title(\"Confusion Matrix\")\nplt.show()\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(true_labels, predictions, target_names=test_generator.class_indices.keys()))\n\nplt.figure(figsize=(14, 5))\nplt.subplot(1, 2, 1)\nplt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\nplt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\nplt.legend()\nplt.title(\"Accuracy Curves\")\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history[\"loss\"], label=\"Training Loss\")\nplt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\nplt.legend()\nplt.title(\"Loss Curves\")\nplt.show()\n\n# =============================================================================\n# 13. Testing Saved Model on Individual Test Images\n# =============================================================================\nsaved_model = keras.models.load_model(\"final_emotion_model.keras\", compile=False)\nclass_labels = list(test_generator.class_indices.keys())\n\nfor class_name in class_labels:\n    class_path = os.path.join(test_dir, class_name)\n    if os.path.exists(class_path):\n        test_images = os.listdir(class_path)\n        print(f\"\\nTesting images for class: {class_name}\")\n        for img_name in test_images[:5]:\n            img_path = os.path.join(class_path, img_name)\n            # Load as grayscale then convert to RGB.\n            img = keras.preprocessing.image.load_img(img_path, target_size=(img_size, img_size), color_mode=\"grayscale\")\n            img_array = keras.preprocessing.image.img_to_array(img) / 255.0\n            img_array = np.repeat(img_array, 3, axis=-1)\n            img_array = np.expand_dims(img_array, axis=0)\n            \n            prediction = saved_model.predict(img_array)\n            predicted_class = class_labels[np.argmax(prediction)]\n            confidence = np.max(prediction)\n            \n            plt.imshow(img_array[0].astype(\"float32\"))\n            plt.title(f\"Predicted: {predicted_class}\\nConfidence: {confidence:.2f}\")\n            plt.axis(\"off\")\n            plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"/kaggle/input/custom-fer2013affectnet/Custom_ferAffect2013net\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fer_dirs = glob.glob(os.path.join(train_dir, \"*\", \"fer2013\"))\naff_dirs = glob.glob(os.path.join(train_dir, \"*\", \"affectnet\"))\nprint(\"FER directories found:\", glob.glob(os.path.join(train_dir, \"*\", \"fer2013\")))\nprint(\"AffectNet directories found:\", glob.glob(os.path.join(train_dir, \"*\", \"affectnet\")))\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# NEW Experimental\n\nimport tensorflow.keras.backend as K\nimport os\nimport glob\nimport math\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport time\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom tensorflow.keras.applications import EfficientNetB0, MobileNetV3Small\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Input, Concatenate\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.metrics import AUC, Precision, Recall\n\n# =============================================================================\n# Define key parameters\n# =============================================================================\nimg_size = 96         # We upscale FER images to 96x96\nbatch_size = 64       # Smaller batch size to avoid memory issues\nepochs = 20           # Increase epochs, we'll use early stopping\nmodel_type = \"efficientnet\"  # Options: \"efficientnet\", \"mobilenet\", \"ensemble\"\n\n# =============================================================================\n# 1. Build a DataFrame from the dataset directory structure\n# =============================================================================\ndef build_image_df(root_dir, subfolders=[\"fer2013\", \"affectnet\"]):\n    \"\"\"\n    Scans the given root directory (Train or Test) and returns a DataFrame with columns:\n      - filepath: full path to the image file\n      - label: the emotion (parent folder name)\n      - source: the subfolder name (e.g., fer2013 or affectnet)\n    Assumes directory structure: root_dir/emotion/subfolder/image.jpg\n    \"\"\"\n    data = []\n    emotions = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n    for emotion in emotions:\n        emotion_path = os.path.join(root_dir, emotion)\n        for sub in subfolders:\n            sub_path = os.path.join(emotion_path, sub)\n            if os.path.exists(sub_path):\n                for img_file in os.listdir(sub_path):\n                    if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n                        data.append({\n                            \"filepath\": os.path.join(sub_path, img_file),\n                            \"label\": emotion,\n                            \"source\": sub\n                        })\n    return pd.DataFrame(data)\n\n# =============================================================================\n# 2. Dataset Paths & DataFrame Creation\n# =============================================================================\n# Adjust this path to your actual data directory\ndata_dir = \"/kaggle/input/custom-fer2013affectnet/Custom_ferAffect2013net\"\ntrain_dir = os.path.join(data_dir, \"Train\")\ntest_dir  = os.path.join(data_dir, \"Test\")\n\ntrain_df_full = build_image_df(train_dir)\ntest_df = build_image_df(test_dir)\n\nprint(\"Train DataFrame shape:\", train_df_full.shape)\nprint(\"Test DataFrame shape:\", test_df.shape)\n\n# =============================================================================\n# 3. Split Training Data into Train & Validation Sets\n# =============================================================================\ntrain_df, val_df = train_test_split(train_df_full, test_size=0.2, stratify=train_df_full[\"label\"], random_state=42)\n\n# =============================================================================\n# 4. Data Visualization (Optional)\n# =============================================================================\ndef plot_data_distribution():\n    # Plot distribution of emotions by source\n    plt.figure(figsize=(16, 6))\n    \n    # Combined\n    plt.subplot(1, 3, 1)\n    sns.countplot(x=\"label\", data=train_df_full, palette=\"viridis\")\n    plt.title(\"Full Dataset Distribution\")\n    plt.xlabel(\"Emotion\")\n    plt.ylabel(\"Count\")\n    plt.xticks(rotation=45)\n    \n    # FER2013\n    plt.subplot(1, 3, 2)\n    sns.countplot(x=\"label\", data=train_df_full[train_df_full[\"source\"] == \"fer2013\"], palette=\"coolwarm\")\n    plt.title(\"FER2013 Distribution\")\n    plt.xlabel(\"Emotion\")\n    plt.ylabel(\"Count\")\n    plt.xticks(rotation=45)\n    \n    # AffectNet\n    plt.subplot(1, 3, 3)\n    sns.countplot(x=\"label\", data=train_df_full[train_df_full[\"source\"] == \"affectnet\"], palette=\"Spectral\")\n    plt.title(\"AffectNet Distribution\")\n    plt.xlabel(\"Emotion\")\n    plt.ylabel(\"Count\")\n    plt.xticks(rotation=45)\n    \n    plt.tight_layout()\n    plt.show()\n\n# Uncomment to visualize data distribution\n# plot_data_distribution()\n\n# =============================================================================\n# 5. Optimized Data Generators\n# =============================================================================\n# Get emotion classes\nclasses = sorted(train_df_full[\"label\"].unique())\nprint(f\"Classes: {classes}\")\n\n# Define preprocessing functions\ndef preprocess_fer(img):\n    \"\"\"Convert grayscale to RGB and resize to target size\"\"\"\n    # Convert to 3 channels by repeating the grayscale channel\n    img = tf.image.grayscale_to_rgb(img)\n    # Resize to target size\n    img = tf.image.resize(img, [img_size, img_size], method='bicubic')\n    return img / 255.0  # Normalize\n\ndef preprocess_affectnet(img):\n    \"\"\"Resize RGB image to target size\"\"\"\n    img = tf.image.resize(img, [img_size, img_size])\n    return img / 255.0  # Normalize\n\n# Create training data generators\ndef create_generators():\n    # Common augmentation parameters\n    common_aug = {\n        'horizontal_flip': True,\n        'rotation_range': 20,\n        'fill_mode': 'nearest'\n    }\n    \n    # For FER2013 (grayscale)\n    fer_datagen = ImageDataGenerator(\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        zoom_range=0.1,\n        brightness_range=[0.8, 1.2],\n        **common_aug\n    )\n    \n    fer_train_gen = fer_datagen.flow_from_dataframe(\n        dataframe=train_df[train_df[\"source\"] == \"fer2013\"],\n        x_col=\"filepath\",\n        y_col=\"label\",\n        target_size=(img_size, img_size),\n        color_mode=\"grayscale\",\n        class_mode=\"categorical\",\n        classes=classes,\n        batch_size=batch_size,\n        shuffle=True\n    )\n    \n    # For AffectNet (RGB)\n    aff_datagen = ImageDataGenerator(\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        zoom_range=0.2,\n        brightness_range=[0.7, 1.3],\n        **common_aug\n    )\n    \n    aff_train_gen = aff_datagen.flow_from_dataframe(\n        dataframe=train_df[train_df[\"source\"] == \"affectnet\"],\n        x_col=\"filepath\",\n        y_col=\"label\",\n        target_size=(img_size, img_size),\n        color_mode=\"rgb\",\n        class_mode=\"categorical\",\n        classes=classes,\n        batch_size=batch_size,\n        shuffle=True\n    )\n    \n    # Validation generators - no augmentation\n    val_datagen = ImageDataGenerator()\n    \n    fer_val_gen = val_datagen.flow_from_dataframe(\n        dataframe=val_df[val_df[\"source\"] == \"fer2013\"],\n        x_col=\"filepath\",\n        y_col=\"label\",\n        target_size=(img_size, img_size),\n        color_mode=\"grayscale\",\n        class_mode=\"categorical\",\n        classes=classes,\n        batch_size=batch_size,\n        shuffle=False\n    )\n    \n    aff_val_gen = val_datagen.flow_from_dataframe(\n        dataframe=val_df[val_df[\"source\"] == \"affectnet\"],\n        x_col=\"filepath\",\n        y_col=\"label\",\n        target_size=(img_size, img_size),\n        color_mode=\"rgb\",\n        class_mode=\"categorical\",\n        classes=classes,\n        batch_size=batch_size,\n        shuffle=False\n    )\n    \n    return fer_train_gen, aff_train_gen, fer_val_gen, aff_val_gen\n\n# Create test generator\ndef create_test_generator():\n    test_datagen = ImageDataGenerator()\n    \n    # Split test data by source\n    fer_test_df = test_df[test_df[\"source\"] == \"fer2013\"]\n    aff_test_df = test_df[test_df[\"source\"] == \"affectnet\"]\n    \n    fer_test_gen = test_datagen.flow_from_dataframe(\n        dataframe=fer_test_df,\n        x_col=\"filepath\",\n        y_col=\"label\",\n        target_size=(img_size, img_size),\n        color_mode=\"grayscale\",\n        class_mode=\"categorical\",\n        classes=classes,\n        batch_size=batch_size,\n        shuffle=False\n    )\n    \n    aff_test_gen = test_datagen.flow_from_dataframe(\n        dataframe=aff_test_df,\n        x_col=\"filepath\",\n        y_col=\"label\",\n        target_size=(img_size, img_size),\n        color_mode=\"rgb\",\n        class_mode=\"categorical\",\n        classes=classes,\n        batch_size=batch_size,\n        shuffle=False\n    )\n    \n    return fer_test_gen, aff_test_gen\n\nfer_train_gen, aff_train_gen, fer_val_gen, aff_val_gen = create_generators()\nfer_test_gen, aff_test_gen = create_test_generator()\n\n# =============================================================================\n# 6. Custom Data Generator that combines both sources\n# =============================================================================\nclass CombinedGenerator:\n    def __init__(self, fer_gen, aff_gen, batch_size=32):\n        self.fer_gen = fer_gen\n        self.aff_gen = aff_gen\n        self.batch_size = batch_size\n        self.n_classes = len(classes)\n        self.fer_samples = len(fer_gen.filenames)\n        self.aff_samples = len(aff_gen.filenames)\n        self.total_samples = self.fer_samples + self.aff_samples\n        \n    def __len__(self):\n        return (self.total_samples + self.batch_size - 1) // self.batch_size\n    \n    def __iter__(self):\n        self.fer_iter = iter(self.fer_gen)\n        self.aff_iter = iter(self.aff_gen)\n        return self\n    \n    def __next__(self):\n        # Randomly choose which generator to pull from based on dataset size ratio\n        if np.random.random() < self.fer_samples / self.total_samples:\n            try:\n                batch_x, batch_y = next(self.fer_iter)\n                # Convert grayscale to RGB\n                if batch_x.shape[-1] == 1:\n                    batch_x = np.repeat(batch_x, 3, axis=-1)\n                return batch_x, batch_y\n            except StopIteration:\n                self.fer_iter = iter(self.fer_gen)\n                return next(self)\n        else:\n            try:\n                return next(self.aff_iter)\n            except StopIteration:\n                self.aff_iter = iter(self.aff_gen)\n                return next(self)\n\n# Create combined generators\ntrain_gen = CombinedGenerator(fer_train_gen, aff_train_gen, batch_size)\nval_gen = CombinedGenerator(fer_val_gen, aff_val_gen, batch_size)\ntest_gen = CombinedGenerator(fer_test_gen, aff_test_gen, batch_size)\n\n# =============================================================================\n# 7. Compute Class Weights for imbalanced dataset\n# =============================================================================\ndef compute_class_weights(train_df):\n    # Compute balanced class weights\n    class_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(train_df[\"label\"]),\n        y=train_df[\"label\"]\n    )\n    \n    # Map class names to indices\n    label_to_index = {label: i for i, label in enumerate(classes)}\n    \n    # Create dictionary of class weights\n    weights_dict = {label_to_index[label]: weight \n                    for label, weight in zip(np.unique(train_df[\"label\"]), class_weights)}\n    \n    return weights_dict\n\nclass_weights = compute_class_weights(train_df)\nprint(\"Class weights:\", class_weights)\n\n# =============================================================================\n# 8. Model Architecture\n# =============================================================================\ndef create_model(model_type=\"efficientnet\"):\n    input_tensor = Input(shape=(img_size, img_size, 3))\n    \n    if model_type == \"efficientnet\":\n        # EfficientNetB0 without any extra preprocessing\n        base_model = EfficientNetB0(\n            include_top=False, \n            weights=\"imagenet\", \n            input_tensor=input_tensor\n        )\n        # Freeze early layers\n        for layer in base_model.layers[:100]:\n            layer.trainable = False\n        \n        x = base_model.output\n        \n    elif model_type == \"mobilenet\":\n        # MobileNetV3Small\n        base_model = MobileNetV3Small(\n            include_top=False, \n            weights=\"imagenet\", \n            input_tensor=input_tensor\n        )\n        # Freeze early layers\n        for layer in base_model.layers[:50]:\n            layer.trainable = False\n        \n        x = base_model.output\n        \n    elif model_type == \"ensemble\":\n        # Use both models\n        efficient_base = EfficientNetB0(\n            include_top=False, \n            weights=\"imagenet\", \n            input_tensor=input_tensor\n        )\n        mobile_base = MobileNetV3Small(\n            include_top=False, \n            weights=\"imagenet\", \n            input_tensor=input_tensor\n        )\n        \n        # Freeze early layers\n        for layer in efficient_base.layers[:100]:\n            layer.trainable = False\n        for layer in mobile_base.layers[:50]:\n            layer.trainable = False\n        \n        # Global pooling for both models\n        efficient_features = GlobalAveragePooling2D()(efficient_base.output)\n        mobile_features = GlobalAveragePooling2D()(mobile_base.output)\n        \n        # Concatenate features\n        x = Concatenate()([efficient_features, mobile_features])\n    else:\n        raise ValueError(f\"Unknown model type: {model_type}\")\n    \n    # Common head for all models\n    if model_type != \"ensemble\":\n        x = GlobalAveragePooling2D()(x)\n    \n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    \n    x = Dense(256, activation=\"relu\")(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.3)(x)\n    \n    # Output layer\n    outputs = Dense(len(classes), activation=\"softmax\")(x)\n    \n    model = Model(inputs=input_tensor, outputs=outputs)\n\n    # Compile model with a fixed learning rate\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-4, clipnorm=1.0),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    \n    return model\n\n# Simplify model to verify training works\nsimple_model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(len(classes), activation='softmax')\n])\n\nsimple_model.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-4),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# =============================================================================\n# 9. Training with callbacks\n# =============================================================================\n\ncheckpoint_path = os.path.join(\"checkpoints\", f\"{model_type}_emotion_model.keras\")\nos.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n\ndef train_model(model, train_generator, val_generator, epochs=20, class_weights=None):\n    # Better learning rate schedule\n    steps_per_epoch = len(train_generator)\n    lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n        initial_learning_rate=1e-3,\n        decay_steps=steps_per_epoch * epochs,\n        alpha=1e-5\n    )\n\n    # Update the model's optimizer with the new learning rate schedule\n    model.optimizer.learning_rate = lr_schedule  # Direct assignment\n\n    checkpoint_path_keras = checkpoint_path + \".keras\"\n\n    # Callbacks\n    callbacks = [\n        # Save best model\n        ModelCheckpoint(\n            checkpoint_path,\n            save_weights_only=False,\n            monitor=\"val_accuracy\",\n            save_best_only=True,\n            verbose=1\n        ),\n        # Early stopping\n        EarlyStopping(\n            monitor=\"val_accuracy\",\n            patience=7,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        # Reduce learning rate when plateau\n        ReduceLROnPlateau(\n            monitor=\"val_loss\",\n            factor=0.5,\n            patience=3,\n            min_lr=1e-6,\n            verbose=1\n        )\n    ]\n\n    # Calculate steps per epoch and validation steps\n    steps_per_epoch = len(train_generator)\n    validation_steps = len(val_generator)\n\n    print(f\"Steps per epoch: {steps_per_epoch}\")\n    print(f\"Validation steps: {validation_steps}\")\n\n    # Train model\n    start_time = time.time()\n    try:\n        history = model.fit(\n            train_generator,\n            epochs=epochs,\n            steps_per_epoch=steps_per_epoch,\n            validation_data=val_generator,\n            validation_steps=validation_steps,\n            class_weight=class_weights,\n            callbacks=callbacks,\n            verbose=1\n        )\n    except Exception as e:\n        print(f\"Training error: {str(e)}\")\n        return None\n    training_time = time.time() - start_time\n    print(f\"Training completed in {training_time:.2f} seconds\")\n    return history\n\n# =============================================================================\n# 10. Evaluation\n# =============================================================================\ndef evaluate_model(model, test_generator):\n    # Calculate steps for test data\n    test_steps = len(test_generator)\n    \n    # Evaluate model\n    test_loss, test_acc = model.evaluate(test_generator, steps=test_steps)\n    print(f\"Test Loss: {test_loss:.4f}\")\n    print(f\"Test Accuracy: {test_acc:.4f}\")\n    \n    # Get predictions\n    y_pred_probs = model.predict(test_generator, steps=test_steps)\n    y_pred = np.argmax(y_pred_probs, axis=1)\n    \n    # Get true labels\n    y_true = []\n    for i in range(test_steps):\n        try:\n            _, batch_y = next(iter(test_generator))\n            y_true.extend(np.argmax(batch_y, axis=1))\n        except StopIteration:\n            break\n    \n    # Limit to same size\n    y_true = y_true[:len(y_pred)]\n    \n    # Print classification report\n    print(\"\\nClassification Report:\")\n    print(classification_report(\n        y_true, \n        y_pred, \n        target_names=classes\n    ))\n    \n    # Plot confusion matrix\n    plt.figure(figsize=(10, 8))\n    cm = confusion_matrix(y_true, y_pred)\n    sns.heatmap(\n        cm, \n        annot=True, \n        fmt=\"d\", \n        cmap=\"Blues\",\n        xticklabels=classes,\n        yticklabels=classes\n    )\n    plt.title(\"Confusion Matrix\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.tight_layout()\n    plt.show()\n    \n    return y_true, y_pred\n\n# =============================================================================\n# 11. Visualization Functions\n# =============================================================================\ndef plot_training_history(history):\n    plt.figure(figsize=(12, 5))\n    \n    # Plot accuracy\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'], label='Training')\n    plt.plot(history.history['val_accuracy'], label='Validation')\n    plt.title('Model Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    # Plot loss\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'], label='Training')\n    plt.plot(history.history['val_loss'], label='Validation')\n    plt.title('Model Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()\n\n# =============================================================================\n# 12. Test on sample images\n# =============================================================================\ndef test_on_samples(model, num_samples=3):\n    plt.figure(figsize=(16, 12))\n    \n    # Get sample images from each class\n    for i, emotion in enumerate(classes):\n        # Get sample paths\n        sample_paths = []\n        fer_samples = test_df[(test_df['label'] == emotion) & (test_df['source'] == 'fer2013')]['filepath'].values\n        aff_samples = test_df[(test_df['label'] == emotion) & (test_df['source'] == 'affectnet')]['filepath'].values\n        \n        if len(fer_samples) > 0:\n            sample_paths.append(fer_samples[0])\n        if len(aff_samples) > 0:\n            sample_paths.append(aff_samples[0])\n        \n        # Limit to num_samples\n        sample_paths = sample_paths[:num_samples]\n        \n        for j, img_path in enumerate(sample_paths):\n            # Load and preprocess image\n            color_mode = 'grayscale' if 'fer2013' in img_path else 'rgb'\n            img = keras.preprocessing.image.load_img(\n                img_path, \n                target_size=(img_size, img_size),\n                color_mode=color_mode\n            )\n            img_array = keras.preprocessing.image.img_to_array(img) / 255.0\n            \n            # Convert grayscale to RGB if needed\n            if img_array.shape[-1] == 1:\n                img_array = np.repeat(img_array, 3, axis=-1)\n            \n            # Add batch dimension\n            img_batch = np.expand_dims(img_array, axis=0)\n            \n            # Predict\n            predictions = model.predict(img_batch)\n            predicted_class = classes[np.argmax(predictions[0])]\n            confidence = np.max(predictions[0]) * 100\n            \n            # Plot\n            plt_idx = i * num_samples + j + 1\n            if plt_idx <= num_samples * len(classes):\n                plt.subplot(len(classes), num_samples, plt_idx)\n                plt.imshow(img_array)\n                plt.title(f\"True: {emotion}\\nPred: {predicted_class}\\nConf: {confidence:.1f}%\")\n                plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n# =============================================================================\n# MAIN EXECUTION\n# =============================================================================\ndef main():\n    # Debug information\n    print(\"Starting main function\")\n    print(f\"Model type: {model_type}\")\n    \n    try:\n        # Create and train model\n        model = create_model(model_type)\n        print(f\"Created {model_type} model\")\n    \n        # Print model summary\n        model.summary()\n    \n        # Train model\n        history = train_model(\n            model, \n            train_gen, \n            val_gen, \n            epochs=epochs, \n            class_weights=class_weights\n        )\n    \n        # Plot training history\n        plot_training_history(history)\n        \n        # Evaluate model\n        y_true, y_pred = evaluate_model(model, test_gen)\n        \n        # Test on sample images\n        test_on_samples(model)\n        \n        # Save final model\n        model.save(f\"final_{model_type}_emotion_model.keras\")\n        print(f\"Model saved as final_{model_type}_emotion_model.keras\")\n        \n        return model, history\n        \n    except Exception as e:\n        print(f\"Error in main function: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n        return None, None\n\nif __name__ == \"__main__\":\n    # Set random seeds for reproducibility\n    np.random.seed(42)\n    tf.random.set_seed(42)\n    \n    # Mixed precision for faster training\n    try:\n        policy = tf.keras.mixed_precision.Policy('mixed_float16')\n        tf.keras.mixed_precision.set_global_policy(policy)\n        print(\"Using mixed precision\")\n    except:\n        print(\"Mixed precision not available\")\n    \n    # Train model\n    model, history = main()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}