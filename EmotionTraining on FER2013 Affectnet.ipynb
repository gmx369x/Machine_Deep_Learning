{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1351797,"sourceType":"datasetVersion","datasetId":786787},{"sourceId":10537282,"sourceType":"datasetVersion","datasetId":6519896},{"sourceId":10634054,"sourceType":"datasetVersion","datasetId":6583945}],"dockerImageVersionId":30841,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ResNet18 + MobileNetV2 + EfficientNetB0\n\n!pip install tensorflow\n!pip install numpy\n!pip install matplotlib\nimport tensorflow as tf # print(tf.__version__) 2.17.1\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-11T10:55:40.279387Z","iopub.execute_input":"2025-03-11T10:55:40.279681Z","iopub.status.idle":"2025-03-11T10:56:12.360576Z","shell.execute_reply.started":"2025-03-11T10:55:40.279647Z","shell.execute_reply":"2025-03-11T10:56:12.359424Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Version 7z\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom tensorflow.keras.applications import MobileNetV2\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\n\n# =============================================================================\n# Configure GPU and enable mixed precision\n# =============================================================================\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(f\"Found {len(gpus)} GPUs: Memory growth enabled\")\n    except RuntimeError as e:\n        print(f\"GPU error: {e}\")\n\n# Enable mixed precision training\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled\")\n\n# =============================================================================\n# Key parameters\n# =============================================================================\nIMG_SIZE = 224  # Keep at 96x96 as specified\nBATCH_SIZE = 128\nAUTOTUNE = tf.data.AUTOTUNE\nLOG_DIR = \"./emotion_logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\n# Create all required directories\ndef ensure_dir(directory):\n    \"\"\"Make sure a directory exists, creating it if necessary\"\"\"\n    if not os.path.exists(directory):\n        os.makedirs(directory, exist_ok=True)\n\n# Create main log directories\nensure_dir(LOG_DIR)\nensure_dir(LOG_DIR + '/affectnet')\nensure_dir(LOG_DIR + '/fer2013')\nensure_dir(LOG_DIR + '/combined')\nensure_dir(\"./model_checkpoints\")\n\n# Define problematic classes for targeted augmentation\nPROBLEMATIC_CLASSES = ['surprise', 'sad', 'disgust']\n\n# =============================================================================\n# Custom Label Smoothing Loss\n# =============================================================================\ndef label_smoothing_loss(epsilon=0.1):\n    \"\"\"\n    Cross entropy loss with label smoothing to prevent model from being too confident.\n    \n    Args:\n        epsilon: Smoothing factor (0 = no smoothing, 1 = complete smoothing)\n        \n    Returns:\n        Loss function\n    \"\"\"\n    def loss_fn(y_true, y_pred):\n        num_classes = tf.cast(tf.shape(y_true)[-1], tf.float32)\n        \n        # Apply label smoothing\n        y_true = y_true * (1.0 - epsilon) + (epsilon / num_classes)\n        \n        # Calculate cross entropy with extra small epsilon to prevent log(0)\n        return -tf.reduce_sum(y_true * tf.math.log(y_pred + 1e-7), axis=-1)\n    \n    return loss_fn\n\n# =============================================================================\n# Build DataFrame from dataset directory structure\n# =============================================================================\ndef build_image_df(root_dir, subfolders=[\"fer2013\", \"affectnet\"]):\n    \"\"\"\n    Scans the directory and returns a DataFrame with file paths and labels.\n    \"\"\"\n    data = []\n    emotions = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n    \n    print(f\"Found {len(emotions)} emotion categories: {emotions}\")\n    \n    for emotion in emotions:\n        emotion_path = os.path.join(root_dir, emotion)\n        for sub in subfolders:\n            sub_path = os.path.join(emotion_path, sub)\n            if os.path.exists(sub_path):\n                img_files = [f for f in os.listdir(sub_path) \n                            if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n                \n                print(f\"Found {len(img_files)} images in {emotion}/{sub}\")\n                \n                for img_file in img_files:\n                    data.append({\n                        \"filepath\": os.path.join(sub_path, img_file),\n                        \"label\": emotion,\n                        \"source\": sub\n                    })\n    \n    df = pd.DataFrame(data)\n    print(f\"Total images: {len(df)}\")\n    return df\n\n# =============================================================================\n# Fixed graph-compatible preprocessing function\n# =============================================================================\ndef preprocess_image(file_path, label, source, training=True):\n    \"\"\"\n    Fixed graph-compatible preprocessing with class-specific augmentation.\n    \n    Args:\n        file_path: Path to the image file\n        label: Emotion label (as index)\n        source: Dataset source ('fer2013' or 'affectnet')\n        training: Whether to apply augmentation\n        \n    Returns:\n        Preprocessed image and one-hot encoded label\n    \"\"\"\n    # Read the file\n    img = tf.io.read_file(file_path)\n    \n    # Decode image with proper error handling\n    def decode_image():\n        try:\n            decoded = tf.image.decode_image(img, channels=3, expand_animations=False)\n            decoded = tf.ensure_shape(decoded, [None, None, 3])\n            return decoded\n        except:\n            # Return blank image if decoding fails\n            return tf.zeros([IMG_SIZE, IMG_SIZE, 3], dtype=tf.uint8)\n    \n    img = decode_image()\n    \n    # Resize to target size\n    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE], method='bilinear')\n    \n    # Normalize pixel values using MobileNet standard preprocessing\n    img = tf.cast(img, tf.float32)\n    img = img / 127.5 - 1.0  # Scale to [-1, 1]\n    \n    # Apply basic augmentation during training\n    if training:\n        # Random flip - works in graph mode\n        img = tf.image.random_flip_left_right(img)\n        \n        # Basic brightness and contrast\n        img = tf.image.random_brightness(img, 0.2)\n        img = tf.image.random_contrast(img, 0.8, 1.2)\n            \n        # Add random noise to improve robustness\n        noise = tf.random.normal(shape=tf.shape(img), mean=0.0, stddev=0.01)\n        img = img + noise\n        \n        # Ensure values stay in valid range\n        img = tf.clip_by_value(img, -1.0, 1.0)\n    \n    # One-hot encode label\n    label = tf.one_hot(label, depth=8)  # 8 emotion classes\n    \n    return img, label\n\n# =============================================================================\n# Fixed dataset creation function\n# =============================================================================\ndef create_dataset(dataframe, is_training=True, dataset_type=None):\n    \"\"\"\n    Creates a tf.data.Dataset with fixed preprocessing.\n    \n    Args:\n        dataframe: DataFrame with filepath, label, and source columns\n        is_training: Whether this is for training (includes augmentation)\n        dataset_type: Optional filter for specific dataset ('affectnet' or 'fer2013')\n        \n    Returns:\n        tf.data.Dataset and class mapping\n    \"\"\"\n    # Optionally filter to specific dataset\n    if dataset_type is not None:\n        dataframe = dataframe[dataframe['source'] == dataset_type].reset_index(drop=True)\n        print(f\"Filtered to {len(dataframe)} {dataset_type} images\")\n    \n    # Create class indices\n    class_indices = {cls: i for i, cls in enumerate(sorted(dataframe[\"label\"].unique()))}\n    labels = [class_indices[label] for label in dataframe[\"label\"]]\n    \n    # Create dataset\n    ds = tf.data.Dataset.from_tensor_slices((\n        dataframe[\"filepath\"].values,\n        labels,\n        dataframe[\"source\"].values\n    ))\n    \n    # Apply preprocessing with training flag\n    training_value = tf.constant(is_training)\n    ds = ds.map(\n        lambda path, label, source: preprocess_image(path, label, source, training=training_value),\n        num_parallel_calls=AUTOTUNE\n    )\n    \n    if is_training:\n        # Training pipeline\n        ds = ds.shuffle(buffer_size=min(10000, len(dataframe)))\n        \n    # Repeat dataset for multiple epochs\n    ds = ds.repeat()\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(AUTOTUNE)\n    \n    return ds, class_indices\n\n# =============================================================================\n# Create balanced dataset with emphasis classes\n# =============================================================================\ndef create_emphasis_dataset(dataframe, is_training=True, emphasis_classes=PROBLEMATIC_CLASSES):\n    \"\"\"\n    Creates a balanced dataset with emphasis on problematic classes.\n    \n    Args:\n        dataframe: Input DataFrame\n        is_training: Whether to apply training augmentations\n        emphasis_classes: List of classes to emphasize (oversample)\n        \n    Returns:\n        Balanced tf.data.Dataset with emphasis on specified classes\n    \"\"\"\n    balanced_data = []\n    \n    # Sample from each class with emphasis on problematic ones\n    for class_name in sorted(dataframe[\"label\"].unique()):\n        class_df = dataframe[dataframe[\"label\"] == class_name]\n        samples_per_class = 400  # Base sampling\n        \n        # Increase samples for emphasis classes\n        if class_name in emphasis_classes:\n            samples_per_class = 600  # 50% more samples for problematic classes\n            \n        # Sample with replacement if needed\n        if len(class_df) <= samples_per_class:\n            sampled = class_df.sample(n=samples_per_class, replace=True)\n        else:\n            sampled = class_df.sample(n=samples_per_class, replace=False)\n            \n        balanced_data.append(sampled)\n    \n    # Combine all balanced samples\n    balanced_df = pd.concat(balanced_data, ignore_index=True)\n    print(f\"Created balanced dataset with {len(balanced_df)} samples (with emphasis on {emphasis_classes})\")\n    \n    # Create dataset\n    return create_dataset(balanced_df, is_training=is_training)\n\n# =============================================================================\n# Enhanced Confusion Matrix Callback with Class-Specific Monitoring\n# =============================================================================\nclass EnhancedConfusionMatrixCallback(tf.keras.callbacks.Callback):\n    \"\"\"\n    Enhanced callback to monitor class-specific metrics during training.\n    \"\"\"\n    def __init__(self, validation_data, class_names, log_dir, model_name=\"model\", freq=5):\n        super(EnhancedConfusionMatrixCallback, self).__init__()\n        self.validation_data = validation_data\n        self.class_names = class_names\n        self.freq = freq\n        self.log_dir = log_dir\n        self.model_name = model_name\n        self.zero_prediction_classes = set()  # Track classes with zero predictions\n        self.class_metrics_history = {cls: [] for cls in class_names}  # Track per-class metrics\n        \n        # Ensure log directory exists\n        ensure_dir(self.log_dir)\n        \n    def on_epoch_end(self, epoch, logs=None):\n        # Calculate and log class-specific metrics every epoch\n        val_steps = 30  # Limit computation\n        y_true = []\n        y_pred = []\n        \n        # Get predictions for validation data\n        for i, (images, labels) in enumerate(self.validation_data):\n            if i >= val_steps:\n                break\n            batch_preds = self.model.predict(images, verbose=0)\n            y_pred.append(np.argmax(batch_preds, axis=1))\n            y_true.append(np.argmax(labels.numpy(), axis=1))\n        \n        # Flatten the lists\n        y_true = np.concatenate(y_true)\n        y_pred = np.concatenate(y_pred)\n        \n        # Calculate confusion matrix\n        cm = confusion_matrix(y_true, y_pred)\n        \n        # Calculate per-class metrics\n        class_accuracies = np.zeros(len(self.class_names))\n        for i in range(len(self.class_names)):\n            if np.sum(y_true == i) > 0:  # Avoid division by zero\n                class_accuracies[i] = cm[i, i] / np.sum(y_true == i)\n                \n            # Track metrics history\n            self.class_metrics_history[self.class_names[i]].append(class_accuracies[i])\n        \n        # Check for classes with zero predictions\n        zero_pred_classes = []\n        for i, class_name in enumerate(self.class_names):\n            if np.sum(cm[:, i]) == 0:\n                zero_pred_classes.append(class_name)\n                self.zero_prediction_classes.add(class_name)\n        \n        # Log warnings for zero prediction classes\n        if zero_pred_classes:\n            warning_msg = f\"\\n⚠️ WARNING: Zero predictions for classes: {', '.join(zero_pred_classes)}\"\n            print(warning_msg)\n            \n            # Save warning to log file\n            with open(f\"{self.log_dir}/warnings.txt\", \"a\") as f:\n                f.write(f\"Epoch {epoch+1}: {warning_msg}\\n\")\n        \n        # Save visualizations and detailed reports on the specified frequency\n        if (epoch + 1) % self.freq == 0:\n            # Print confusion matrix\n            print(\"\\nConfusion Matrix:\")\n            print(cm)\n            \n            # Print per-class accuracy\n            for i, (name, acc) in enumerate(zip(self.class_names, class_accuracies)):\n                print(f\"{name}: {acc:.4f}\", end=\"  \")\n                if (i + 1) % 4 == 0:\n                    print()  # New line for readability\n            print(\"\\n\")\n            \n            # Print class accuracy trends instead of plotting them\n            print(\"Class Accuracy Trends:\")\n            for class_name in self.class_names:\n                history = self.class_metrics_history[class_name]\n                trend = \", \".join([f\"{acc:.4f}\" for acc in history[-5:]])  # Show last 5 epochs\n                print(f\"{class_name}: [{trend}]\")\n            print()\n            \n            # Save confusion matrix visualization (still useful)\n            plt.figure(figsize=(10, 8))\n            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                       xticklabels=self.class_names,\n                       yticklabels=self.class_names)\n            plt.xlabel('Predicted')\n            plt.ylabel('True')\n            plt.title(f'Confusion Matrix - {self.model_name} - Epoch {epoch+1}')\n            plt.tight_layout()\n            \n            try:\n                plt.savefig(f'{self.log_dir}/confusion_matrix_epoch_{epoch+1}.png')\n            except Exception as e:\n                print(f\"Warning: Could not save confusion matrix plot: {e}\")\n            \n            plt.close()\n\n# =============================================================================\n# Create emotion recognition model with additional MLP head\n# =============================================================================\n\ndef focal_loss(gamma=2.0, alpha=0.25):\n    \"\"\"\n    Focal loss for multi-class classification.\n    \n    Args:\n      gamma: Focusing parameter to reduce the relative loss for well-classified examples.\n      alpha: Balancing factor for class imbalance.\n    \n    Returns:\n      A function that computes the focal loss.\n    \"\"\"\n    def loss_fn(y_true, y_pred):\n        epsilon = 1e-7  # to avoid log(0)\n        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n        cross_entropy = -y_true * tf.math.log(y_pred)\n        focal_loss_value = alpha * tf.pow(1.0 - y_pred, gamma) * cross_entropy\n        return tf.reduce_sum(focal_loss_value, axis=-1)\n    return loss_fn\n\n\ndef create_emotion_model(num_classes):\n    \"\"\"\n    Create a facial emotion recognition model with enhanced classification head.\n    \n    Args:\n        num_classes: Number of emotion classes\n        \n    Returns:\n        Compiled Keras model and base model\n    \"\"\"\n    # Input shape\n    input_shape = (IMG_SIZE, IMG_SIZE, 3)\n    \n    # Create input layer\n    inputs = keras.layers.Input(shape=input_shape)\n    \n    # Use MobileNetV2 as base\n    base_model = MobileNetV2(\n        include_top=False,\n        weights='imagenet',\n        input_tensor=inputs,\n        alpha=1.0  # Controls model width\n    )\n    print(\"Using MobileNetV2 base model\")\n    \n    # Freeze base model layers\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    # Add custom head with dropout and batch normalization\n    x = base_model.output\n    x = keras.layers.GlobalAveragePooling2D()(x)\n    \n    # First dense block\n    x = keras.layers.Dense(256)(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.Dropout(0.4)(x)\n    \n    # Second dense block\n    x = keras.layers.Dense(128)(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.Dropout(0.3)(x)\n    \n    # Output layer with label smoothing\n    outputs = keras.layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n    \n    # Create model\n    model = keras.Model(inputs=inputs, outputs=outputs)\n    \n    # Compile with label smoothing loss\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n        loss=focal_loss(gamma=2.0, alpha=0.25),#label_smoothing_loss(epsilon=0.1),\n        metrics=['accuracy']\n    )\n    \n    return model, base_model\n\n# =============================================================================\n# Evaluation function\n# =============================================================================\ndef evaluate_model(model, test_ds, steps, class_names, log_dir, dataset_name=\"\"):\n    \"\"\"\n    Evaluate model with detailed metrics and visualizations.\n    \"\"\"\n    print(f\"\\nEvaluating model on {dataset_name} test set\")\n    \n    # Get predictions\n    y_true = []\n    y_pred = []\n    \n    # Loop through test batches\n    for i, (images, labels) in enumerate(test_ds):\n        if i >= steps:\n            break\n        batch_preds = model.predict(images, verbose=0)\n        y_pred.append(np.argmax(batch_preds, axis=1))\n        y_true.append(np.argmax(labels.numpy(), axis=1))\n    \n    # Concatenate\n    y_true = np.concatenate(y_true)\n    y_pred = np.concatenate(y_pred)\n    \n    # Calculate metrics\n    test_accuracy = np.mean(y_pred == y_true)\n    f1 = f1_score(y_true, y_pred, average='weighted')\n    \n    print(f\"{dataset_name} Test Accuracy: {test_accuracy:.4f}\")\n    print(f\"{dataset_name} Weighted F1-Score: {f1:.4f}\")\n    \n    # Calculate confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Visualize confusion matrix\n    plt.figure(figsize=(12, 10))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n               xticklabels=class_names,\n               yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title(f'Confusion Matrix - {dataset_name} Test Set')\n    plt.tight_layout()\n    \n    try:\n        plt.savefig(f'{log_dir}/confusion_matrix_{dataset_name}_test.png')\n    except Exception as e:\n        print(f\"Warning: Could not save confusion matrix plot: {e}\")\n        \n    plt.close()\n    \n    # Print classification report\n    print(f\"\\n{dataset_name} Classification Report:\")\n    report = classification_report(\n        y_true, \n        y_pred, \n        target_names=class_names,\n        zero_division=0\n    )\n    print(report)\n    \n    # Save report to file\n    with open(f'{log_dir}/classification_report_{dataset_name}.txt', 'w') as f:\n        f.write(report)\n    \n    return {\n        'accuracy': test_accuracy,\n        'f1_score': f1,\n        'confusion_matrix': cm\n    }\n\n# =============================================================================\n# Two-Stage Fine-Tuning with Progressive Unfreezing\n# =============================================================================\ndef train_with_progressive_unfreezing(model, base_model, train_ds, val_ds, \n                                    steps_per_epoch, val_steps, \n                                    epochs_head=10, epochs_finetune=20,\n                                    callbacks=None, class_weights=None):\n    \"\"\"\n    Two-stage training approach: first train only the head, then progressively unfreeze layers.\n    \n    Args:\n        model: The model to train\n        base_model: The base model part (for unfreezing)\n        train_ds: Training dataset\n        val_ds: Validation dataset\n        steps_per_epoch: Steps per training epoch\n        val_steps: Validation steps\n        epochs_head: Epochs for head-only training\n        epochs_finetune: Epochs for fine-tuning\n        callbacks: List of callbacks\n        class_weights: Class weights for handling imbalance\n        \n    Returns:\n        Training history\n    \"\"\"\n    print(f\"\\nStage 1: Training only the classification head ({epochs_head} epochs)\")\n    \n    # Ensure base model is frozen\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    # Compile with higher learning rate for head training\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n        loss=focal_loss(gamma=2.0, alpha=0.25),#label_smoothing_loss(epsilon=0.1),\n        metrics=['accuracy']\n    )\n    \n    # Train head only\n    history_head = model.fit(\n        train_ds,\n        epochs=epochs_head,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=val_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    \n    print(f\"\\nStage 2: Fine-tuning with progressive unfreezing ({epochs_finetune} epochs)\")\n    \n    # Progressively unfreeze layers in groups\n    fine_tuning_history = []\n    \n    # Groups of layers to unfreeze (from last to first)\n    layer_groups = [\n        # Unfreeze last layers first (deeper = more specific features)\n        base_model.layers[-15:],  # Last block\n        base_model.layers[-30:-15],  # Second-to-last block\n        base_model.layers[-50:-30]   # Third-to-last block\n    ]\n    \n    for i, group in enumerate(layer_groups):\n        print(f\"\\nUnfreezing group {i+1}/{len(layer_groups)} ({len(group)} layers)\")\n        \n        # Unfreeze current group\n        for layer in group:\n            layer.trainable = True\n            \n        # Recompile with lower learning rate as we go deeper\n        lr = 1e-4 / (i + 1)  # Decrease learning rate for deeper layers\n        \n        model.compile(\n            optimizer=keras.optimizers.Adam(learning_rate=lr),\n            loss=focal_loss(gamma=2.0, alpha=0.25),#label_smoothing_loss(epsilon=0.1),\n            metrics=['accuracy']\n        )\n        \n        # Train for a few epochs\n        epochs_per_group = max(5, epochs_finetune // len(layer_groups))\n        \n        history = model.fit(\n            train_ds,\n            epochs=epochs_per_group,\n            steps_per_epoch=steps_per_epoch,\n            validation_data=val_ds,\n            validation_steps=val_steps,\n            callbacks=callbacks,\n            class_weight=class_weights,\n            verbose=1\n        )\n        \n        fine_tuning_history.append(history)\n    \n    # Return combined history\n    return history_head, fine_tuning_history\n\n# =============================================================================\n# Sequential Training Pipeline\n# =============================================================================\ndef train_enhanced_emotion_model(data_dir):\n    \"\"\"\n    Enhanced sequential training with all improvements.\n    \n    Args:\n        data_dir: Path to dataset directory\n        \n    Returns:\n        Trained model and evaluation metrics\n    \"\"\"\n    print(\"Starting enhanced sequential emotion recognition training\")\n    \n    # 1. Load and prepare data\n    print(\"\\n1. Loading datasets\")\n    train_dir = os.path.join(data_dir, \"Train\")\n    test_dir = os.path.join(data_dir, \"Test\")\n    \n    train_df_full = build_image_df(train_dir)\n    test_df = build_image_df(test_dir)\n    \n    # Show dataset distributions\n    print(\"\\nAffectNet training distribution:\")\n    print(train_df_full[train_df_full['source'] == 'affectnet']['label'].value_counts())\n    \n    print(\"\\nFER2013 training distribution:\")\n    print(train_df_full[train_df_full['source'] == 'fer2013']['label'].value_counts())\n    \n    # 2. Split test set by dataset source\n    test_affectnet_df = test_df[test_df['source'] == 'affectnet']\n    test_fer_df = test_df[test_df['source'] == 'fer2013']\n    \n    print(f\"\\nTest sets: AffectNet={len(test_affectnet_df)}, FER2013={len(test_fer_df)}\")\n    \n    # Get classes for later use\n    classes = sorted(train_df_full[\"label\"].unique())\n    num_classes = len(classes)\n    print(f\"Classes: {classes}\")\n    \n    # 3. Create validation splits\n    # For AffectNet\n    affectnet_train_df = train_df_full[train_df_full['source'] == 'affectnet']\n    affectnet_train_df, affectnet_val_df = train_test_split(\n        affectnet_train_df, \n        test_size=0.15, \n        stratify=affectnet_train_df[\"label\"], \n        random_state=42\n    )\n    \n    # For FER2013\n    fer_train_df = train_df_full[train_df_full['source'] == 'fer2013']\n    fer_train_df, fer_val_df = train_test_split(\n        fer_train_df, \n        test_size=0.15, \n        stratify=fer_train_df[\"label\"], \n        random_state=42\n    )\n    \n    print(f\"AffectNet: {len(affectnet_train_df)} train, {len(affectnet_val_df)} validation\")\n    print(f\"FER2013: {len(fer_train_df)} train, {len(fer_val_df)} validation\")\n    \n    # 4. Create datasets with emphasis on problematic classes\n    print(\"\\n2. Creating enhanced data pipelines\")\n    \n    # AffectNet datasets\n    affectnet_train_ds, class_indices = create_emphasis_dataset(\n        affectnet_train_df, is_training=True)\n    \n    affectnet_val_ds, _ = create_dataset(\n        affectnet_val_df, is_training=False, \n        dataset_type='affectnet')\n    \n    affectnet_test_ds, _ = create_dataset(\n        test_affectnet_df, is_training=False, \n        dataset_type='affectnet')\n    \n    # FER2013 datasets\n    fer_train_ds, _ = create_emphasis_dataset(\n        fer_train_df, is_training=True)\n    \n    fer_val_ds, _ = create_dataset(\n        fer_val_df, is_training=False, \n        dataset_type='fer2013')\n    \n    fer_test_ds, _ = create_dataset(\n        test_fer_df, is_training=False, \n        dataset_type='fer2013')\n    \n    # Create combined test dataset\n    combined_test_ds, _ = create_dataset(\n        test_df, is_training=False)\n    \n    # 5. Calculate steps\n    affectnet_steps_per_epoch = len(affectnet_train_df) // BATCH_SIZE\n    affectnet_val_steps = len(affectnet_val_df) // BATCH_SIZE\n    affectnet_test_steps = len(test_affectnet_df) // BATCH_SIZE\n    \n    fer_steps_per_epoch = len(fer_train_df) // BATCH_SIZE\n    fer_val_steps = len(fer_val_df) // BATCH_SIZE\n    fer_test_steps = len(test_fer_df) // BATCH_SIZE\n    \n    combined_test_steps = len(test_df) // BATCH_SIZE\n    \n    # 6. Create enhanced model\n    print(\"\\n3. Creating enhanced model\")\n    model, base_model = create_emotion_model(num_classes)\n    \n    # 7. Compute class weights for each dataset with adjustments\n    print(\"\\n4. Computing class weights with adjustments for problematic classes\")\n    \n    # AffectNet class weights\n    affectnet_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(affectnet_train_df[\"label\"]),\n        y=affectnet_train_df[\"label\"]\n    )\n    affectnet_class_weights = {class_indices[label]: weight for label, weight in \n                     zip(np.unique(affectnet_train_df[\"label\"]), affectnet_weights)}\n    \n    # FER2013 class weights\n    fer_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(fer_train_df[\"label\"]),\n        y=fer_train_df[\"label\"]\n    )\n    fer_class_weights = {class_indices[label]: weight for label, weight in \n                zip(np.unique(fer_train_df[\"label\"]), fer_weights)}\n    \n    # Increase weights for problematic classes\n    for problem_class in PROBLEMATIC_CLASSES:\n        if problem_class in class_indices:\n            class_idx = class_indices[problem_class]\n            # Increase the weight by 20%\n            if class_idx in affectnet_class_weights:\n                affectnet_class_weights[class_idx] *= 1.2\n            if class_idx in fer_class_weights:\n                fer_class_weights[class_idx] *= 1.2\n    \n    print(\"Enhanced AffectNet class weights:\", affectnet_class_weights)\n    print(\"Enhanced FER2013 class weights:\", fer_class_weights)\n    \n    # 8. Setup callbacks with enhanced monitoring\n    print(\"\\n5. Setting up enhanced callbacks\")\n    \n    # Base callbacks shared across training phases\n    base_callbacks = [\n        # Early stopping\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=10,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        # Learning rate scheduler\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.5,\n            patience=5,\n            min_lr=1e-6,\n            verbose=1\n        ),\n        # TensorBoard\n        tf.keras.callbacks.TensorBoard(\n            log_dir=LOG_DIR,\n            histogram_freq=1,\n            update_freq='epoch'\n        )\n    ]\n    \n    # AffectNet-specific callbacks\n    affectnet_callbacks = base_callbacks + [\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'model_checkpoints/affectnet_best.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        ),\n        # Enhanced confusion matrix monitoring\n        EnhancedConfusionMatrixCallback(\n            affectnet_val_ds, \n            classes, \n            log_dir=LOG_DIR + '/affectnet',\n            model_name=\"AffectNet\",\n            freq=3\n        ),\n        # CSV Logger\n        tf.keras.callbacks.CSVLogger(\n            'affectnet_training_log.csv', \n            append=True\n        )\n    ]\n    \n    # FER2013-specific callbacks\n    fer_callbacks = base_callbacks + [\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'model_checkpoints/fer2013_best.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        ),\n        # Enhanced confusion matrix monitoring\n        EnhancedConfusionMatrixCallback(\n            fer_val_ds, \n            classes, \n            log_dir=LOG_DIR + '/fer2013',\n            model_name=\"FER2013\",\n            freq=3\n        ),\n        # CSV Logger\n        tf.keras.callbacks.CSVLogger(\n            'fer2013_training_log.csv', \n            append=True\n        )\n    ]\n    \n    # 9. STAGE 1: Train on AffectNet using progressive unfreezing\n    print(\"\\n6. STAGE 1: Training on AffectNet with progressive unfreezing\")\n    \n    history_affectnet_head, history_affectnet_finetune = train_with_progressive_unfreezing(\n        model, base_model,\n        affectnet_train_ds, affectnet_val_ds,\n        affectnet_steps_per_epoch, affectnet_val_steps,\n        epochs_head=10, epochs_finetune=15,\n        callbacks=affectnet_callbacks,\n        class_weights=affectnet_class_weights\n    )\n    \n    # Save AffectNet model\n    model.save(\"affectnet_model.keras\")\n    print(\"AffectNet model saved to 'affectnet_model.keras'\")\n    \n    # 10. Evaluate on AffectNet test set\n    affectnet_metrics = evaluate_model(\n        model, \n        affectnet_test_ds, \n        affectnet_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"AffectNet\"\n    )\n    \n    # 11. STAGE 2: Fine-tune on FER2013 with progressive unfreezing\n    print(\"\\n7. STAGE 2: Fine-tuning on FER2013 with progressive unfreezing\")\n    \n    history_fer_head, history_fer_finetune = train_with_progressive_unfreezing(\n        model, base_model,\n        fer_train_ds, fer_val_ds,\n        fer_steps_per_epoch, fer_val_steps,\n        epochs_head=8, epochs_finetune=12,\n        callbacks=fer_callbacks,\n        class_weights=fer_class_weights\n    )\n    \n    # 12. Evaluate on FER2013 test set\n    fer_metrics = evaluate_model(\n        model, \n        fer_test_ds, \n        fer_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"FER2013\"\n    )\n    \n    # 13. Evaluate on combined test set\n    combined_metrics = evaluate_model(\n        model, \n        combined_test_ds, \n        combined_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"Combined\"\n    )\n    \n    # 14. Save the final model\n    model.save(\"final_enhanced_emotion_model.keras\")\n    print(\"Final model saved to 'final_enhanced_emotion_model.keras'\")\n    \n    # Return models and metrics\n    return model, {\n        'affectnet': affectnet_metrics,\n        'fer2013': fer_metrics,\n        'combined': combined_metrics\n    }\n\n# =============================================================================\n# Main entry point\n# =============================================================================\nif __name__ == \"__main__\":\n    # Set data directory path\n    data_dir = \"/kaggle/input/custom-fer2013affectnet/Custom_ferAffect2013net\"\n    \n    # Train model with all improvements\n    model, metrics = train_enhanced_emotion_model(data_dir)\n    \n    # Print final results\n    print(\"\\n=== FINAL RESULTS ===\")\n    print(f\"AffectNet Test Accuracy: {metrics['affectnet']['accuracy']:.4f}\")\n    print(f\"AffectNet F1 Score: {metrics['affectnet']['f1_score']:.4f}\")\n    print(f\"FER2013 Test Accuracy: {metrics['fer2013']['accuracy']:.4f}\")\n    print(f\"FER2013 F1 Score: {metrics['fer2013']['f1_score']:.4f}\")\n    print(f\"Combined Test Accuracy: {metrics['combined']['accuracy']:.4f}\")\n    print(f\"Combined F1 Score: {metrics['combined']['f1_score']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T17:47:42.430994Z","iopub.execute_input":"2025-03-11T17:47:42.431329Z","iopub.status.idle":"2025-03-11T18:38:28.708782Z","shell.execute_reply.started":"2025-03-11T17:47:42.431307Z","shell.execute_reply":"2025-03-11T18:38:28.708043Z"}},"outputs":[{"name":"stdout","text":"Found 1 GPUs: Memory growth enabled\nMixed precision enabled\nStarting enhanced sequential emotion recognition training\n\n1. Loading datasets\nFound 8 emotion categories: ['surprise', 'fear', 'neutral', 'sad', 'disgust', 'contempt', 'happy', 'anger']\nFound 3161 images in surprise/fer2013\nFound 4039 images in surprise/affectnet\nFound 4092 images in fear/fer2013\nFound 3176 images in fear/affectnet\nFound 4951 images in neutral/fer2013\nFound 5126 images in neutral/affectnet\nFound 4823 images in sad/fer2013\nFound 3091 images in sad/affectnet\nFound 435 images in disgust/fer2013\nFound 2477 images in disgust/affectnet\nFound 54 images in contempt/fer2013\nFound 2871 images in contempt/affectnet\nFound 7199 images in happy/fer2013\nFound 5044 images in happy/affectnet\nFound 3987 images in anger/fer2013\nFound 3218 images in anger/affectnet\nTotal images: 57744\nFound 8 emotion categories: ['surprise', 'fear', 'neutral', 'sad', 'disgust', 'contempt', 'happy', 'anger']\nFound 831 images in surprise/fer2013\nFound 4039 images in surprise/affectnet\nFound 1024 images in fear/fer2013\nFound 3176 images in fear/affectnet\nFound 1233 images in neutral/fer2013\nFound 5126 images in neutral/affectnet\nFound 1247 images in sad/fer2013\nFound 3091 images in sad/affectnet\nFound 111 images in disgust/fer2013\nFound 2477 images in disgust/affectnet\nFound 54 images in contempt/fer2013\nFound 2871 images in contempt/affectnet\nFound 1774 images in happy/fer2013\nFound 5044 images in happy/affectnet\nFound 958 images in anger/fer2013\nFound 3218 images in anger/affectnet\nTotal images: 36274\n\nAffectNet training distribution:\nlabel\nneutral     5126\nhappy       5044\nsurprise    4039\nanger       3218\nfear        3176\nsad         3091\ncontempt    2871\ndisgust     2477\nName: count, dtype: int64\n\nFER2013 training distribution:\nlabel\nhappy       7199\nneutral     4951\nsad         4823\nfear        4092\nanger       3987\nsurprise    3161\ndisgust      435\ncontempt      54\nName: count, dtype: int64\n\nTest sets: AffectNet=29042, FER2013=7232\nClasses: ['anger', 'contempt', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\nAffectNet: 24685 train, 4357 validation\nFER2013: 24396 train, 4306 validation\n\n2. Creating enhanced data pipelines\nCreated balanced dataset with 3800 samples (with emphasis on ['surprise', 'sad', 'disgust'])\nFiltered to 4357 affectnet images\nFiltered to 29042 affectnet images\nCreated balanced dataset with 3800 samples (with emphasis on ['surprise', 'sad', 'disgust'])\nFiltered to 4306 fer2013 images\nFiltered to 7232 fer2013 images\n\n3. Creating enhanced model\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-2-0351fcea758e>:407: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n  base_model = MobileNetV2(\n","output_type":"stream"},{"name":"stdout","text":"Using MobileNetV2 base model\n\n4. Computing class weights with adjustments for problematic classes\nEnhanced AffectNet class weights: {0: 1.128199268738574, 1: 1.2646004098360655, 2: 1.758190883190883, 3: 1.142824074074074, 4: 0.7197632376953581, 5: 0.7081994491622676, 6: 1.4094975256947089, 7: 1.0785755898630933}\nEnhanced FER2013 class weights: {0: 0.899822956624373, 1: 66.29347826086956, 2: 9.890270270270271, 3: 0.8767970097757332, 4: 0.4983657460369341, 5: 0.7246910646387833, 6: 0.8927543303244693, 7: 1.3618905842947524}\n\n5. Setting up enhanced callbacks\n\n6. STAGE 1: Training on AffectNet with progressive unfreezing\n\nStage 1: Training only the classification head (10 epochs)\nEpoch 1/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.2759 - loss: 0.4382\nEpoch 1: val_accuracy improved from -inf to 0.25758, saving model to model_checkpoints/affectnet_best.weights.h5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 332ms/step - accuracy: 0.2764 - loss: 0.4378 - val_accuracy: 0.2576 - val_loss: 0.3838 - learning_rate: 0.0010\nEpoch 2/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.5169 - loss: 0.2314\nEpoch 2: val_accuracy improved from 0.25758 to 0.29090, saving model to model_checkpoints/affectnet_best.weights.h5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 296ms/step - accuracy: 0.5171 - loss: 0.2313 - val_accuracy: 0.2909 - val_loss: 0.3786 - learning_rate: 0.0010\nEpoch 3/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.6500 - loss: 0.1555\nEpoch 3: val_accuracy did not improve from 0.29090\n\nConfusion Matrix:\n[[102  51 119  38   0   2  52  57]\n [ 35 169  85  13   2   0  32  60]\n [ 46  37 146  25   2   0  26  48]\n [ 35  30  74 126   1   0  41 128]\n [ 62  99 169  18 144  31  30 115]\n [ 89  71 116  26  52  67  31 209]\n [ 64  49 111  34   0   1  67  76]\n [ 38  33  80  75   7   8  30 256]]\nanger: 0.2423  contempt: 0.4268  disgust: 0.4424  fear: 0.2897  \nhappy: 0.2156  neutral: 0.1014  sad: 0.1667  surprise: 0.4858  \n\n\nClass Accuracy Trends:\nanger: [0.1948, 0.1710, 0.2423]\ncontempt: [0.3283, 0.3030, 0.4268]\ndisgust: [0.3697, 0.6273, 0.4424]\nfear: [0.4644, 0.3448, 0.2897]\nhappy: [0.1766, 0.2201, 0.2156]\nneutral: [0.0893, 0.1634, 0.1014]\nsad: [0.0821, 0.2164, 0.1667]\nsurprise: [0.4459, 0.3947, 0.4858]\n\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 299ms/step - accuracy: 0.6501 - loss: 0.1554 - val_accuracy: 0.2842 - val_loss: 0.4109 - learning_rate: 0.0010\nEpoch 4/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.7327 - loss: 0.1110\nEpoch 4: val_accuracy did not improve from 0.29090\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 296ms/step - accuracy: 0.7327 - loss: 0.1110 - val_accuracy: 0.2725 - val_loss: 0.4584 - learning_rate: 0.0010\nEpoch 5/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.7939 - loss: 0.0786\nEpoch 5: val_accuracy did not improve from 0.29090\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 269ms/step - accuracy: 0.7940 - loss: 0.0786 - val_accuracy: 0.2806 - val_loss: 0.4587 - learning_rate: 0.0010\nEpoch 6/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.8317 - loss: 0.0623\nEpoch 6: val_accuracy did not improve from 0.29090\n\nConfusion Matrix:\n[[ 89  34  70  61   0   1 101  65]\n [ 42 127  49  34   0   1  58  85]\n [ 43  30  78  47   2   0  64  66]\n [ 25  20  30 156   0   0  75 129]\n [ 44  75 107  33  84  51  83 191]\n [ 75  43  38  42  21  90 108 244]\n [ 47  35  50  51   0   1 140  78]\n [ 30  21  34 110   1   7  67 257]]\nanger: 0.2114  contempt: 0.3207  disgust: 0.2364  fear: 0.3586  \nhappy: 0.1257  neutral: 0.1362  sad: 0.3483  surprise: 0.4877  \n\n\nClass Accuracy Trends:\nanger: [0.1710, 0.2423, 0.1021, 0.1544, 0.2114]\ncontempt: [0.3030, 0.4268, 0.2197, 0.3535, 0.3207]\ndisgust: [0.6273, 0.4424, 0.6152, 0.3424, 0.2364]\nfear: [0.3448, 0.2897, 0.2782, 0.4161, 0.3586]\nhappy: [0.2201, 0.2156, 0.1407, 0.1916, 0.1257]\nneutral: [0.1634, 0.1014, 0.1604, 0.1558, 0.1362]\nsad: [0.2164, 0.1667, 0.3085, 0.2040, 0.3483]\nsurprise: [0.3947, 0.4858, 0.4858, 0.4820, 0.4877]\n\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 277ms/step - accuracy: 0.8318 - loss: 0.0623 - val_accuracy: 0.2677 - val_loss: 0.4995 - learning_rate: 0.0010\nEpoch 7/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.8643 - loss: 0.0492\nEpoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 7: val_accuracy did not improve from 0.29090\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 283ms/step - accuracy: 0.8644 - loss: 0.0492 - val_accuracy: 0.2803 - val_loss: 0.5000 - learning_rate: 0.0010\nEpoch 8/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.8922 - loss: 0.0352\nEpoch 8: val_accuracy did not improve from 0.29090\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 286ms/step - accuracy: 0.8923 - loss: 0.0351 - val_accuracy: 0.2858 - val_loss: 0.5150 - learning_rate: 5.0000e-04\nEpoch 9/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.9205 - loss: 0.0260\nEpoch 9: val_accuracy improved from 0.29090 to 0.30308, saving model to model_checkpoints/affectnet_best.weights.h5\n\nConfusion Matrix:\n[[ 49  58 123  40   0   4 105  42]\n [ 17 146 100  21   2   2  60  48]\n [ 18  32 153  30   3   0  56  38]\n [  9  37  80 136   0   0  87  86]\n [ 23  82 133  31 180  55  70  94]\n [ 28  60  93  38  64 139  87 152]\n [ 14  45 118  36   1   1 136  51]\n [ 13  41  79  86   6  15  71 216]]\nanger: 0.1164  contempt: 0.3687  disgust: 0.4636  fear: 0.3126  \nhappy: 0.2695  neutral: 0.2103  sad: 0.3383  surprise: 0.4099  \n\n\nClass Accuracy Trends:\nanger: [0.1544, 0.2114, 0.2067, 0.1496, 0.1164]\ncontempt: [0.3535, 0.3207, 0.4899, 0.3990, 0.3687]\ndisgust: [0.3424, 0.2364, 0.1606, 0.4121, 0.4636]\nfear: [0.4161, 0.3586, 0.4782, 0.3172, 0.3126]\nhappy: [0.1916, 0.1257, 0.2545, 0.1841, 0.2695]\nneutral: [0.1558, 0.1362, 0.1286, 0.1694, 0.2103]\nsad: [0.2040, 0.3483, 0.1294, 0.2612, 0.3383]\nsurprise: [0.4820, 0.4877, 0.4137, 0.4896, 0.4099]\n\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 296ms/step - accuracy: 0.9205 - loss: 0.0260 - val_accuracy: 0.3031 - val_loss: 0.4873 - learning_rate: 5.0000e-04\nEpoch 10/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9266 - loss: 0.0233\nEpoch 10: val_accuracy improved from 0.30308 to 0.30699, saving model to model_checkpoints/affectnet_best.weights.h5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 272ms/step - accuracy: 0.9267 - loss: 0.0233 - val_accuracy: 0.3070 - val_loss: 0.4849 - learning_rate: 5.0000e-04\nRestoring model weights from the end of the best epoch: 10.\n\nStage 2: Fine-tuning with progressive unfreezing (15 epochs)\n\nUnfreezing group 1/3 (15 layers)\nEpoch 1/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.6410 - loss: 0.2136\nEpoch 1: val_accuracy did not improve from 0.30699\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 354ms/step - accuracy: 0.6415 - loss: 0.2131 - val_accuracy: 0.1921 - val_loss: 1.0667 - learning_rate: 1.0000e-04\nEpoch 2/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.8859 - loss: 0.0394\nEpoch 2: val_accuracy did not improve from 0.30699\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 302ms/step - accuracy: 0.8860 - loss: 0.0394 - val_accuracy: 0.2183 - val_loss: 0.9798 - learning_rate: 1.0000e-04\nEpoch 3/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.9321 - loss: 0.0199\nEpoch 3: val_accuracy did not improve from 0.30699\n\nConfusion Matrix:\n[[ 56  50  57 180   0   0   7  71]\n [ 16 147  41 107   0   0   6  79]\n [ 19  47  74 144   0   0   4  42]\n [  6  25  28 282   0   0   5  89]\n [ 54 104  88 161  10  14   3 234]\n [ 61  57  51 153   5  19  19 296]\n [ 19  46  64 190   0   0  10  73]\n [  6  21  25 251   0   0   1 223]]\nanger: 0.1330  contempt: 0.3712  disgust: 0.2242  fear: 0.6483  \nhappy: 0.0150  neutral: 0.0287  sad: 0.0249  surprise: 0.4231  \n\n\nClass Accuracy Trends:\nanger: [0.1164, 0.1924, 0.1116, 0.1948, 0.1330]\ncontempt: [0.3687, 0.4066, 0.2904, 0.5682, 0.3712]\ndisgust: [0.4636, 0.3848, 0.1606, 0.1879, 0.2242]\nfear: [0.3126, 0.3609, 0.7011, 0.4529, 0.6483]\nhappy: [0.2695, 0.3204, 0.0060, 0.0045, 0.0150]\nneutral: [0.2103, 0.1891, 0.0045, 0.0061, 0.0287]\nsad: [0.3383, 0.0970, 0.0249, 0.0249, 0.0249]\nsurprise: [0.4099, 0.5009, 0.3890, 0.4972, 0.4231]\n\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 304ms/step - accuracy: 0.9322 - loss: 0.0199 - val_accuracy: 0.2123 - val_loss: 0.9543 - learning_rate: 1.0000e-04\nEpoch 4/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.9541 - loss: 0.0138\nEpoch 4: val_accuracy did not improve from 0.30699\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 315ms/step - accuracy: 0.9541 - loss: 0.0138 - val_accuracy: 0.2528 - val_loss: 0.7604 - learning_rate: 1.0000e-04\nEpoch 5/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9645 - loss: 0.0104\nEpoch 5: val_accuracy did not improve from 0.30699\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 267ms/step - accuracy: 0.9645 - loss: 0.0104 - val_accuracy: 0.2737 - val_loss: 0.6728 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n\nUnfreezing group 2/3 (15 layers)\nEpoch 1/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.5896 - loss: 0.2496\nEpoch 1: val_accuracy did not improve from 0.30699\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 323ms/step - accuracy: 0.5900 - loss: 0.2492 - val_accuracy: 0.2045 - val_loss: 0.9438 - learning_rate: 5.0000e-05\nEpoch 2/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.8233 - loss: 0.0637\nEpoch 2: val_accuracy did not improve from 0.30699\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 297ms/step - accuracy: 0.8234 - loss: 0.0636 - val_accuracy: 0.2263 - val_loss: 0.8497 - learning_rate: 5.0000e-05\nEpoch 3/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.9008 - loss: 0.0316\nEpoch 3: val_accuracy did not improve from 0.30699\n\nConfusion Matrix:\n[[ 33 102 110  49   0   0  15 112]\n [  5 211  62  13   0   0   3 102]\n [ 17  67 129  32   0   0   7  78]\n [  7  36  63 118   0   0   9 202]\n [ 24 180 138  19  23   3   8 273]\n [ 60 112  76  23   3   9  11 367]\n [ 18  80 101  32   0   0  23 148]\n [  7  47  42  67   0   0   7 357]]\nanger: 0.0784  contempt: 0.5328  disgust: 0.3909  fear: 0.2713  \nhappy: 0.0344  neutral: 0.0136  sad: 0.0572  surprise: 0.6774  \n\n\nClass Accuracy Trends:\nanger: [0.1140, 0.1449, 0.0665, 0.0903, 0.0784]\ncontempt: [0.5808, 0.5859, 0.3131, 0.4470, 0.5328]\ndisgust: [0.2091, 0.3758, 0.2364, 0.4303, 0.3909]\nfear: [0.4989, 0.4322, 0.3425, 0.2920, 0.2713]\nhappy: [0.0719, 0.1542, 0.0090, 0.0150, 0.0344]\nneutral: [0.0666, 0.0953, 0.0061, 0.0182, 0.0136]\nsad: [0.1617, 0.1045, 0.0274, 0.0348, 0.0572]\nsurprise: [0.4915, 0.4554, 0.7438, 0.6660, 0.6774]\n\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 303ms/step - accuracy: 0.9008 - loss: 0.0316 - val_accuracy: 0.2328 - val_loss: 0.8354 - learning_rate: 5.0000e-05\nEpoch 4/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.9336 - loss: 0.0199\nEpoch 4: val_accuracy did not improve from 0.30699\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 303ms/step - accuracy: 0.9337 - loss: 0.0198 - val_accuracy: 0.2507 - val_loss: 0.7423 - learning_rate: 5.0000e-05\nEpoch 5/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9555 - loss: 0.0134\nEpoch 5: val_accuracy did not improve from 0.30699\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 287ms/step - accuracy: 0.9555 - loss: 0.0134 - val_accuracy: 0.2707 - val_loss: 0.6670 - learning_rate: 5.0000e-05\nRestoring model weights from the end of the best epoch: 1.\n\nUnfreezing group 3/3 (20 layers)\nEpoch 1/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.6360 - loss: 0.1888\nEpoch 1: val_accuracy did not improve from 0.30699\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 322ms/step - accuracy: 0.6364 - loss: 0.1885 - val_accuracy: 0.2339 - val_loss: 0.7324 - learning_rate: 3.3333e-05\nEpoch 2/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.8310 - loss: 0.0603\nEpoch 2: val_accuracy did not improve from 0.30699\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 306ms/step - accuracy: 0.8311 - loss: 0.0602 - val_accuracy: 0.2544 - val_loss: 0.6596 - learning_rate: 3.3333e-05\nEpoch 3/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.8971 - loss: 0.0321\nEpoch 3: val_accuracy did not improve from 0.30699\n\nConfusion Matrix:\n[[ 49  65 116  73   0   0  33  85]\n [  5 162  83  31   1   0  13 101]\n [ 18  35 144  53   1   0  11  68]\n [  7  27  56 174   0   0  21 150]\n [ 12  73  95  41 137  25  21 264]\n [ 22  56  61  42  23  72  23 362]\n [ 10  54 103  79   0   0  55 101]\n [  9  31  49 114   0   1  11 312]]\nanger: 0.1164  contempt: 0.4091  disgust: 0.4364  fear: 0.4000  \nhappy: 0.2051  neutral: 0.1089  sad: 0.1368  surprise: 0.5920  \n\n\nClass Accuracy Trends:\nanger: [0.1259, 0.1401, 0.0784, 0.1069, 0.1164]\ncontempt: [0.5606, 0.4975, 0.4242, 0.4268, 0.4091]\ndisgust: [0.3636, 0.4515, 0.3424, 0.3818, 0.4364]\nfear: [0.2989, 0.3655, 0.3908, 0.4000, 0.4000]\nhappy: [0.0539, 0.1108, 0.0734, 0.0973, 0.2051]\nneutral: [0.0469, 0.0817, 0.0363, 0.0681, 0.1089]\nsad: [0.0771, 0.0896, 0.0572, 0.0697, 0.1368]\nsurprise: [0.6490, 0.5996, 0.6034, 0.6167, 0.5920]\n\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 308ms/step - accuracy: 0.8972 - loss: 0.0321 - val_accuracy: 0.2852 - val_loss: 0.5955 - learning_rate: 3.3333e-05\nEpoch 4/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.9379 - loss: 0.0198\nEpoch 4: val_accuracy improved from 0.30699 to 0.31526, saving model to model_checkpoints/affectnet_best.weights.h5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 303ms/step - accuracy: 0.9379 - loss: 0.0198 - val_accuracy: 0.3153 - val_loss: 0.5383 - learning_rate: 3.3333e-05\nEpoch 5/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9558 - loss: 0.0136\nEpoch 5: val_accuracy improved from 0.31526 to 0.33387, saving model to model_checkpoints/affectnet_best.weights.h5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 279ms/step - accuracy: 0.9558 - loss: 0.0136 - val_accuracy: 0.3339 - val_loss: 0.5005 - learning_rate: 3.3333e-05\nRestoring model weights from the end of the best epoch: 5.\nAffectNet model saved to 'affectnet_model.keras'\n\nEvaluating model on AffectNet test set\nAffectNet Test Accuracy: 0.3892\nAffectNet Weighted F1-Score: 0.3865\n\nAffectNet Classification Report:\n              precision    recall  f1-score   support\n\n       anger       0.46      0.21      0.29      3104\n    contempt       0.33      0.59      0.43      2871\n     disgust       0.26      0.57      0.36      2477\n        fear       0.40      0.42      0.41      3176\n       happy       0.87      0.31      0.45      5044\n     neutral       0.76      0.23      0.36      5126\n         sad       0.44      0.31      0.36      3091\n    surprise       0.30      0.62      0.41      4039\n\n    accuracy                           0.39     28928\n   macro avg       0.48      0.41      0.38     28928\nweighted avg       0.52      0.39      0.39     28928\n\n\n7. STAGE 2: Fine-tuning on FER2013 with progressive unfreezing\n\nStage 1: Training only the classification head (8 epochs)\nEpoch 1/8\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.3795 - loss: 1.0996\nEpoch 1: val_accuracy improved from -inf to 0.17637, saving model to model_checkpoints/fer2013_best.weights.h5\n\n⚠️ WARNING: Zero predictions for classes: happy, neutral\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 316ms/step - accuracy: 0.3798 - loss: 1.0969 - val_accuracy: 0.1764 - val_loss: 0.7808 - learning_rate: 0.0010\nEpoch 2/8\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.5084 - loss: 0.2523\nEpoch 2: val_accuracy did not improve from 0.17637\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 279ms/step - accuracy: 0.5085 - loss: 0.2522 - val_accuracy: 0.1702 - val_loss: 0.6162 - learning_rate: 0.0010\nEpoch 3/8\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.5764 - loss: 0.1788\nEpoch 3: val_accuracy improved from 0.17637 to 0.18987, saving model to model_checkpoints/fer2013_best.weights.h5\n\nConfusion Matrix:\n[[119  26 226  32   0   0  55  91]\n [  0   6   0   0   0   0   0   0]\n [  3   1  47   3   0   0   1   5]\n [ 73  13 142  72   1   0  64 191]\n [ 73  59 356  47   2   0  57 352]\n [ 52  43 210  46   0   4  86 211]\n [ 84  21 230  51   0   1 147 111]\n [  9   4  45  14   0   0  15 339]]\nanger: 0.2168  contempt: 1.0000  disgust: 0.7833  fear: 0.1295  \nhappy: 0.0021  neutral: 0.0061  sad: 0.2279  surprise: 0.7958  \n\n\nClass Accuracy Trends:\nanger: [0.0893, 0.1548, 0.2168]\ncontempt: [1.0000, 1.0000, 1.0000]\ndisgust: [0.7333, 0.8000, 0.7833]\nfear: [0.2644, 0.1295, 0.1295]\nhappy: [0.0000, 0.0011, 0.0021]\nneutral: [0.0000, 0.0046, 0.0061]\nsad: [0.1845, 0.1659, 0.2279]\nsurprise: [0.7629, 0.7934, 0.7958]\n\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 288ms/step - accuracy: 0.5765 - loss: 0.1788 - val_accuracy: 0.1899 - val_loss: 0.5616 - learning_rate: 0.0010\nEpoch 4/8\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.6262 - loss: 0.1402\nEpoch 4: val_accuracy improved from 0.18987 to 0.23414, saving model to model_checkpoints/fer2013_best.weights.h5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 296ms/step - accuracy: 0.6263 - loss: 0.1401 - val_accuracy: 0.2341 - val_loss: 0.4563 - learning_rate: 0.0010\nEpoch 5/8\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.6907 - loss: 0.1112\nEpoch 5: val_accuracy improved from 0.23414 to 0.25758, saving model to model_checkpoints/fer2013_best.weights.h5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 263ms/step - accuracy: 0.6907 - loss: 0.1112 - val_accuracy: 0.2576 - val_loss: 0.4251 - learning_rate: 0.0010\nEpoch 6/8\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.7359 - loss: 0.0907\nEpoch 6: val_accuracy improved from 0.25758 to 0.27509, saving model to model_checkpoints/fer2013_best.weights.h5\n\nConfusion Matrix:\n[[227   8  64  61   1  27 110  51]\n [  0   4   0   0   0   0   2   0]\n [ 13   1  24   2   0   2  16   2]\n [127   1  39 113   2  26 103 145]\n [197  23  92 110  34  62 165 263]\n [104   9  52  65   0 103 184 135]\n [126   4  65  95   0  37 245  73]\n [ 24   2  19  30   0  10  31 310]]\nanger: 0.4135  contempt: 0.6667  disgust: 0.4000  fear: 0.2032  \nhappy: 0.0359  neutral: 0.1580  sad: 0.3798  surprise: 0.7277  \n\n\nClass Accuracy Trends:\nanger: [0.1548, 0.2168, 0.3169, 0.4080, 0.4135]\ncontempt: [1.0000, 1.0000, 0.5000, 0.6667, 0.6667]\ndisgust: [0.8000, 0.7833, 0.6333, 0.5833, 0.4000]\nfear: [0.1295, 0.1295, 0.2122, 0.1565, 0.2032]\nhappy: [0.0011, 0.0021, 0.0137, 0.0349, 0.0359]\nneutral: [0.0046, 0.0061, 0.0276, 0.0798, 0.1580]\nsad: [0.1659, 0.2279, 0.3147, 0.3690, 0.3798]\nsurprise: [0.7934, 0.7958, 0.7840, 0.7535, 0.7277]\n\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 269ms/step - accuracy: 0.7359 - loss: 0.0907 - val_accuracy: 0.2751 - val_loss: 0.4162 - learning_rate: 0.0010\nEpoch 7/8\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7704 - loss: 0.0742\nEpoch 7: val_accuracy improved from 0.27509 to 0.27604, saving model to model_checkpoints/fer2013_best.weights.h5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 254ms/step - accuracy: 0.7704 - loss: 0.0741 - val_accuracy: 0.2760 - val_loss: 0.4364 - learning_rate: 0.0010\nEpoch 8/8\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.8009 - loss: 0.0610\nEpoch 8: val_accuracy did not improve from 0.27604\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 241ms/step - accuracy: 0.8010 - loss: 0.0610 - val_accuracy: 0.2720 - val_loss: 0.4566 - learning_rate: 0.0010\nRestoring model weights from the end of the best epoch: 1.\n\nStage 2: Fine-tuning with progressive unfreezing (12 epochs)\n\nUnfreezing group 1/3 (15 layers)\nEpoch 1/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.4742 - loss: 0.3223\nEpoch 1: val_accuracy did not improve from 0.27604\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 309ms/step - accuracy: 0.4744 - loss: 0.3219 - val_accuracy: 0.1960 - val_loss: 0.6283 - learning_rate: 1.0000e-04\nEpoch 2/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.6439 - loss: 0.1353\nEpoch 2: val_accuracy did not improve from 0.27604\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 282ms/step - accuracy: 0.6441 - loss: 0.1352 - val_accuracy: 0.2427 - val_loss: 0.5204 - learning_rate: 1.0000e-04\nEpoch 3/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.7766 - loss: 0.0737\nEpoch 3: val_accuracy improved from 0.27604 to 0.30137, saving model to model_checkpoints/fer2013_best.weights.h5\n\nConfusion Matrix:\n[[207   2  36 171   5   2  60  66]\n [  0   3   0   1   0   1   0   1]\n [  8   0  25  11   0   0   8   8]\n [ 87   0  16 258   1   5  58 131]\n [121   2  41 249 162  10  68 293]\n [ 88   3  17 211   6  26 104 197]\n [117   0  25 229   4   9 183  78]\n [ 15   0   0  90   1   1  12 307]]\nanger: 0.3770  contempt: 0.5000  disgust: 0.4167  fear: 0.4640  \nhappy: 0.1712  neutral: 0.0399  sad: 0.2837  surprise: 0.7207  \n\n\nClass Accuracy Trends:\nanger: [0.4153, 0.4171, 0.2022, 0.3133, 0.3770]\ncontempt: [0.6667, 0.6667, 1.0000, 0.8333, 0.5000]\ndisgust: [0.4667, 0.5667, 0.6500, 0.5833, 0.4167]\nfear: [0.1385, 0.0845, 0.4209, 0.5126, 0.4640]\nhappy: [0.0455, 0.0729, 0.0074, 0.0645, 0.1712]\nneutral: [0.2255, 0.2347, 0.0077, 0.0169, 0.0399]\nsad: [0.3380, 0.3132, 0.1287, 0.1860, 0.2837]\nsurprise: [0.7512, 0.7394, 0.6432, 0.6056, 0.7207]\n\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 287ms/step - accuracy: 0.7768 - loss: 0.0737 - val_accuracy: 0.3014 - val_loss: 0.4571 - learning_rate: 1.0000e-04\nEpoch 4/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.8680 - loss: 0.0404\nEpoch 4: val_accuracy improved from 0.30137 to 0.32102, saving model to model_checkpoints/fer2013_best.weights.h5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 301ms/step - accuracy: 0.8681 - loss: 0.0404 - val_accuracy: 0.3210 - val_loss: 0.4577 - learning_rate: 1.0000e-04\nEpoch 5/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9192 - loss: 0.0250\nEpoch 5: val_accuracy improved from 0.32102 to 0.33286, saving model to model_checkpoints/fer2013_best.weights.h5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 258ms/step - accuracy: 0.9192 - loss: 0.0250 - val_accuracy: 0.3329 - val_loss: 0.4332 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n\nUnfreezing group 2/3 (15 layers)\nEpoch 1/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.5845 - loss: 0.1875\nEpoch 1: val_accuracy did not improve from 0.33286\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 308ms/step - accuracy: 0.5847 - loss: 0.1874 - val_accuracy: 0.2469 - val_loss: 0.4959 - learning_rate: 5.0000e-05\nEpoch 2/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.7404 - loss: 0.0896\nEpoch 2: val_accuracy did not improve from 0.33286\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 280ms/step - accuracy: 0.7406 - loss: 0.0895 - val_accuracy: 0.2654 - val_loss: 0.4884 - learning_rate: 5.0000e-05\nEpoch 3/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.8461 - loss: 0.0483\nEpoch 3: val_accuracy did not improve from 0.33286\n\nConfusion Matrix:\n[[121   2  56 196   4  12  80  78]\n [  0   5   0   0   0   0   0   1]\n [  3   0  29  18   0   0   3   7]\n [ 32   1  21 268   0   6  75 153]\n [ 54   4  66 261 124   9  81 347]\n [ 27   1  20 242   6  47 108 201]\n [ 27   2  42 261   9  12 205  87]\n [  6   0   4  73   0   0  16 327]]\nanger: 0.2204  contempt: 0.8333  disgust: 0.4833  fear: 0.4820  \nhappy: 0.1311  neutral: 0.0721  sad: 0.3178  surprise: 0.7676  \n\n\nClass Accuracy Trends:\nanger: [0.2933, 0.2477, 0.2769, 0.2568, 0.2204]\ncontempt: [0.3333, 0.6667, 1.0000, 0.8333, 0.8333]\ndisgust: [0.2833, 0.3500, 0.6333, 0.5333, 0.4833]\nfear: [0.4101, 0.5522, 0.3543, 0.4874, 0.4820]\nhappy: [0.2051, 0.2812, 0.0571, 0.0698, 0.1311]\nneutral: [0.0445, 0.0445, 0.0383, 0.0429, 0.0721]\nsad: [0.4589, 0.3566, 0.2543, 0.2574, 0.3178]\nsurprise: [0.7394, 0.6808, 0.7629, 0.7512, 0.7676]\n\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 294ms/step - accuracy: 0.8462 - loss: 0.0483 - val_accuracy: 0.2895 - val_loss: 0.4629 - learning_rate: 5.0000e-05\nEpoch 4/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9032 - loss: 0.0292\nEpoch 4: val_accuracy did not improve from 0.33286\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 301ms/step - accuracy: 0.9033 - loss: 0.0292 - val_accuracy: 0.3097 - val_loss: 0.4462 - learning_rate: 5.0000e-05\nEpoch 5/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9394 - loss: 0.0192\nEpoch 5: val_accuracy improved from 0.33286 to 0.38423, saving model to model_checkpoints/fer2013_best.weights.h5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 273ms/step - accuracy: 0.9394 - loss: 0.0192 - val_accuracy: 0.3842 - val_loss: 0.3552 - learning_rate: 5.0000e-05\nRestoring model weights from the end of the best epoch: 5.\n\nUnfreezing group 3/3 (20 layers)\nEpoch 1/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.8484 - loss: 0.0555\nEpoch 1: val_accuracy did not improve from 0.38423\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 305ms/step - accuracy: 0.8485 - loss: 0.0554 - val_accuracy: 0.3385 - val_loss: 0.4030 - learning_rate: 3.3333e-05\nEpoch 2/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.9198 - loss: 0.0236\nEpoch 2: val_accuracy did not improve from 0.38423\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 284ms/step - accuracy: 0.9199 - loss: 0.0235 - val_accuracy: 0.3385 - val_loss: 0.4189 - learning_rate: 3.3333e-05\nEpoch 3/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.9494 - loss: 0.0151\nEpoch 3: val_accuracy did not improve from 0.38423\n\nConfusion Matrix:\n[[111   1  52 137  13  43 108  84]\n [  0   2   0   0   0   1   1   2]\n [  4   0  31  11   0   1   6   7]\n [ 51   0  26 183   4  29  93 170]\n [ 51   0  31 132 298  71  70 293]\n [ 19   0  11 125  16 174 128 179]\n [ 28   0  42 166  23  63 230  93]\n [  5   0   4  36   1   5  21 354]]\nanger: 0.2022  contempt: 0.3333  disgust: 0.5167  fear: 0.3291  \nhappy: 0.3150  neutral: 0.2669  sad: 0.3566  surprise: 0.8310  \n\n\nClass Accuracy Trends:\nanger: [0.2222, 0.2168, 0.2532, 0.2823, 0.2022]\ncontempt: [0.5000, 0.8333, 0.8333, 0.5000, 0.3333]\ndisgust: [0.3833, 0.3667, 0.5333, 0.5333, 0.5167]\nfear: [0.5054, 0.4784, 0.3489, 0.3255, 0.3291]\nhappy: [0.1892, 0.3975, 0.2939, 0.2844, 0.3150]\nneutral: [0.0859, 0.2285, 0.1580, 0.1856, 0.2669]\nsad: [0.3473, 0.3705, 0.3271, 0.2884, 0.3566]\nsurprise: [0.7418, 0.7324, 0.8286, 0.8498, 0.8310]\n\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 291ms/step - accuracy: 0.9495 - loss: 0.0151 - val_accuracy: 0.3568 - val_loss: 0.3979 - learning_rate: 3.3333e-05\nEpoch 4/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.9632 - loss: 0.0117\nEpoch 4: val_accuracy did not improve from 0.38423\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 300ms/step - accuracy: 0.9632 - loss: 0.0116 - val_accuracy: 0.3594 - val_loss: 0.3957 - learning_rate: 3.3333e-05\nEpoch 5/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.9730 - loss: 0.0099\nEpoch 5: val_accuracy improved from 0.38423 to 0.38920, saving model to model_checkpoints/fer2013_best.weights.h5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 271ms/step - accuracy: 0.9730 - loss: 0.0099 - val_accuracy: 0.3892 - val_loss: 0.3699 - learning_rate: 3.3333e-05\nRestoring model weights from the end of the best epoch: 5.\n\nEvaluating model on FER2013 test set\nFER2013 Test Accuracy: 0.3862\nFER2013 Weighted F1-Score: 0.3907\n\nFER2013 Classification Report:\n              precision    recall  f1-score   support\n\n       anger       0.36      0.24      0.29       894\n    contempt       0.93      0.46      0.62        54\n     disgust       0.15      0.51      0.23       111\n        fear       0.23      0.35      0.28      1024\n       happy       0.79      0.40      0.53      1774\n     neutral       0.42      0.28      0.33      1233\n         sad       0.34      0.34      0.34      1247\n    surprise       0.38      0.78      0.51       831\n\n    accuracy                           0.39      7168\n   macro avg       0.45      0.42      0.39      7168\nweighted avg       0.46      0.39      0.39      7168\n\n\nEvaluating model on Combined test set\nCombined Test Accuracy: 0.2896\nCombined Weighted F1-Score: 0.2762\n\nCombined Classification Report:\n              precision    recall  f1-score   support\n\n       anger       0.30      0.17      0.21      4126\n    contempt       0.89      0.01      0.02      2925\n     disgust       0.27      0.11      0.16      2588\n        fear       0.22      0.23      0.23      4200\n       happy       0.62      0.26      0.37      6818\n     neutral       0.28      0.47      0.35      6359\n         sad       0.19      0.41      0.26      4338\n    surprise       0.37      0.41      0.39      4870\n\n    accuracy                           0.29     36224\n   macro avg       0.39      0.26      0.25     36224\nweighted avg       0.39      0.29      0.28     36224\n\nFinal model saved to 'final_enhanced_emotion_model.keras'\n\n=== FINAL RESULTS ===\nAffectNet Test Accuracy: 0.3892\nAffectNet F1 Score: 0.3865\nFER2013 Test Accuracy: 0.3862\nFER2013 F1 Score: 0.3907\nCombined Test Accuracy: 0.2896\nCombined F1 Score: 0.2762\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Version 6o current accuracy\n#=== FINAL RESULTS === 96x96\n#AffectNet Test Accuracy: 0.4461\n#AffectNet F1 Score: 0.4446\n#FER2013 Test Accuracy: 0.2203\n#FER2013 F1 Score: 0.1875\n#Combined Test Accuracy: 0.3168\n#Combined F1 Score: 0.3050\n\n#=== FINAL RESULTS === 224x224\n#AffectNet Test Accuracy: 0.4669\n#AffectNet F1 Score: 0.4799\n#FER2013 Test Accuracy: 0.2953\n#FER2013 F1 Score: 0.2474\n#Combined Test Accuracy: 0.3050\n#Combined F1 Score: 0.2910\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom tensorflow.keras.applications import MobileNetV2\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\n\n# =============================================================================\n# Configure GPU and enable mixed precision\n# =============================================================================\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(f\"Found {len(gpus)} GPUs: Memory growth enabled\")\n    except RuntimeError as e:\n        print(f\"GPU error: {e}\")\n\n# Enable mixed precision training\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled\")\n\n# =============================================================================\n# Key parameters\n# =============================================================================\nIMG_SIZE = 224  # Keep at 96x96 as specified\nBATCH_SIZE = 128\nAUTOTUNE = tf.data.AUTOTUNE\nLOG_DIR = \"./emotion_logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\n# Create all required directories\ndef ensure_dir(directory):\n    \"\"\"Make sure a directory exists, creating it if necessary\"\"\"\n    if not os.path.exists(directory):\n        os.makedirs(directory, exist_ok=True)\n\n# Create main log directories\nensure_dir(LOG_DIR)\nensure_dir(LOG_DIR + '/affectnet')\nensure_dir(LOG_DIR + '/fer2013')\nensure_dir(LOG_DIR + '/combined')\nensure_dir(\"./model_checkpoints\")\n\n# Define problematic classes for targeted augmentation\nPROBLEMATIC_CLASSES = ['surprise', 'sad', 'disgust']\n\n# =============================================================================\n# Custom Label Smoothing Loss\n# =============================================================================\ndef label_smoothing_loss(epsilon=0.1):\n    \"\"\"\n    Cross entropy loss with label smoothing to prevent model from being too confident.\n    \n    Args:\n        epsilon: Smoothing factor (0 = no smoothing, 1 = complete smoothing)\n        \n    Returns:\n        Loss function\n    \"\"\"\n    def loss_fn(y_true, y_pred):\n        num_classes = tf.cast(tf.shape(y_true)[-1], tf.float32)\n        \n        # Apply label smoothing\n        y_true = y_true * (1.0 - epsilon) + (epsilon / num_classes)\n        \n        # Calculate cross entropy with extra small epsilon to prevent log(0)\n        return -tf.reduce_sum(y_true * tf.math.log(y_pred + 1e-7), axis=-1)\n    \n    return loss_fn\n\n# =============================================================================\n# Build DataFrame from dataset directory structure\n# =============================================================================\ndef build_image_df(root_dir, subfolders=[\"fer2013\", \"affectnet\"]):\n    \"\"\"\n    Scans the directory and returns a DataFrame with file paths and labels.\n    \"\"\"\n    data = []\n    emotions = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n    \n    print(f\"Found {len(emotions)} emotion categories: {emotions}\")\n    \n    for emotion in emotions:\n        emotion_path = os.path.join(root_dir, emotion)\n        for sub in subfolders:\n            sub_path = os.path.join(emotion_path, sub)\n            if os.path.exists(sub_path):\n                img_files = [f for f in os.listdir(sub_path) \n                            if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n                \n                print(f\"Found {len(img_files)} images in {emotion}/{sub}\")\n                \n                for img_file in img_files:\n                    data.append({\n                        \"filepath\": os.path.join(sub_path, img_file),\n                        \"label\": emotion,\n                        \"source\": sub\n                    })\n    \n    df = pd.DataFrame(data)\n    print(f\"Total images: {len(df)}\")\n    return df\n\n# =============================================================================\n# Fixed graph-compatible preprocessing function\n# =============================================================================\ndef preprocess_image(file_path, label, source, training=True):\n    \"\"\"\n    Fixed graph-compatible preprocessing with class-specific augmentation.\n    \n    Args:\n        file_path: Path to the image file\n        label: Emotion label (as index)\n        source: Dataset source ('fer2013' or 'affectnet')\n        training: Whether to apply augmentation\n        \n    Returns:\n        Preprocessed image and one-hot encoded label\n    \"\"\"\n    # Read the file\n    img = tf.io.read_file(file_path)\n    \n    # Decode image with proper error handling\n    def decode_image():\n        try:\n            decoded = tf.image.decode_image(img, channels=3, expand_animations=False)\n            decoded = tf.ensure_shape(decoded, [None, None, 3])\n            return decoded\n        except:\n            # Return blank image if decoding fails\n            return tf.zeros([IMG_SIZE, IMG_SIZE, 3], dtype=tf.uint8)\n    \n    img = decode_image()\n    \n    # Resize to target size\n    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE], method='bilinear')\n    \n    # Normalize pixel values using MobileNet standard preprocessing\n    img = tf.cast(img, tf.float32)\n    img = img / 127.5 - 1.0  # Scale to [-1, 1]\n    \n    # Apply basic augmentation during training\n    if training:\n        # Random flip - works in graph mode\n        img = tf.image.random_flip_left_right(img)\n        \n        # Basic brightness and contrast\n        img = tf.image.random_brightness(img, 0.2)\n        img = tf.image.random_contrast(img, 0.8, 1.2)\n            \n        # Add random noise to improve robustness\n        noise = tf.random.normal(shape=tf.shape(img), mean=0.0, stddev=0.01)\n        img = img + noise\n        \n        # Ensure values stay in valid range\n        img = tf.clip_by_value(img, -1.0, 1.0)\n    \n    # One-hot encode label\n    label = tf.one_hot(label, depth=8)  # 8 emotion classes\n    \n    return img, label\n\n# =============================================================================\n# Fixed dataset creation function\n# =============================================================================\ndef create_dataset(dataframe, is_training=True, dataset_type=None):\n    \"\"\"\n    Creates a tf.data.Dataset with fixed preprocessing.\n    \n    Args:\n        dataframe: DataFrame with filepath, label, and source columns\n        is_training: Whether this is for training (includes augmentation)\n        dataset_type: Optional filter for specific dataset ('affectnet' or 'fer2013')\n        \n    Returns:\n        tf.data.Dataset and class mapping\n    \"\"\"\n    # Optionally filter to specific dataset\n    if dataset_type is not None:\n        dataframe = dataframe[dataframe['source'] == dataset_type].reset_index(drop=True)\n        print(f\"Filtered to {len(dataframe)} {dataset_type} images\")\n    \n    # Create class indices\n    class_indices = {cls: i for i, cls in enumerate(sorted(dataframe[\"label\"].unique()))}\n    labels = [class_indices[label] for label in dataframe[\"label\"]]\n    \n    # Create dataset\n    ds = tf.data.Dataset.from_tensor_slices((\n        dataframe[\"filepath\"].values,\n        labels,\n        dataframe[\"source\"].values\n    ))\n    \n    # Apply preprocessing with training flag\n    training_value = tf.constant(is_training)\n    ds = ds.map(\n        lambda path, label, source: preprocess_image(path, label, source, training=training_value),\n        num_parallel_calls=AUTOTUNE\n    )\n    \n    if is_training:\n        # Training pipeline\n        ds = ds.shuffle(buffer_size=min(10000, len(dataframe)))\n        \n    # Repeat dataset for multiple epochs\n    ds = ds.repeat()\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(AUTOTUNE)\n    \n    return ds, class_indices\n\n# =============================================================================\n# Create balanced dataset with emphasis classes\n# =============================================================================\ndef create_emphasis_dataset(dataframe, is_training=True, emphasis_classes=PROBLEMATIC_CLASSES):\n    \"\"\"\n    Creates a balanced dataset with emphasis on problematic classes.\n    \n    Args:\n        dataframe: Input DataFrame\n        is_training: Whether to apply training augmentations\n        emphasis_classes: List of classes to emphasize (oversample)\n        \n    Returns:\n        Balanced tf.data.Dataset with emphasis on specified classes\n    \"\"\"\n    balanced_data = []\n    \n    # Sample from each class with emphasis on problematic ones\n    for class_name in sorted(dataframe[\"label\"].unique()):\n        class_df = dataframe[dataframe[\"label\"] == class_name]\n        samples_per_class = 400  # Base sampling\n        \n        # Increase samples for emphasis classes\n        if class_name in emphasis_classes:\n            samples_per_class = 600  # 50% more samples for problematic classes\n            \n        # Sample with replacement if needed\n        if len(class_df) <= samples_per_class:\n            sampled = class_df.sample(n=samples_per_class, replace=True)\n        else:\n            sampled = class_df.sample(n=samples_per_class, replace=False)\n            \n        balanced_data.append(sampled)\n    \n    # Combine all balanced samples\n    balanced_df = pd.concat(balanced_data, ignore_index=True)\n    print(f\"Created balanced dataset with {len(balanced_df)} samples (with emphasis on {emphasis_classes})\")\n    \n    # Create dataset\n    return create_dataset(balanced_df, is_training=is_training)\n\n# =============================================================================\n# Enhanced Confusion Matrix Callback with Class-Specific Monitoring\n# =============================================================================\nclass EnhancedConfusionMatrixCallback(tf.keras.callbacks.Callback):\n    \"\"\"\n    Enhanced callback to monitor class-specific metrics during training.\n    \"\"\"\n    def __init__(self, validation_data, class_names, log_dir, model_name=\"model\", freq=5):\n        super(EnhancedConfusionMatrixCallback, self).__init__()\n        self.validation_data = validation_data\n        self.class_names = class_names\n        self.freq = freq\n        self.log_dir = log_dir\n        self.model_name = model_name\n        self.zero_prediction_classes = set()  # Track classes with zero predictions\n        self.class_metrics_history = {cls: [] for cls in class_names}  # Track per-class metrics\n        \n        # Ensure log directory exists\n        ensure_dir(self.log_dir)\n        \n    def on_epoch_end(self, epoch, logs=None):\n        # Calculate and log class-specific metrics every epoch\n        val_steps = 30  # Limit computation\n        y_true = []\n        y_pred = []\n        \n        # Get predictions for validation data\n        for i, (images, labels) in enumerate(self.validation_data):\n            if i >= val_steps:\n                break\n            batch_preds = self.model.predict(images, verbose=0)\n            y_pred.append(np.argmax(batch_preds, axis=1))\n            y_true.append(np.argmax(labels.numpy(), axis=1))\n        \n        # Flatten the lists\n        y_true = np.concatenate(y_true)\n        y_pred = np.concatenate(y_pred)\n        \n        # Calculate confusion matrix\n        cm = confusion_matrix(y_true, y_pred)\n        \n        # Calculate per-class metrics\n        class_accuracies = np.zeros(len(self.class_names))\n        for i in range(len(self.class_names)):\n            if np.sum(y_true == i) > 0:  # Avoid division by zero\n                class_accuracies[i] = cm[i, i] / np.sum(y_true == i)\n                \n            # Track metrics history\n            self.class_metrics_history[self.class_names[i]].append(class_accuracies[i])\n        \n        # Check for classes with zero predictions\n        zero_pred_classes = []\n        for i, class_name in enumerate(self.class_names):\n            if np.sum(cm[:, i]) == 0:\n                zero_pred_classes.append(class_name)\n                self.zero_prediction_classes.add(class_name)\n        \n        # Log warnings for zero prediction classes\n        if zero_pred_classes:\n            warning_msg = f\"\\n⚠️ WARNING: Zero predictions for classes: {', '.join(zero_pred_classes)}\"\n            print(warning_msg)\n            \n            # Save warning to log file\n            with open(f\"{self.log_dir}/warnings.txt\", \"a\") as f:\n                f.write(f\"Epoch {epoch+1}: {warning_msg}\\n\")\n        \n        # Save visualizations and detailed reports on the specified frequency\n        if (epoch + 1) % self.freq == 0:\n            # Print confusion matrix\n            print(\"\\nConfusion Matrix:\")\n            print(cm)\n            \n            # Print per-class accuracy\n            for i, (name, acc) in enumerate(zip(self.class_names, class_accuracies)):\n                print(f\"{name}: {acc:.4f}\", end=\"  \")\n                if (i + 1) % 4 == 0:\n                    print()  # New line for readability\n            print(\"\\n\")\n            \n            # Print class accuracy trends instead of plotting them\n            print(\"Class Accuracy Trends:\")\n            for class_name in self.class_names:\n                history = self.class_metrics_history[class_name]\n                trend = \", \".join([f\"{acc:.4f}\" for acc in history[-5:]])  # Show last 5 epochs\n                print(f\"{class_name}: [{trend}]\")\n            print()\n            \n            # Save confusion matrix visualization (still useful)\n            plt.figure(figsize=(10, 8))\n            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                       xticklabels=self.class_names,\n                       yticklabels=self.class_names)\n            plt.xlabel('Predicted')\n            plt.ylabel('True')\n            plt.title(f'Confusion Matrix - {self.model_name} - Epoch {epoch+1}')\n            plt.tight_layout()\n            \n            try:\n                plt.savefig(f'{self.log_dir}/confusion_matrix_epoch_{epoch+1}.png')\n            except Exception as e:\n                print(f\"Warning: Could not save confusion matrix plot: {e}\")\n            \n            plt.close()\n\n# =============================================================================\n# Create emotion recognition model with additional MLP head\n# =============================================================================\ndef create_emotion_model(num_classes):\n    \"\"\"\n    Create a facial emotion recognition model with enhanced classification head.\n    \n    Args:\n        num_classes: Number of emotion classes\n        \n    Returns:\n        Compiled Keras model and base model\n    \"\"\"\n    # Input shape\n    input_shape = (IMG_SIZE, IMG_SIZE, 3)\n    \n    # Create input layer\n    inputs = keras.layers.Input(shape=input_shape)\n    \n    # Use MobileNetV2 as base\n    base_model = MobileNetV2(\n        include_top=False,\n        weights='imagenet',\n        input_tensor=inputs,\n        alpha=1.0  # Controls model width\n    )\n    print(\"Using MobileNetV2 base model\")\n    \n    # Freeze base model layers\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    # Add custom head with dropout and batch normalization\n    x = base_model.output\n    x = keras.layers.GlobalAveragePooling2D()(x)\n    \n    # First dense block\n    x = keras.layers.Dense(256)(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.Dropout(0.4)(x)\n    \n    # Second dense block\n    x = keras.layers.Dense(128)(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.Dropout(0.3)(x)\n    \n    # Output layer with label smoothing\n    outputs = keras.layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n    \n    # Create model\n    model = keras.Model(inputs=inputs, outputs=outputs)\n    \n    # Compile with label smoothing loss\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n        loss=label_smoothing_loss(epsilon=0.1),\n        metrics=['accuracy']\n    )\n    \n    return model, base_model\n\n# =============================================================================\n# Evaluation function\n# =============================================================================\ndef evaluate_model(model, test_ds, steps, class_names, log_dir, dataset_name=\"\"):\n    \"\"\"\n    Evaluate model with detailed metrics and visualizations.\n    \"\"\"\n    print(f\"\\nEvaluating model on {dataset_name} test set\")\n    \n    # Get predictions\n    y_true = []\n    y_pred = []\n    \n    # Loop through test batches\n    for i, (images, labels) in enumerate(test_ds):\n        if i >= steps:\n            break\n        batch_preds = model.predict(images, verbose=0)\n        y_pred.append(np.argmax(batch_preds, axis=1))\n        y_true.append(np.argmax(labels.numpy(), axis=1))\n    \n    # Concatenate\n    y_true = np.concatenate(y_true)\n    y_pred = np.concatenate(y_pred)\n    \n    # Calculate metrics\n    test_accuracy = np.mean(y_pred == y_true)\n    f1 = f1_score(y_true, y_pred, average='weighted')\n    \n    print(f\"{dataset_name} Test Accuracy: {test_accuracy:.4f}\")\n    print(f\"{dataset_name} Weighted F1-Score: {f1:.4f}\")\n    \n    # Calculate confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Visualize confusion matrix\n    plt.figure(figsize=(12, 10))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n               xticklabels=class_names,\n               yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title(f'Confusion Matrix - {dataset_name} Test Set')\n    plt.tight_layout()\n    \n    try:\n        plt.savefig(f'{log_dir}/confusion_matrix_{dataset_name}_test.png')\n    except Exception as e:\n        print(f\"Warning: Could not save confusion matrix plot: {e}\")\n        \n    plt.close()\n    \n    # Print classification report\n    print(f\"\\n{dataset_name} Classification Report:\")\n    report = classification_report(\n        y_true, \n        y_pred, \n        target_names=class_names,\n        zero_division=0\n    )\n    print(report)\n    \n    # Save report to file\n    with open(f'{log_dir}/classification_report_{dataset_name}.txt', 'w') as f:\n        f.write(report)\n    \n    return {\n        'accuracy': test_accuracy,\n        'f1_score': f1,\n        'confusion_matrix': cm\n    }\n\n# =============================================================================\n# Two-Stage Fine-Tuning with Progressive Unfreezing\n# =============================================================================\ndef train_with_progressive_unfreezing(model, base_model, train_ds, val_ds, \n                                    steps_per_epoch, val_steps, \n                                    epochs_head=10, epochs_finetune=20,\n                                    callbacks=None, class_weights=None):\n    \"\"\"\n    Two-stage training approach: first train only the head, then progressively unfreeze layers.\n    \n    Args:\n        model: The model to train\n        base_model: The base model part (for unfreezing)\n        train_ds: Training dataset\n        val_ds: Validation dataset\n        steps_per_epoch: Steps per training epoch\n        val_steps: Validation steps\n        epochs_head: Epochs for head-only training\n        epochs_finetune: Epochs for fine-tuning\n        callbacks: List of callbacks\n        class_weights: Class weights for handling imbalance\n        \n    Returns:\n        Training history\n    \"\"\"\n    print(f\"\\nStage 1: Training only the classification head ({epochs_head} epochs)\")\n    \n    # Ensure base model is frozen\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    # Compile with higher learning rate for head training\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n        loss=label_smoothing_loss(epsilon=0.1),\n        metrics=['accuracy']\n    )\n    \n    # Train head only\n    history_head = model.fit(\n        train_ds,\n        epochs=epochs_head,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=val_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    \n    print(f\"\\nStage 2: Fine-tuning with progressive unfreezing ({epochs_finetune} epochs)\")\n    \n    # Progressively unfreeze layers in groups\n    fine_tuning_history = []\n    \n    # Groups of layers to unfreeze (from last to first)\n    layer_groups = [\n        # Unfreeze last layers first (deeper = more specific features)\n        base_model.layers[-15:],  # Last block\n        base_model.layers[-30:-15],  # Second-to-last block\n        base_model.layers[-50:-30]   # Third-to-last block\n    ]\n    \n    for i, group in enumerate(layer_groups):\n        print(f\"\\nUnfreezing group {i+1}/{len(layer_groups)} ({len(group)} layers)\")\n        \n        # Unfreeze current group\n        for layer in group:\n            layer.trainable = True\n            \n        # Recompile with lower learning rate as we go deeper\n        lr = 1e-4 / (i + 1)  # Decrease learning rate for deeper layers\n        \n        model.compile(\n            optimizer=keras.optimizers.Adam(learning_rate=lr),\n            loss=label_smoothing_loss(epsilon=0.1),\n            metrics=['accuracy']\n        )\n        \n        # Train for a few epochs\n        epochs_per_group = max(5, epochs_finetune // len(layer_groups))\n        \n        history = model.fit(\n            train_ds,\n            epochs=epochs_per_group,\n            steps_per_epoch=steps_per_epoch,\n            validation_data=val_ds,\n            validation_steps=val_steps,\n            callbacks=callbacks,\n            class_weight=class_weights,\n            verbose=1\n        )\n        \n        fine_tuning_history.append(history)\n    \n    # Return combined history\n    return history_head, fine_tuning_history\n\n# =============================================================================\n# Sequential Training Pipeline\n# =============================================================================\ndef train_enhanced_emotion_model(data_dir):\n    \"\"\"\n    Enhanced sequential training with all improvements.\n    \n    Args:\n        data_dir: Path to dataset directory\n        \n    Returns:\n        Trained model and evaluation metrics\n    \"\"\"\n    print(\"Starting enhanced sequential emotion recognition training\")\n    \n    # 1. Load and prepare data\n    print(\"\\n1. Loading datasets\")\n    train_dir = os.path.join(data_dir, \"Train\")\n    test_dir = os.path.join(data_dir, \"Test\")\n    \n    train_df_full = build_image_df(train_dir)\n    test_df = build_image_df(test_dir)\n    \n    # Show dataset distributions\n    print(\"\\nAffectNet training distribution:\")\n    print(train_df_full[train_df_full['source'] == 'affectnet']['label'].value_counts())\n    \n    print(\"\\nFER2013 training distribution:\")\n    print(train_df_full[train_df_full['source'] == 'fer2013']['label'].value_counts())\n    \n    # 2. Split test set by dataset source\n    test_affectnet_df = test_df[test_df['source'] == 'affectnet']\n    test_fer_df = test_df[test_df['source'] == 'fer2013']\n    \n    print(f\"\\nTest sets: AffectNet={len(test_affectnet_df)}, FER2013={len(test_fer_df)}\")\n    \n    # Get classes for later use\n    classes = sorted(train_df_full[\"label\"].unique())\n    num_classes = len(classes)\n    print(f\"Classes: {classes}\")\n    \n    # 3. Create validation splits\n    # For AffectNet\n    affectnet_train_df = train_df_full[train_df_full['source'] == 'affectnet']\n    affectnet_train_df, affectnet_val_df = train_test_split(\n        affectnet_train_df, \n        test_size=0.15, \n        stratify=affectnet_train_df[\"label\"], \n        random_state=42\n    )\n    \n    # For FER2013\n    fer_train_df = train_df_full[train_df_full['source'] == 'fer2013']\n    fer_train_df, fer_val_df = train_test_split(\n        fer_train_df, \n        test_size=0.15, \n        stratify=fer_train_df[\"label\"], \n        random_state=42\n    )\n    \n    print(f\"AffectNet: {len(affectnet_train_df)} train, {len(affectnet_val_df)} validation\")\n    print(f\"FER2013: {len(fer_train_df)} train, {len(fer_val_df)} validation\")\n    \n    # 4. Create datasets with emphasis on problematic classes\n    print(\"\\n2. Creating enhanced data pipelines\")\n    \n    # AffectNet datasets\n    affectnet_train_ds, class_indices = create_emphasis_dataset(\n        affectnet_train_df, is_training=True)\n    \n    affectnet_val_ds, _ = create_dataset(\n        affectnet_val_df, is_training=False, \n        dataset_type='affectnet')\n    \n    affectnet_test_ds, _ = create_dataset(\n        test_affectnet_df, is_training=False, \n        dataset_type='affectnet')\n    \n    # FER2013 datasets\n    fer_train_ds, _ = create_emphasis_dataset(\n        fer_train_df, is_training=True)\n    \n    fer_val_ds, _ = create_dataset(\n        fer_val_df, is_training=False, \n        dataset_type='fer2013')\n    \n    fer_test_ds, _ = create_dataset(\n        test_fer_df, is_training=False, \n        dataset_type='fer2013')\n    \n    # Create combined test dataset\n    combined_test_ds, _ = create_dataset(\n        test_df, is_training=False)\n    \n    # 5. Calculate steps\n    affectnet_steps_per_epoch = len(affectnet_train_df) // BATCH_SIZE\n    affectnet_val_steps = len(affectnet_val_df) // BATCH_SIZE\n    affectnet_test_steps = len(test_affectnet_df) // BATCH_SIZE\n    \n    fer_steps_per_epoch = len(fer_train_df) // BATCH_SIZE\n    fer_val_steps = len(fer_val_df) // BATCH_SIZE\n    fer_test_steps = len(test_fer_df) // BATCH_SIZE\n    \n    combined_test_steps = len(test_df) // BATCH_SIZE\n    \n    # 6. Create enhanced model\n    print(\"\\n3. Creating enhanced model\")\n    model, base_model = create_emotion_model(num_classes)\n    \n    # 7. Compute class weights for each dataset with adjustments\n    print(\"\\n4. Computing class weights with adjustments for problematic classes\")\n    \n    # AffectNet class weights\n    affectnet_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(affectnet_train_df[\"label\"]),\n        y=affectnet_train_df[\"label\"]\n    )\n    affectnet_class_weights = {class_indices[label]: weight for label, weight in \n                     zip(np.unique(affectnet_train_df[\"label\"]), affectnet_weights)}\n    \n    # FER2013 class weights\n    fer_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(fer_train_df[\"label\"]),\n        y=fer_train_df[\"label\"]\n    )\n    fer_class_weights = {class_indices[label]: weight for label, weight in \n                zip(np.unique(fer_train_df[\"label\"]), fer_weights)}\n    \n    # Increase weights for problematic classes\n    for problem_class in PROBLEMATIC_CLASSES:\n        if problem_class in class_indices:\n            class_idx = class_indices[problem_class]\n            # Increase the weight by 20%\n            if class_idx in affectnet_class_weights:\n                affectnet_class_weights[class_idx] *= 1.2\n            if class_idx in fer_class_weights:\n                fer_class_weights[class_idx] *= 1.2\n    \n    print(\"Enhanced AffectNet class weights:\", affectnet_class_weights)\n    print(\"Enhanced FER2013 class weights:\", fer_class_weights)\n    \n    # 8. Setup callbacks with enhanced monitoring\n    print(\"\\n5. Setting up enhanced callbacks\")\n    \n    # Base callbacks shared across training phases\n    base_callbacks = [\n        # Early stopping\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=10,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        # Learning rate scheduler\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.5,\n            patience=5,\n            min_lr=1e-6,\n            verbose=1\n        ),\n        # TensorBoard\n        tf.keras.callbacks.TensorBoard(\n            log_dir=LOG_DIR,\n            histogram_freq=1,\n            update_freq='epoch'\n        )\n    ]\n    \n    # AffectNet-specific callbacks\n    affectnet_callbacks = base_callbacks + [\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'model_checkpoints/affectnet_best.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        ),\n        # Enhanced confusion matrix monitoring\n        EnhancedConfusionMatrixCallback(\n            affectnet_val_ds, \n            classes, \n            log_dir=LOG_DIR + '/affectnet',\n            model_name=\"AffectNet\",\n            freq=3\n        ),\n        # CSV Logger\n        tf.keras.callbacks.CSVLogger(\n            'affectnet_training_log.csv', \n            append=True\n        )\n    ]\n    \n    # FER2013-specific callbacks\n    fer_callbacks = base_callbacks + [\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'model_checkpoints/fer2013_best.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        ),\n        # Enhanced confusion matrix monitoring\n        EnhancedConfusionMatrixCallback(\n            fer_val_ds, \n            classes, \n            log_dir=LOG_DIR + '/fer2013',\n            model_name=\"FER2013\",\n            freq=3\n        ),\n        # CSV Logger\n        tf.keras.callbacks.CSVLogger(\n            'fer2013_training_log.csv', \n            append=True\n        )\n    ]\n    \n    # 9. STAGE 1: Train on AffectNet using progressive unfreezing\n    print(\"\\n6. STAGE 1: Training on AffectNet with progressive unfreezing\")\n    \n    history_affectnet_head, history_affectnet_finetune = train_with_progressive_unfreezing(\n        model, base_model,\n        affectnet_train_ds, affectnet_val_ds,\n        affectnet_steps_per_epoch, affectnet_val_steps,\n        epochs_head=10, epochs_finetune=15,\n        callbacks=affectnet_callbacks,\n        class_weights=affectnet_class_weights\n    )\n    \n    # Save AffectNet model\n    model.save(\"affectnet_model.keras\")\n    print(\"AffectNet model saved to 'affectnet_model.keras'\")\n    \n    # 10. Evaluate on AffectNet test set\n    affectnet_metrics = evaluate_model(\n        model, \n        affectnet_test_ds, \n        affectnet_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"AffectNet\"\n    )\n    \n    # 11. STAGE 2: Fine-tune on FER2013 with progressive unfreezing\n    print(\"\\n7. STAGE 2: Fine-tuning on FER2013 with progressive unfreezing\")\n    \n    history_fer_head, history_fer_finetune = train_with_progressive_unfreezing(\n        model, base_model,\n        fer_train_ds, fer_val_ds,\n        fer_steps_per_epoch, fer_val_steps,\n        epochs_head=8, epochs_finetune=12,\n        callbacks=fer_callbacks,\n        class_weights=fer_class_weights\n    )\n    \n    # 12. Evaluate on FER2013 test set\n    fer_metrics = evaluate_model(\n        model, \n        fer_test_ds, \n        fer_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"FER2013\"\n    )\n    \n    # 13. Evaluate on combined test set\n    combined_metrics = evaluate_model(\n        model, \n        combined_test_ds, \n        combined_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"Combined\"\n    )\n    \n    # 14. Save the final model\n    model.save(\"final_enhanced_emotion_model.keras\")\n    print(\"Final model saved to 'final_enhanced_emotion_model.keras'\")\n    \n    # Return models and metrics\n    return model, {\n        'affectnet': affectnet_metrics,\n        'fer2013': fer_metrics,\n        'combined': combined_metrics\n    }\n\n# =============================================================================\n# Main entry point\n# =============================================================================\nif __name__ == \"__main__\":\n    # Set data directory path\n    data_dir = \"/kaggle/input/custom-fer2013affectnet/Custom_ferAffect2013net\"\n    \n    # Train model with all improvements\n    model, metrics = train_enhanced_emotion_model(data_dir)\n    \n    # Print final results\n    print(\"\\n=== FINAL RESULTS ===\")\n    print(f\"AffectNet Test Accuracy: {metrics['affectnet']['accuracy']:.4f}\")\n    print(f\"AffectNet F1 Score: {metrics['affectnet']['f1_score']:.4f}\")\n    print(f\"FER2013 Test Accuracy: {metrics['fer2013']['accuracy']:.4f}\")\n    print(f\"FER2013 F1 Score: {metrics['fer2013']['f1_score']:.4f}\")\n    print(f\"Combined Test Accuracy: {metrics['combined']['accuracy']:.4f}\")\n    print(f\"Combined F1 Score: {metrics['combined']['f1_score']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T16:21:24.947779Z","iopub.execute_input":"2025-03-11T16:21:24.948071Z","iopub.status.idle":"2025-03-11T17:14:32.218109Z","shell.execute_reply.started":"2025-03-11T16:21:24.948046Z","shell.execute_reply":"2025-03-11T17:14:32.217305Z"}},"outputs":[{"name":"stdout","text":"Found 1 GPUs: Memory growth enabled\nMixed precision enabled\nStarting enhanced sequential emotion recognition training\n\n1. Loading datasets\nFound 8 emotion categories: ['surprise', 'fear', 'neutral', 'sad', 'disgust', 'contempt', 'happy', 'anger']\nFound 3161 images in surprise/fer2013\nFound 4039 images in surprise/affectnet\nFound 4092 images in fear/fer2013\nFound 3176 images in fear/affectnet\nFound 4951 images in neutral/fer2013\nFound 5126 images in neutral/affectnet\nFound 4823 images in sad/fer2013\nFound 3091 images in sad/affectnet\nFound 435 images in disgust/fer2013\nFound 2477 images in disgust/affectnet\nFound 54 images in contempt/fer2013\nFound 2871 images in contempt/affectnet\nFound 7199 images in happy/fer2013\nFound 5044 images in happy/affectnet\nFound 3987 images in anger/fer2013\nFound 3218 images in anger/affectnet\nTotal images: 57744\nFound 8 emotion categories: ['surprise', 'fear', 'neutral', 'sad', 'disgust', 'contempt', 'happy', 'anger']\nFound 831 images in surprise/fer2013\nFound 4039 images in surprise/affectnet\nFound 1024 images in fear/fer2013\nFound 3176 images in fear/affectnet\nFound 1233 images in neutral/fer2013\nFound 5126 images in neutral/affectnet\nFound 1247 images in sad/fer2013\nFound 3091 images in sad/affectnet\nFound 111 images in disgust/fer2013\nFound 2477 images in disgust/affectnet\nFound 54 images in contempt/fer2013\nFound 2871 images in contempt/affectnet\nFound 1774 images in happy/fer2013\nFound 5044 images in happy/affectnet\nFound 958 images in anger/fer2013\nFound 3218 images in anger/affectnet\nTotal images: 36274\n\nAffectNet training distribution:\nlabel\nneutral     5126\nhappy       5044\nsurprise    4039\nanger       3218\nfear        3176\nsad         3091\ncontempt    2871\ndisgust     2477\nName: count, dtype: int64\n\nFER2013 training distribution:\nlabel\nhappy       7199\nneutral     4951\nsad         4823\nfear        4092\nanger       3987\nsurprise    3161\ndisgust      435\ncontempt      54\nName: count, dtype: int64\n\nTest sets: AffectNet=29042, FER2013=7232\nClasses: ['anger', 'contempt', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\nAffectNet: 24685 train, 4357 validation\nFER2013: 24396 train, 4306 validation\n\n2. Creating enhanced data pipelines\nCreated balanced dataset with 3800 samples (with emphasis on ['surprise', 'sad', 'disgust'])\nFiltered to 4357 affectnet images\nFiltered to 29042 affectnet images\nCreated balanced dataset with 3800 samples (with emphasis on ['surprise', 'sad', 'disgust'])\nFiltered to 4306 fer2013 images\nFiltered to 7232 fer2013 images\n\n3. Creating enhanced model\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-1-19a4ad10bc36>:394: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n  base_model = MobileNetV2(\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nUsing MobileNetV2 base model\n\n4. Computing class weights with adjustments for problematic classes\nEnhanced AffectNet class weights: {0: 1.128199268738574, 1: 1.2646004098360655, 2: 1.758190883190883, 3: 1.142824074074074, 4: 0.7197632376953581, 5: 0.7081994491622676, 6: 1.4094975256947089, 7: 1.0785755898630933}\nEnhanced FER2013 class weights: {0: 0.899822956624373, 1: 66.29347826086956, 2: 9.890270270270271, 3: 0.8767970097757332, 4: 0.4983657460369341, 5: 0.7246910646387833, 6: 0.8927543303244693, 7: 1.3618905842947524}\n\n5. Setting up enhanced callbacks\n\n6. STAGE 1: Training on AffectNet with progressive unfreezing\n\nStage 1: Training only the classification head (10 epochs)\nEpoch 1/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.2895 - loss: 2.3618\nEpoch 1: val_accuracy improved from -inf to 0.24472, saving model to model_checkpoints/affectnet_best.weights.h5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 387ms/step - accuracy: 0.2899 - loss: 2.3605 - val_accuracy: 0.2447 - val_loss: 2.0659 - learning_rate: 0.0010\nEpoch 2/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.5312 - loss: 1.7081\nEpoch 2: val_accuracy improved from 0.24472 to 0.28722, saving model to model_checkpoints/affectnet_best.weights.h5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 295ms/step - accuracy: 0.5314 - loss: 1.7076 - val_accuracy: 0.2872 - val_loss: 1.9443 - learning_rate: 0.0010\nEpoch 3/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.6706 - loss: 1.4011\nEpoch 3: val_accuracy did not improve from 0.28722\n\nConfusion Matrix:\n[[ 66  29 189  47   0   5  76   9]\n [ 20  98 136  46   5   0  76  15]\n [ 34  22 171  47   2   0  45   9]\n [ 21  18 124 152   1   0  84  35]\n [ 19  42 232  29 201  40  44  61]\n [ 46  36 199  27  86 105  64  98]\n [ 39  28 137  54   2   2 127  13]\n [ 17  23 139 154  10   6  70 108]]\nanger: 0.1568  contempt: 0.2475  disgust: 0.5182  fear: 0.3494  \nhappy: 0.3009  neutral: 0.1589  sad: 0.3159  surprise: 0.2049  \n\n\nClass Accuracy Trends:\nanger: [0.0523, 0.1876, 0.1568]\ncontempt: [0.3232, 0.4949, 0.2475]\ndisgust: [0.6091, 0.4576, 0.5182]\nfear: [0.3448, 0.2897, 0.3494]\nhappy: [0.1063, 0.2156, 0.3009]\nneutral: [0.1604, 0.2330, 0.1589]\nsad: [0.1965, 0.1965, 0.3159]\nsurprise: [0.3510, 0.3283, 0.2049]\n\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 300ms/step - accuracy: 0.6708 - loss: 1.4009 - val_accuracy: 0.2649 - val_loss: 2.0840 - learning_rate: 0.0010\nEpoch 4/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.7685 - loss: 1.1883\nEpoch 4: val_accuracy did not improve from 0.28722\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 305ms/step - accuracy: 0.7685 - loss: 1.1881 - val_accuracy: 0.2677 - val_loss: 2.1235 - learning_rate: 0.0010\nEpoch 5/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8199 - loss: 1.0648\nEpoch 5: val_accuracy did not improve from 0.28722\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 273ms/step - accuracy: 0.8200 - loss: 1.0647 - val_accuracy: 0.2792 - val_loss: 2.1576 - learning_rate: 0.0010\nEpoch 6/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8727 - loss: 0.9677\nEpoch 6: val_accuracy did not improve from 0.28722\n\nConfusion Matrix:\n[[ 64  35 148  65   1   3  86  19]\n [ 25 115  96  49   5   0  93  13]\n [ 32  30 133  58   3   1  55  18]\n [ 23  24  79 166   1   1  88  53]\n [ 19  53 181  64 196  71  39  45]\n [ 31  49 166  61  56 151  75  72]\n [ 35  41  92  72   2   1 134  25]\n [ 19  29  95 178  10  11  78 107]]\nanger: 0.1520  contempt: 0.2904  disgust: 0.4030  fear: 0.3816  \nhappy: 0.2934  neutral: 0.2284  sad: 0.3333  surprise: 0.2030  \n\n\nClass Accuracy Trends:\nanger: [0.1876, 0.1568, 0.1188, 0.2090, 0.1520]\ncontempt: [0.4949, 0.2475, 0.3763, 0.3990, 0.2904]\ndisgust: [0.4576, 0.5182, 0.3667, 0.3727, 0.4030]\nfear: [0.2897, 0.3494, 0.4161, 0.2667, 0.3816]\nhappy: [0.2156, 0.3009, 0.2470, 0.1991, 0.2934]\nneutral: [0.2330, 0.1589, 0.1558, 0.2057, 0.2284]\nsad: [0.1965, 0.3159, 0.3134, 0.3930, 0.3333]\nsurprise: [0.3283, 0.2049, 0.2353, 0.2903, 0.2030]\n\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 273ms/step - accuracy: 0.8727 - loss: 0.9676 - val_accuracy: 0.2762 - val_loss: 2.1475 - learning_rate: 0.0010\nEpoch 7/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.8999 - loss: 0.9082\nEpoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 7: val_accuracy did not improve from 0.28722\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 255ms/step - accuracy: 0.8999 - loss: 0.9081 - val_accuracy: 0.2849 - val_loss: 2.1298 - learning_rate: 0.0010\nEpoch 8/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9323 - loss: 0.8317\nEpoch 8: val_accuracy did not improve from 0.28722\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 271ms/step - accuracy: 0.9323 - loss: 0.8317 - val_accuracy: 0.2760 - val_loss: 2.1721 - learning_rate: 5.0000e-04\nEpoch 9/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.9467 - loss: 0.8003\nEpoch 9: val_accuracy did not improve from 0.28722\n\nConfusion Matrix:\n[[104  47 126  44   0   3  74  23]\n [ 40 137  94  33   4   0  63  25]\n [ 62  35 123  41   1   0  44  24]\n [ 38  41  74 135   0   1  67  79]\n [ 50 115 125  45 167  54  34  78]\n [ 68  84 136  38  48 122  43 122]\n [ 62  43 103  44   1   1 108  40]\n [ 40  46  97 116   8   7  40 173]]\nanger: 0.2470  contempt: 0.3460  disgust: 0.3727  fear: 0.3103  \nhappy: 0.2500  neutral: 0.1846  sad: 0.2687  surprise: 0.3283  \n\n\nClass Accuracy Trends:\nanger: [0.2090, 0.1520, 0.1686, 0.1639, 0.2470]\ncontempt: [0.3990, 0.2904, 0.1995, 0.2778, 0.3460]\ndisgust: [0.3727, 0.4030, 0.4303, 0.4697, 0.3727]\nfear: [0.2667, 0.3816, 0.3770, 0.3632, 0.3103]\nhappy: [0.1991, 0.2934, 0.2605, 0.2365, 0.2500]\nneutral: [0.2057, 0.2284, 0.3071, 0.2345, 0.1846]\nsad: [0.3930, 0.3333, 0.2736, 0.1915, 0.2687]\nsurprise: [0.2903, 0.2030, 0.2998, 0.3435, 0.3283]\n\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 289ms/step - accuracy: 0.9467 - loss: 0.8002 - val_accuracy: 0.2771 - val_loss: 2.1753 - learning_rate: 5.0000e-04\nEpoch 10/10\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.9539 - loss: 0.7800\nEpoch 10: val_accuracy did not improve from 0.28722\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 247ms/step - accuracy: 0.9540 - loss: 0.7800 - val_accuracy: 0.2845 - val_loss: 2.1626 - learning_rate: 5.0000e-04\nRestoring model weights from the end of the best epoch: 2.\n\nStage 2: Fine-tuning with progressive unfreezing (15 epochs)\n\nUnfreezing group 1/3 (15 layers)\nEpoch 1/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.5421 - loss: 1.6998\nEpoch 1: val_accuracy did not improve from 0.28722\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 312ms/step - accuracy: 0.5426 - loss: 1.6987 - val_accuracy: 0.2001 - val_loss: 2.7701 - learning_rate: 1.0000e-04\nEpoch 2/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.8068 - loss: 1.1160\nEpoch 2: val_accuracy did not improve from 0.28722\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 295ms/step - accuracy: 0.8070 - loss: 1.1156 - val_accuracy: 0.2236 - val_loss: 2.7359 - learning_rate: 1.0000e-04\nEpoch 3/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.9058 - loss: 0.9114\nEpoch 3: val_accuracy did not improve from 0.28722\n\nConfusion Matrix:\n[[ 75  43 146  80   0   0  65  12]\n [ 29 156  92  42   1   0  60  16]\n [ 26  27 158  67   1   0  44   7]\n [ 18  36  69 207   0   0  68  37]\n [ 36  99 226 107  72  22  74  32]\n [ 45  72 170 138  11  43 123  59]\n [ 45  47 105  76   0   0 107  22]\n [ 18  44  89 201   2   1  57 115]]\nanger: 0.1781  contempt: 0.3939  disgust: 0.4788  fear: 0.4759  \nhappy: 0.1078  neutral: 0.0651  sad: 0.2662  surprise: 0.2182  \n\n\nClass Accuracy Trends:\nanger: [0.2470, 0.1781, 0.0618, 0.1021, 0.1781]\ncontempt: [0.3460, 0.3737, 0.2828, 0.4192, 0.3939]\ndisgust: [0.3727, 0.3788, 0.6515, 0.5636, 0.4788]\nfear: [0.3103, 0.3402, 0.2713, 0.3080, 0.4759]\nhappy: [0.2500, 0.2305, 0.0060, 0.0389, 0.1078]\nneutral: [0.1846, 0.2693, 0.0061, 0.0151, 0.0651]\nsad: [0.2687, 0.3333, 0.1592, 0.1318, 0.2662]\nsurprise: [0.3283, 0.2562, 0.4440, 0.4687, 0.2182]\n\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 303ms/step - accuracy: 0.9059 - loss: 0.9112 - val_accuracy: 0.2408 - val_loss: 2.5535 - learning_rate: 1.0000e-04\nEpoch 4/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.9509 - loss: 0.8053\nEpoch 4: val_accuracy did not improve from 0.28722\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 295ms/step - accuracy: 0.9510 - loss: 0.8052 - val_accuracy: 0.2403 - val_loss: 2.5554 - learning_rate: 1.0000e-04\nEpoch 5/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9766 - loss: 0.7492\nEpoch 5: val_accuracy did not improve from 0.28722\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 284ms/step - accuracy: 0.9766 - loss: 0.7492 - val_accuracy: 0.2725 - val_loss: 2.3786 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n\nUnfreezing group 2/3 (15 layers)\nEpoch 1/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.5678 - loss: 1.6635\nEpoch 1: val_accuracy did not improve from 0.28722\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 324ms/step - accuracy: 0.5682 - loss: 1.6625 - val_accuracy: 0.2261 - val_loss: 2.6047 - learning_rate: 5.0000e-05\nEpoch 2/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.7864 - loss: 1.1408\nEpoch 2: val_accuracy did not improve from 0.28722\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 295ms/step - accuracy: 0.7866 - loss: 1.1405 - val_accuracy: 0.2433 - val_loss: 2.4385 - learning_rate: 5.0000e-05\nEpoch 3/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.8911 - loss: 0.9392\nEpoch 3: val_accuracy did not improve from 0.28722\n\nConfusion Matrix:\n[[ 59  61 172  51   0   0  37  41]\n [  7 195  91  35   1   1  26  40]\n [ 11  35 181  52   1   0  24  26]\n [  7  35  80 171   0   0  38 104]\n [ 17 112 237  47  62  22  30 141]\n [ 21  98 169  77   9  54  67 166]\n [ 23  61 123  62   1   0  74  58]\n [  4  44  99 146   0   1  20 213]]\nanger: 0.1401  contempt: 0.4924  disgust: 0.5485  fear: 0.3931  \nhappy: 0.0928  neutral: 0.0817  sad: 0.1841  surprise: 0.4042  \n\n\nClass Accuracy Trends:\nanger: [0.2589, 0.2162, 0.0594, 0.0760, 0.1401]\ncontempt: [0.3409, 0.5000, 0.3864, 0.4293, 0.4924]\ndisgust: [0.4030, 0.3727, 0.5970, 0.5848, 0.5485]\nfear: [0.4598, 0.5149, 0.3149, 0.3839, 0.3931]\nhappy: [0.1213, 0.1587, 0.0389, 0.0763, 0.0928]\nneutral: [0.0756, 0.1710, 0.0287, 0.0711, 0.0817]\nsad: [0.3408, 0.2861, 0.1866, 0.1990, 0.1841]\nsurprise: [0.1518, 0.1233, 0.4573, 0.3586, 0.4042]\n\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 298ms/step - accuracy: 0.8912 - loss: 0.9390 - val_accuracy: 0.2642 - val_loss: 2.3925 - learning_rate: 5.0000e-05\nEpoch 4/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.9475 - loss: 0.8212\nEpoch 4: val_accuracy did not improve from 0.28722\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 292ms/step - accuracy: 0.9475 - loss: 0.8211 - val_accuracy: 0.2847 - val_loss: 2.3353 - learning_rate: 5.0000e-05\nEpoch 5/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.9692 - loss: 0.7650\nEpoch 5: val_accuracy improved from 0.28722 to 0.30722, saving model to model_checkpoints/affectnet_best.weights.h5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 289ms/step - accuracy: 0.9692 - loss: 0.7650 - val_accuracy: 0.3072 - val_loss: 2.2741 - learning_rate: 5.0000e-05\nRestoring model weights from the end of the best epoch: 5.\n\nUnfreezing group 3/3 (20 layers)\nEpoch 1/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.8199 - loss: 1.0909\nEpoch 1: val_accuracy improved from 0.30722 to 0.32881, saving model to model_checkpoints/affectnet_best.weights.h5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 324ms/step - accuracy: 0.8202 - loss: 1.0903 - val_accuracy: 0.3288 - val_loss: 2.1933 - learning_rate: 3.3333e-05\nEpoch 2/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.9520 - loss: 0.8013\nEpoch 2: val_accuracy improved from 0.32881 to 0.36604, saving model to model_checkpoints/affectnet_best.weights.h5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 300ms/step - accuracy: 0.9521 - loss: 0.8012 - val_accuracy: 0.3660 - val_loss: 2.0646 - learning_rate: 3.3333e-05\nEpoch 3/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.9803 - loss: 0.7328\nEpoch 3: val_accuracy did not improve from 0.36604\n\nConfusion Matrix:\n[[132  75 110  29   0   1  66   8]\n [ 25 209  86  19   1   2  42  12]\n [ 47  37 162  26   2   0  50   6]\n [ 31  36  87 136   0   0  97  48]\n [ 21  85 143  24 272  46  41  36]\n [ 61  80 114  36  35 176 101  58]\n [ 47  64  92  30   0   0 160   9]\n [ 31  51  95 114   4   7  85 140]]\nanger: 0.3135  contempt: 0.5278  disgust: 0.4909  fear: 0.3126  \nhappy: 0.4072  neutral: 0.2663  sad: 0.3980  surprise: 0.2657  \n\n\nClass Accuracy Trends:\nanger: [0.1164, 0.1401, 0.2019, 0.2613, 0.3135]\ncontempt: [0.4924, 0.4848, 0.4167, 0.5025, 0.5278]\ndisgust: [0.5121, 0.4879, 0.5848, 0.5242, 0.4909]\nfear: [0.4069, 0.4115, 0.3770, 0.3356, 0.3126]\nhappy: [0.1362, 0.2320, 0.3518, 0.4386, 0.4072]\nneutral: [0.1422, 0.1634, 0.2269, 0.2799, 0.2663]\nsad: [0.1791, 0.1766, 0.3159, 0.3582, 0.3980]\nsurprise: [0.4592, 0.4858, 0.2789, 0.3093, 0.2657]\n\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 298ms/step - accuracy: 0.9803 - loss: 0.7328 - val_accuracy: 0.3582 - val_loss: 2.0682 - learning_rate: 3.3333e-05\nEpoch 4/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.9883 - loss: 0.7122\nEpoch 4: val_accuracy improved from 0.36604 to 0.38051, saving model to model_checkpoints/affectnet_best.weights.h5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 315ms/step - accuracy: 0.9883 - loss: 0.7121 - val_accuracy: 0.3805 - val_loss: 2.0011 - learning_rate: 3.3333e-05\nEpoch 5/5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9924 - loss: 0.6904\nEpoch 5: val_accuracy improved from 0.38051 to 0.40533, saving model to model_checkpoints/affectnet_best.weights.h5\n\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 266ms/step - accuracy: 0.9924 - loss: 0.6904 - val_accuracy: 0.4053 - val_loss: 1.9071 - learning_rate: 3.3333e-05\nRestoring model weights from the end of the best epoch: 5.\nAffectNet model saved to 'affectnet_model.keras'\n\nEvaluating model on AffectNet test set\nAffectNet Test Accuracy: 0.4669\nAffectNet Weighted F1-Score: 0.4799\n\nAffectNet Classification Report:\n              precision    recall  f1-score   support\n\n       anger       0.42      0.36      0.39      3104\n    contempt       0.34      0.64      0.45      2871\n     disgust       0.29      0.61      0.39      2477\n        fear       0.46      0.43      0.44      3176\n       happy       0.86      0.53      0.65      5044\n     neutral       0.80      0.39      0.52      5126\n         sad       0.37      0.46      0.41      3091\n    surprise       0.49      0.40      0.44      4039\n\n    accuracy                           0.47     28928\n   macro avg       0.50      0.48      0.46     28928\nweighted avg       0.55      0.47      0.48     28928\n\n\n7. STAGE 2: Fine-tuning on FER2013 with progressive unfreezing\n\nStage 1: Training only the classification head (8 epochs)\nEpoch 1/8\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.3453 - loss: 8.9823\nEpoch 1: val_accuracy improved from -inf to 0.15814, saving model to model_checkpoints/fer2013_best.weights.h5\n\n⚠️ WARNING: Zero predictions for classes: happy, neutral\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 346ms/step - accuracy: 0.3455 - loss: 8.9716 - val_accuracy: 0.1581 - val_loss: 2.5400 - learning_rate: 0.0010\nEpoch 2/8\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 0.4528 - loss: 5.7054\nEpoch 2: val_accuracy did not improve from 0.15814\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 280ms/step - accuracy: 0.4528 - loss: 5.7048 - val_accuracy: 0.1527 - val_loss: 2.2616 - learning_rate: 0.0010\nEpoch 3/8\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.5181 - loss: 5.4609\nEpoch 3: val_accuracy improved from 0.15814 to 0.20620, saving model to model_checkpoints/fer2013_best.weights.h5\n\nConfusion Matrix:\n[[ 38  10 225  47   0   0 157  72]\n [  0   6   0   0   0   0   0   0]\n [  1   2  52   1   0   0   4   0]\n [ 21   9 153  73   0   1 146 153]\n [ 27  41 402  53  26   2 222 173]\n [ 12  25 217  38   2   6 225 127]\n [ 14  15 250  41   1   1 276  47]\n [  1   4  46  21   0   0  35 319]]\nanger: 0.0692  contempt: 1.0000  disgust: 0.8667  fear: 0.1313  \nhappy: 0.0275  neutral: 0.0092  sad: 0.4279  surprise: 0.7488  \n\n\nClass Accuracy Trends:\nanger: [0.0273, 0.0383, 0.0692]\ncontempt: [1.0000, 1.0000, 1.0000]\ndisgust: [0.8833, 0.9500, 0.8667]\nfear: [0.0863, 0.0773, 0.1313]\nhappy: [0.0000, 0.0106, 0.0275]\nneutral: [0.0000, 0.0015, 0.0092]\nsad: [0.3597, 0.2977, 0.4279]\nsurprise: [0.6080, 0.6197, 0.7488]\n\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 287ms/step - accuracy: 0.5181 - loss: 5.4605 - val_accuracy: 0.2062 - val_loss: 2.0580 - learning_rate: 0.0010\nEpoch 4/8\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.5728 - loss: 5.2390\nEpoch 4: val_accuracy improved from 0.20620 to 0.23509, saving model to model_checkpoints/fer2013_best.weights.h5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 294ms/step - accuracy: 0.5729 - loss: 5.2389 - val_accuracy: 0.2351 - val_loss: 2.0086 - learning_rate: 0.0010\nEpoch 5/8\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.6283 - loss: 5.1332\nEpoch 5: val_accuracy improved from 0.23509 to 0.24148, saving model to model_checkpoints/fer2013_best.weights.h5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 247ms/step - accuracy: 0.6283 - loss: 5.1331 - val_accuracy: 0.2415 - val_loss: 2.0374 - learning_rate: 0.0010\nEpoch 6/8\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.6821 - loss: 5.0426\nEpoch 6: val_accuracy improved from 0.24148 to 0.25687, saving model to model_checkpoints/fer2013_best.weights.h5\n\nConfusion Matrix:\n[[173   0 115  84   1   7 127  42]\n [  1   4   0   0   0   0   0   1]\n [ 12   0  39   4   0   0   5   0]\n [ 94   2  81 145   0  11 107 116]\n [142   6 257 178  50  24 162 127]\n [ 93   2 153  87   4  49 168  96]\n [ 85   3 134 127   1  15 247  33]\n [ 23   2  27  46   0   3  40 285]]\nanger: 0.3151  contempt: 0.6667  disgust: 0.6500  fear: 0.2608  \nhappy: 0.0529  neutral: 0.0752  sad: 0.3829  surprise: 0.6690  \n\n\nClass Accuracy Trends:\nanger: [0.0383, 0.0692, 0.1257, 0.2131, 0.3151]\ncontempt: [1.0000, 1.0000, 1.0000, 1.0000, 0.6667]\ndisgust: [0.9500, 0.8667, 0.8333, 0.7667, 0.6500]\nfear: [0.0773, 0.1313, 0.1871, 0.1817, 0.2608]\nhappy: [0.0106, 0.0275, 0.0423, 0.0465, 0.0529]\nneutral: [0.0015, 0.0092, 0.0184, 0.0521, 0.0752]\nsad: [0.2977, 0.4279, 0.4899, 0.4357, 0.3829]\nsurprise: [0.6197, 0.7488, 0.7277, 0.7254, 0.6690]\n\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 271ms/step - accuracy: 0.6822 - loss: 5.0423 - val_accuracy: 0.2569 - val_loss: 2.0585 - learning_rate: 0.0010\nEpoch 7/8\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.7286 - loss: 4.9966\nEpoch 7: val_accuracy improved from 0.25687 to 0.25710, saving model to model_checkpoints/fer2013_best.weights.h5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 260ms/step - accuracy: 0.7286 - loss: 4.9963 - val_accuracy: 0.2571 - val_loss: 2.0982 - learning_rate: 0.0010\nEpoch 8/8\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.7712 - loss: 4.8955\nEpoch 8: val_accuracy improved from 0.25710 to 0.25971, saving model to model_checkpoints/fer2013_best.weights.h5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 260ms/step - accuracy: 0.7712 - loss: 4.8954 - val_accuracy: 0.2597 - val_loss: 2.1916 - learning_rate: 0.0010\nRestoring model weights from the end of the best epoch: 1.\n\nStage 2: Fine-tuning with progressive unfreezing (12 epochs)\n\nUnfreezing group 1/3 (15 layers)\nEpoch 1/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.4545 - loss: 5.7975\nEpoch 1: val_accuracy did not improve from 0.25971\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 303ms/step - accuracy: 0.4547 - loss: 5.7964 - val_accuracy: 0.2509 - val_loss: 2.1385 - learning_rate: 1.0000e-04\nEpoch 2/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.6078 - loss: 5.2267\nEpoch 2: val_accuracy did not improve from 0.25971\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 283ms/step - accuracy: 0.6080 - loss: 5.2263 - val_accuracy: 0.2595 - val_loss: 2.2773 - learning_rate: 1.0000e-04\nEpoch 3/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.7257 - loss: 5.0480\nEpoch 3: val_accuracy did not improve from 0.25971\n\nConfusion Matrix:\n[[ 75   0  20 150   0   1 301   2]\n [  0   1   0   0   0   0   5   0]\n [  4   0  18  17   0   0  21   0]\n [ 33   0   8 250   0   0 251  14]\n [ 55   0  40 331  30   0 481   9]\n [ 28   0   6 153   0   0 461   4]\n [ 21   0   8 163   0   0 452   1]\n [  6   0   4 219   0   0 102  95]]\nanger: 0.1366  contempt: 0.1667  disgust: 0.3000  fear: 0.4496  \nhappy: 0.0317  neutral: 0.0000  sad: 0.7008  surprise: 0.2230  \n\n\nClass Accuracy Trends:\nanger: [0.3424, 0.3588, 0.2350, 0.1803, 0.1366]\ncontempt: [0.6667, 0.8333, 1.0000, 0.5000, 0.1667]\ndisgust: [0.6000, 0.5500, 0.8333, 0.5667, 0.3000]\nfear: [0.1906, 0.2608, 0.2752, 0.4604, 0.4496]\nhappy: [0.0624, 0.0761, 0.0825, 0.0560, 0.0317]\nneutral: [0.1196, 0.1135, 0.0015, 0.0015, 0.0000]\nsad: [0.4171, 0.3256, 0.4326, 0.6031, 0.7008]\nsurprise: [0.6127, 0.6455, 0.6315, 0.3709, 0.2230]\n\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 289ms/step - accuracy: 0.7258 - loss: 5.0475 - val_accuracy: 0.2398 - val_loss: 2.6763 - learning_rate: 1.0000e-04\nEpoch 4/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.8261 - loss: 4.8049\nEpoch 4: val_accuracy did not improve from 0.25971\n\n⚠️ WARNING: Zero predictions for classes: contempt\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 292ms/step - accuracy: 0.8262 - loss: 4.8049 - val_accuracy: 0.2377 - val_loss: 2.8982 - learning_rate: 1.0000e-04\nEpoch 5/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.8939 - loss: 4.7064\nEpoch 5: val_accuracy did not improve from 0.25971\n\n⚠️ WARNING: Zero predictions for classes: contempt\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 270ms/step - accuracy: 0.8940 - loss: 4.7063 - val_accuracy: 0.2370 - val_loss: 3.1323 - learning_rate: 1.0000e-04\nRestoring model weights from the end of the best epoch: 1.\n\nUnfreezing group 2/3 (15 layers)\nEpoch 1/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.5433 - loss: 5.4578\nEpoch 1: val_accuracy improved from 0.25971 to 0.28314, saving model to model_checkpoints/fer2013_best.weights.h5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 314ms/step - accuracy: 0.5434 - loss: 5.4571 - val_accuracy: 0.2831 - val_loss: 2.1094 - learning_rate: 5.0000e-05\nEpoch 2/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.6752 - loss: 5.0873\nEpoch 2: val_accuracy improved from 0.28314 to 0.28741, saving model to model_checkpoints/fer2013_best.weights.h5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 287ms/step - accuracy: 0.6754 - loss: 5.0871 - val_accuracy: 0.2874 - val_loss: 2.1679 - learning_rate: 5.0000e-05\nEpoch 3/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.7699 - loss: 4.9576\nEpoch 3: val_accuracy did not improve from 0.28741\n\nConfusion Matrix:\n[[159   0  35  63   0   1 286   5]\n [  0   5   0   0   0   0   1   0]\n [  7   0  29   2   0   0  22   0]\n [ 75   0  14 182   0   0 254  31]\n [141   2  87 158  34   0 494  30]\n [ 77   0  13  79   0   7 467   9]\n [ 52   0  26  93   0   0 472   2]\n [ 24   1  12 131   0   1  98 159]]\nanger: 0.2896  contempt: 0.8333  disgust: 0.4833  fear: 0.3273  \nhappy: 0.0359  neutral: 0.0107  sad: 0.7318  surprise: 0.3732  \n\n\nClass Accuracy Trends:\nanger: [0.1184, 0.0947, 0.2386, 0.2441, 0.2896]\ncontempt: [0.0000, 0.0000, 1.0000, 1.0000, 0.8333]\ndisgust: [0.2667, 0.2000, 0.8000, 0.7167, 0.4833]\nfear: [0.5504, 0.4658, 0.3022, 0.2842, 0.3273]\nhappy: [0.0497, 0.0560, 0.0951, 0.0899, 0.0359]\nneutral: [0.0092, 0.0215, 0.0123, 0.0245, 0.0107]\nsad: [0.6357, 0.7116, 0.5736, 0.6806, 0.7318]\nsurprise: [0.1502, 0.1432, 0.5986, 0.4883, 0.3732]\n\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 292ms/step - accuracy: 0.7701 - loss: 4.9573 - val_accuracy: 0.2727 - val_loss: 2.3909 - learning_rate: 5.0000e-05\nEpoch 4/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.8490 - loss: 4.7150\nEpoch 4: val_accuracy did not improve from 0.28741\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 286ms/step - accuracy: 0.8490 - loss: 4.7152 - val_accuracy: 0.2607 - val_loss: 2.5518 - learning_rate: 5.0000e-05\nEpoch 5/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.9069 - loss: 4.7175\nEpoch 5: val_accuracy did not improve from 0.28741\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 278ms/step - accuracy: 0.9069 - loss: 4.7173 - val_accuracy: 0.2687 - val_loss: 2.4171 - learning_rate: 5.0000e-05\nRestoring model weights from the end of the best epoch: 1.\n\nUnfreezing group 3/3 (20 layers)\nEpoch 1/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.6144 - loss: 5.2190\nEpoch 1: val_accuracy did not improve from 0.28741\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 313ms/step - accuracy: 0.6146 - loss: 5.2186 - val_accuracy: 0.2848 - val_loss: 2.1588 - learning_rate: 3.3333e-05\nEpoch 2/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.7145 - loss: 5.0507\nEpoch 2: val_accuracy did not improve from 0.28741\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 289ms/step - accuracy: 0.7147 - loss: 5.0503 - val_accuracy: 0.2839 - val_loss: 2.2140 - learning_rate: 3.3333e-05\nEpoch 3/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.8017 - loss: 4.8816\nEpoch 3: val_accuracy did not improve from 0.28741\n\nConfusion Matrix:\n[[152   0  65  72   0   0 237  23]\n [  0   2   0   0   0   0   3   1]\n [  7   0  34   9   0   0  10   0]\n [ 67   0  41 175   0   0 206  67]\n [120   0 161 199  64   0 334  68]\n [ 62   0  32 103   0   4 421  30]\n [ 48   0  58 109   0   0 414  16]\n [ 14   0  12  89   0   1  59 251]]\nanger: 0.2769  contempt: 0.3333  disgust: 0.5667  fear: 0.3147  \nhappy: 0.0677  neutral: 0.0061  sad: 0.6419  surprise: 0.5892  \n\n\nClass Accuracy Trends:\nanger: [0.2714, 0.2805, 0.2896, 0.2914, 0.2769]\ncontempt: [0.8333, 0.8333, 0.6667, 0.3333, 0.3333]\ndisgust: [0.4333, 0.5333, 0.7500, 0.7167, 0.5667]\nfear: [0.3813, 0.4496, 0.2356, 0.2842, 0.3147]\nhappy: [0.0254, 0.0476, 0.0677, 0.0507, 0.0677]\nneutral: [0.0107, 0.0199, 0.0092, 0.0061, 0.0061]\nsad: [0.7163, 0.6295, 0.5922, 0.5907, 0.6419]\nsurprise: [0.2700, 0.2934, 0.7019, 0.6667, 0.5892]\n\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 292ms/step - accuracy: 0.8018 - loss: 4.8815 - val_accuracy: 0.2867 - val_loss: 2.2607 - learning_rate: 3.3333e-05\nEpoch 4/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.8660 - loss: 4.7240\nEpoch 4: val_accuracy did not improve from 0.28741\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 284ms/step - accuracy: 0.8660 - loss: 4.7241 - val_accuracy: 0.2857 - val_loss: 2.3237 - learning_rate: 3.3333e-05\nEpoch 5/5\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9146 - loss: 4.7006\nEpoch 5: val_accuracy did not improve from 0.28741\n\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 264ms/step - accuracy: 0.9147 - loss: 4.7004 - val_accuracy: 0.2829 - val_loss: 2.2771 - learning_rate: 3.3333e-05\nRestoring model weights from the end of the best epoch: 1.\n\nEvaluating model on FER2013 test set\nFER2013 Test Accuracy: 0.2953\nFER2013 Weighted F1-Score: 0.2474\n\nFER2013 Classification Report:\n              precision    recall  f1-score   support\n\n       anger       0.28      0.31      0.29       894\n    contempt       0.72      0.70      0.71        54\n     disgust       0.07      0.72      0.13       111\n        fear       0.27      0.25      0.26      1024\n       happy       0.98      0.06      0.12      1774\n     neutral       0.73      0.01      0.01      1233\n         sad       0.28      0.61      0.38      1247\n    surprise       0.51      0.70      0.59       831\n\n    accuracy                           0.30      7168\n   macro avg       0.48      0.42      0.31      7168\nweighted avg       0.56      0.30      0.25      7168\n\n\nEvaluating model on Combined test set\nCombined Test Accuracy: 0.3050\nCombined Weighted F1-Score: 0.2910\n\nCombined Classification Report:\n              precision    recall  f1-score   support\n\n       anger       0.27      0.41      0.33      4126\n    contempt       0.72      0.01      0.03      2925\n     disgust       0.22      0.37      0.28      2588\n        fear       0.26      0.26      0.26      4200\n       happy       0.88      0.24      0.38      6818\n     neutral       0.59      0.12      0.20      6359\n         sad       0.19      0.52      0.28      4338\n    surprise       0.41      0.54      0.46      4870\n\n    accuracy                           0.30     36224\n   macro avg       0.44      0.31      0.28     36224\nweighted avg       0.48      0.30      0.29     36224\n\nFinal model saved to 'final_enhanced_emotion_model.keras'\n\n=== FINAL RESULTS ===\nAffectNet Test Accuracy: 0.4669\nAffectNet F1 Score: 0.4799\nFER2013 Test Accuracy: 0.2953\nFER2013 F1 Score: 0.2474\nCombined Test Accuracy: 0.3050\nCombined F1 Score: 0.2910\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#Version 6v accuracy 0.2294\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom tensorflow.keras.applications import MobileNetV2\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\n\n# =============================================================================\n# Configure GPU and enable mixed precision\n# =============================================================================\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(f\"Found {len(gpus)} GPUs: Memory growth enabled\")\n    except RuntimeError as e:\n        print(f\"GPU error: {e}\")\n\n# Enable mixed precision training\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\nprint(\"Mixed precision enabled\")\n\n# =============================================================================\n# Key parameters\n# =============================================================================\nIMG_SIZE = 96  # Keep at 96x96 as specified\nBATCH_SIZE = 128\nAUTOTUNE = tf.data.AUTOTUNE\nLOG_DIR = \"./emotion_logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\n# Create all required directories\ndef ensure_dir(directory):\n    \"\"\"Make sure a directory exists, creating it if necessary\"\"\"\n    if not os.path.exists(directory):\n        os.makedirs(directory, exist_ok=True)\n\n# Create main log directories\nensure_dir(LOG_DIR)\nensure_dir(LOG_DIR + '/affectnet')\nensure_dir(LOG_DIR + '/fer2013')\nensure_dir(LOG_DIR + '/combined')\nensure_dir(\"./model_checkpoints\")\n\n# Define problematic classes for targeted augmentation\nPROBLEMATIC_CLASSES = ['surprise', 'sad', 'disgust']\n\n# =============================================================================\n# Custom Label Smoothing Loss\n# =============================================================================\ndef label_smoothing_loss(epsilon=0.1):\n    \"\"\"\n    Cross entropy loss with label smoothing to prevent model from being too confident.\n    \n    Args:\n        epsilon: Smoothing factor (0 = no smoothing, 1 = complete smoothing)\n        \n    Returns:\n        Loss function\n    \"\"\"\n    def loss_fn(y_true, y_pred):\n        num_classes = tf.cast(tf.shape(y_true)[-1], tf.float32)\n        \n        # Apply label smoothing\n        y_true = y_true * (1.0 - epsilon) + (epsilon / num_classes)\n        \n        # Calculate cross entropy with extra small epsilon to prevent log(0)\n        return -tf.reduce_sum(y_true * tf.math.log(y_pred + 1e-7), axis=-1)\n    \n    return loss_fn\n\n# =============================================================================\n# Build DataFrame from dataset directory structure\n# =============================================================================\ndef build_image_df(root_dir, subfolders=[\"fer2013\", \"affectnet\"]):\n    \"\"\"\n    Scans the directory and returns a DataFrame with file paths and labels.\n    \"\"\"\n    data = []\n    emotions = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n    \n    print(f\"Found {len(emotions)} emotion categories: {emotions}\")\n    \n    for emotion in emotions:\n        emotion_path = os.path.join(root_dir, emotion)\n        for sub in subfolders:\n            sub_path = os.path.join(emotion_path, sub)\n            if os.path.exists(sub_path):\n                img_files = [f for f in os.listdir(sub_path) \n                            if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n                \n                print(f\"Found {len(img_files)} images in {emotion}/{sub}\")\n                \n                for img_file in img_files:\n                    data.append({\n                        \"filepath\": os.path.join(sub_path, img_file),\n                        \"label\": emotion,\n                        \"source\": sub\n                    })\n    \n    df = pd.DataFrame(data)\n    print(f\"Total images: {len(df)}\")\n    return df\n\n# =============================================================================\n# Fixed graph-compatible preprocessing function with stronger augmentation\n# =============================================================================\ndef preprocess_image(file_path, label, source, training=True):\n    \"\"\"\n    Fixed graph-compatible preprocessing with stronger augmentation.\n    \n    Args:\n        file_path: Path to the image file\n        label: Emotion label (as index)\n        source: Dataset source ('fer2013' or 'affectnet')\n        training: Whether to apply augmentation\n        \n    Returns:\n        Preprocessed image and one-hot encoded label\n    \"\"\"\n    # Read the file\n    img = tf.io.read_file(file_path)\n    \n    # Decode image with proper error handling\n    def decode_image():\n        try:\n            decoded = tf.image.decode_image(img, channels=3, expand_animations=False)\n            decoded = tf.ensure_shape(decoded, [None, None, 3])\n            return decoded\n        except:\n            # Return blank image if decoding fails\n            return tf.zeros([IMG_SIZE, IMG_SIZE, 3], dtype=tf.uint8)\n    \n    img = decode_image()\n    \n    # Resize to target size\n    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE], method='bilinear')\n    \n    # Normalize pixel values using MobileNet standard preprocessing\n    img = tf.cast(img, tf.float32)\n    img = img / 127.5 - 1.0  # Scale to [-1, 1]\n    \n    # Apply enhanced augmentation during training\n    if training:\n        # Random flip - works in graph mode\n        img = tf.image.random_flip_left_right(img)\n        \n        # Enhanced brightness and contrast (stronger than before)\n        img = tf.image.random_brightness(img, 0.3)  # Increased from 0.2\n        img = tf.image.random_contrast(img, 0.7, 1.3)  # Increased range\n        \n        # Add saturation variation\n        img = tf.image.random_saturation(img, 0.8, 1.5)\n        \n        # Apply random crop and resize for shape variation\n        # This simulates zoom/scale augmentation\n        crop_size = tf.random.uniform([], 0.8, 1.0, dtype=tf.float32)\n        scaled_size = tf.cast(tf.cast(tf.shape(img)[:2], tf.float32) * crop_size, tf.int32)\n        img = tf.image.random_crop(img, [scaled_size[0], scaled_size[1], 3])\n        img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n            \n        # Add random noise to improve robustness\n        noise = tf.random.normal(shape=tf.shape(img), mean=0.0, stddev=0.02)  # Increased noise\n        img = img + noise\n        \n        # Ensure values stay in valid range\n        img = tf.clip_by_value(img, -1.0, 1.0)\n    \n    # One-hot encode label\n    label = tf.one_hot(label, depth=8)  # 8 emotion classes\n    \n    return img, label\n\n# =============================================================================\n# Fixed dataset creation function\n# =============================================================================\ndef create_dataset(dataframe, is_training=True, dataset_type=None):\n    \"\"\"\n    Creates a tf.data.Dataset with fixed preprocessing.\n    \n    Args:\n        dataframe: DataFrame with filepath, label, and source columns\n        is_training: Whether this is for training (includes augmentation)\n        dataset_type: Optional filter for specific dataset ('affectnet' or 'fer2013')\n        \n    Returns:\n        tf.data.Dataset and class mapping\n    \"\"\"\n    # Optionally filter to specific dataset\n    if dataset_type is not None:\n        dataframe = dataframe[dataframe['source'] == dataset_type].reset_index(drop=True)\n        print(f\"Filtered to {len(dataframe)} {dataset_type} images\")\n    \n    # Create class indices\n    class_indices = {cls: i for i, cls in enumerate(sorted(dataframe[\"label\"].unique()))}\n    labels = [class_indices[label] for label in dataframe[\"label\"]]\n    \n    # Create dataset\n    ds = tf.data.Dataset.from_tensor_slices((\n        dataframe[\"filepath\"].values,\n        labels,\n        dataframe[\"source\"].values\n    ))\n    \n    # Apply preprocessing with training flag\n    training_value = tf.constant(is_training)\n    ds = ds.map(\n        lambda path, label, source: preprocess_image(path, label, source, training=training_value),\n        num_parallel_calls=AUTOTUNE\n    )\n    \n    if is_training:\n        # Training pipeline\n        ds = ds.shuffle(buffer_size=min(10000, len(dataframe)))\n        \n    # Repeat dataset for multiple epochs\n    ds = ds.repeat()\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(AUTOTUNE)\n    \n    return ds, class_indices\n\n# =============================================================================\n# Create balanced dataset with emphasis classes\n# =============================================================================\ndef create_emphasis_dataset(dataframe, is_training=True, emphasis_classes=PROBLEMATIC_CLASSES):\n    \"\"\"\n    Creates a balanced dataset with emphasis on problematic classes.\n    \n    Args:\n        dataframe: Input DataFrame\n        is_training: Whether to apply training augmentations\n        emphasis_classes: List of classes to emphasize (oversample)\n        \n    Returns:\n        Balanced tf.data.Dataset with emphasis on specified classes\n    \"\"\"\n    balanced_data = []\n    \n    # Sample from each class with emphasis on problematic ones\n    for class_name in sorted(dataframe[\"label\"].unique()):\n        class_df = dataframe[dataframe[\"label\"] == class_name]\n        samples_per_class = 400  # Base sampling\n        \n        # Increase samples for emphasis classes\n        if class_name in emphasis_classes:\n            samples_per_class = 600  # 50% more samples for problematic classes\n            \n        # Sample with replacement if needed\n        if len(class_df) <= samples_per_class:\n            sampled = class_df.sample(n=samples_per_class, replace=True)\n        else:\n            sampled = class_df.sample(n=samples_per_class, replace=False)\n            \n        balanced_data.append(sampled)\n    \n    # Combine all balanced samples\n    balanced_df = pd.concat(balanced_data, ignore_index=True)\n    print(f\"Created balanced dataset with {len(balanced_df)} samples (with emphasis on {emphasis_classes})\")\n    \n    # Create dataset\n    return create_dataset(balanced_df, is_training=is_training)\n\n# =============================================================================\n# Fixed Confusion Matrix Callback without plotting errors\n# =============================================================================\nclass EnhancedConfusionMatrixCallback(tf.keras.callbacks.Callback):\n    \"\"\"\n    Enhanced callback to monitor class-specific metrics during training.\n    \"\"\"\n    def __init__(self, validation_data, class_names, log_dir, model_name=\"model\", freq=5):\n        super(EnhancedConfusionMatrixCallback, self).__init__()\n        self.validation_data = validation_data\n        self.class_names = class_names\n        self.freq = freq\n        self.log_dir = log_dir\n        self.model_name = model_name\n        self.zero_prediction_classes = set()  # Track classes with zero predictions\n        self.class_metrics_history = {cls: [] for cls in class_names}  # Track per-class metrics\n        \n        # Ensure log directory exists\n        ensure_dir(self.log_dir)\n        \n    def on_epoch_end(self, epoch, logs=None):\n        # Calculate and log class-specific metrics every epoch\n        val_steps = 30  # Limit computation\n        y_true = []\n        y_pred = []\n        \n        # Get predictions for validation data\n        for i, (images, labels) in enumerate(self.validation_data):\n            if i >= val_steps:\n                break\n            batch_preds = self.model.predict(images, verbose=0)\n            y_pred.append(np.argmax(batch_preds, axis=1))\n            y_true.append(np.argmax(labels.numpy(), axis=1))\n        \n        # Flatten the lists\n        y_true = np.concatenate(y_true)\n        y_pred = np.concatenate(y_pred)\n        \n        # Calculate confusion matrix\n        cm = confusion_matrix(y_true, y_pred)\n        \n        # Calculate per-class metrics\n        class_accuracies = np.zeros(len(self.class_names))\n        for i in range(len(self.class_names)):\n            if np.sum(y_true == i) > 0:  # Avoid division by zero\n                class_accuracies[i] = cm[i, i] / np.sum(y_true == i)\n                \n            # Track metrics history\n            self.class_metrics_history[self.class_names[i]].append(class_accuracies[i])\n        \n        # Check for classes with zero predictions\n        zero_pred_classes = []\n        for i, class_name in enumerate(self.class_names):\n            if np.sum(cm[:, i]) == 0:\n                zero_pred_classes.append(class_name)\n                self.zero_prediction_classes.add(class_name)\n        \n        # Log warnings for zero prediction classes\n        if zero_pred_classes:\n            warning_msg = f\"\\n⚠️ WARNING: Zero predictions for classes: {', '.join(zero_pred_classes)}\"\n            print(warning_msg)\n            \n            # Save warning to log file\n            with open(f\"{self.log_dir}/warnings.txt\", \"a\") as f:\n                f.write(f\"Epoch {epoch+1}: {warning_msg}\\n\")\n        \n        # Save visualizations and detailed reports on the specified frequency\n        if (epoch + 1) % self.freq == 0:\n            # Print confusion matrix\n            print(\"\\nConfusion Matrix:\")\n            print(cm)\n            \n            # Print per-class accuracy\n            for i, (name, acc) in enumerate(zip(self.class_names, class_accuracies)):\n                print(f\"{name}: {acc:.4f}\", end=\"  \")\n                if (i + 1) % 4 == 0:\n                    print()  # New line for readability\n            print(\"\\n\")\n            \n            # Print class accuracy trends instead of plotting them\n            print(\"Class Accuracy Trends:\")\n            for class_name in self.class_names:\n                history = self.class_metrics_history[class_name]\n                trend = \", \".join([f\"{acc:.4f}\" for acc in history[-5:]])  # Show last 5 epochs\n                print(f\"{class_name}: [{trend}]\")\n            print()\n            \n            # Save confusion matrix visualization (still useful)\n            plt.figure(figsize=(10, 8))\n            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                       xticklabels=self.class_names,\n                       yticklabels=self.class_names)\n            plt.xlabel('Predicted')\n            plt.ylabel('True')\n            plt.title(f'Confusion Matrix - {self.model_name} - Epoch {epoch+1}')\n            plt.tight_layout()\n            \n            try:\n                plt.savefig(f'{self.log_dir}/confusion_matrix_epoch_{epoch+1}.png')\n            except Exception as e:\n                print(f\"Warning: Could not save confusion matrix plot: {e}\")\n            \n            plt.close()\n\n# =============================================================================\n# Create emotion recognition model with additional MLP head\n# =============================================================================\ndef create_emotion_model(num_classes):\n    \"\"\"\n    Create a facial emotion recognition model with enhanced classification head.\n    \n    Args:\n        num_classes: Number of emotion classes\n        \n    Returns:\n        Compiled Keras model and base model\n    \"\"\"\n    # Input shape\n    input_shape = (IMG_SIZE, IMG_SIZE, 3)\n    \n    # Create input layer\n    inputs = keras.layers.Input(shape=input_shape)\n    \n    # Use MobileNetV2 as base\n    base_model = MobileNetV2(\n        include_top=False,\n        weights='imagenet',\n        input_tensor=inputs,\n        alpha=1.0  # Controls model width\n    )\n    print(\"Using MobileNetV2 base model\")\n    \n    # Freeze base model layers\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    # Add custom head with dropout and batch normalization\n    x = base_model.output\n    x = keras.layers.GlobalAveragePooling2D()(x)\n    \n    # First dense block - wider layers for better capacity\n    x = keras.layers.Dense(512)(x)  # Increased from 256\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.Dropout(0.4)(x)\n    \n    # Second dense block\n    x = keras.layers.Dense(256)(x)  # Increased from 128\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.Dropout(0.3)(x)\n    \n    # New third dense block for better capacity\n    x = keras.layers.Dense(128)(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Activation('relu')(x)\n    x = keras.layers.Dropout(0.2)(x)\n    \n    # Output layer with label smoothing\n    outputs = keras.layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n    \n    # Create model\n    model = keras.Model(inputs=inputs, outputs=outputs)\n    \n    # Compile with label smoothing loss\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n        loss=label_smoothing_loss(epsilon=0.2),  # Increased from 0.1\n        metrics=['accuracy']\n    )\n    \n    return model, base_model\n\n# =============================================================================\n# Evaluation function\n# =============================================================================\ndef evaluate_model(model, test_ds, steps, class_names, log_dir, dataset_name=\"\"):\n    \"\"\"\n    Evaluate model with detailed metrics and visualizations.\n    \"\"\"\n    print(f\"\\nEvaluating model on {dataset_name} test set\")\n    \n    # Get predictions\n    y_true = []\n    y_pred = []\n    \n    # Loop through test batches\n    for i, (images, labels) in enumerate(test_ds):\n        if i >= steps:\n            break\n        batch_preds = model.predict(images, verbose=0)\n        y_pred.append(np.argmax(batch_preds, axis=1))\n        y_true.append(np.argmax(labels.numpy(), axis=1))\n    \n    # Concatenate\n    y_true = np.concatenate(y_true)\n    y_pred = np.concatenate(y_pred)\n    \n    # Calculate metrics\n    test_accuracy = np.mean(y_pred == y_true)\n    f1 = f1_score(y_true, y_pred, average='weighted')\n    \n    print(f\"{dataset_name} Test Accuracy: {test_accuracy:.4f}\")\n    print(f\"{dataset_name} Weighted F1-Score: {f1:.4f}\")\n    \n    # Calculate confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # Visualize confusion matrix\n    plt.figure(figsize=(12, 10))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n               xticklabels=class_names,\n               yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title(f'Confusion Matrix - {dataset_name} Test Set')\n    plt.tight_layout()\n    \n    try:\n        plt.savefig(f'{log_dir}/confusion_matrix_{dataset_name}_test.png')\n    except Exception as e:\n        print(f\"Warning: Could not save confusion matrix plot: {e}\")\n        \n    plt.close()\n    \n    # Print classification report\n    print(f\"\\n{dataset_name} Classification Report:\")\n    report = classification_report(\n        y_true, \n        y_pred, \n        target_names=class_names,\n        zero_division=0\n    )\n    print(report)\n    \n    # Save report to file\n    with open(f'{log_dir}/classification_report_{dataset_name}.txt', 'w') as f:\n        f.write(report)\n    \n    return {\n        'accuracy': test_accuracy,\n        'f1_score': f1,\n        'confusion_matrix': cm\n    }\n\n# =============================================================================\n# Two-Stage Fine-Tuning with Progressive Unfreezing\n# =============================================================================\ndef train_with_progressive_unfreezing(model, base_model, train_ds, val_ds, \n                                    steps_per_epoch, val_steps, \n                                    epochs_head=10, epochs_finetune=20,\n                                    callbacks=None, class_weights=None):\n    \"\"\"\n    Two-stage training approach: first train only the head, then progressively unfreeze layers.\n    \n    Args:\n        model: The model to train\n        base_model: The base model part (for unfreezing)\n        train_ds: Training dataset\n        val_ds: Validation dataset\n        steps_per_epoch: Steps per training epoch\n        val_steps: Validation steps\n        epochs_head: Epochs for head-only training\n        epochs_finetune: Epochs for fine-tuning\n        callbacks: List of callbacks\n        class_weights: Class weights for handling imbalance\n        \n    Returns:\n        Training history\n    \"\"\"\n    print(f\"\\nStage 1: Training only the classification head ({epochs_head} epochs)\")\n    \n    # Ensure base model is frozen\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    # Compile with higher learning rate for head training\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n        loss=label_smoothing_loss(epsilon=0.2),\n        metrics=['accuracy']\n    )\n    \n    # Train head only\n    history_head = model.fit(\n        train_ds,\n        epochs=epochs_head,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=val_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    \n    print(f\"\\nStage 2: Fine-tuning with progressive unfreezing ({epochs_finetune} epochs)\")\n    \n    # Progressively unfreeze layers in groups\n    fine_tuning_history = []\n    \n    # Groups of layers to unfreeze (from last to first)\n    layer_groups = [\n        # Unfreeze last layers first (deeper = more specific features)\n        base_model.layers[-15:],  # Last block\n        base_model.layers[-30:-15],  # Second-to-last block\n        base_model.layers[-50:-30]   # Third-to-last block\n    ]\n    \n    for i, group in enumerate(layer_groups):\n        print(f\"\\nUnfreezing group {i+1}/{len(layer_groups)} ({len(group)} layers)\")\n        \n        # Unfreeze current group\n        for layer in group:\n            layer.trainable = True\n            \n        # Recompile with lower learning rate as we go deeper\n        lr = 1e-4 / (i + 1)  # Decrease learning rate for deeper layers\n        \n        model.compile(\n            optimizer=keras.optimizers.Adam(learning_rate=lr),\n            loss=label_smoothing_loss(epsilon=0.2),  # Keep consistent\n            metrics=['accuracy']\n        )\n        \n        # Train for a few epochs\n        epochs_per_group = max(5, epochs_finetune // len(layer_groups))\n        \n        history = model.fit(\n            train_ds,\n            epochs=epochs_per_group,\n            steps_per_epoch=steps_per_epoch,\n            validation_data=val_ds,\n            validation_steps=val_steps,\n            callbacks=callbacks,\n            class_weight=class_weights,\n            verbose=1\n        )\n        \n        fine_tuning_history.append(history)\n    \n    # Return combined history\n    return history_head, fine_tuning_history\n\n# =============================================================================\n# Sequential Training Pipeline\n# =============================================================================\ndef train_enhanced_emotion_model(data_dir):\n    \"\"\"\n    Enhanced sequential training with all improvements.\n    \n    Args:\n        data_dir: Path to dataset directory\n        \n    Returns:\n        Trained model and evaluation metrics\n    \"\"\"\n    print(\"Starting enhanced sequential emotion recognition training\")\n    \n    # 1. Load and prepare data\n    print(\"\\n1. Loading datasets\")\n    train_dir = os.path.join(data_dir, \"Train\")\n    test_dir = os.path.join(data_dir, \"Test\")\n    \n    train_df_full = build_image_df(train_dir)\n    test_df = build_image_df(test_dir)\n    \n    # Show dataset distributions\n    print(\"\\nAffectNet training distribution:\")\n    print(train_df_full[train_df_full['source'] == 'affectnet']['label'].value_counts())\n    \n    print(\"\\nFER2013 training distribution:\")\n    print(train_df_full[train_df_full['source'] == 'fer2013']['label'].value_counts())\n    \n    # 2. Split test set by dataset source\n    test_affectnet_df = test_df[test_df['source'] == 'affectnet']\n    test_fer_df = test_df[test_df['source'] == 'fer2013']\n    \n    print(f\"\\nTest sets: AffectNet={len(test_affectnet_df)}, FER2013={len(test_fer_df)}\")\n    \n    # Get classes for later use\n    classes = sorted(train_df_full[\"label\"].unique())\n    num_classes = len(classes)\n    print(f\"Classes: {classes}\")\n    \n    # 3. Create validation splits\n    # For AffectNet\n    affectnet_train_df = train_df_full[train_df_full['source'] == 'affectnet']\n    affectnet_train_df, affectnet_val_df = train_test_split(\n        affectnet_train_df, \n        test_size=0.15, \n        stratify=affectnet_train_df[\"label\"], \n        random_state=42\n    )\n    \n    # For FER2013\n    fer_train_df = train_df_full[train_df_full['source'] == 'fer2013']\n    fer_train_df, fer_val_df = train_test_split(\n        fer_train_df, \n        test_size=0.15, \n        stratify=fer_train_df[\"label\"], \n        random_state=42\n    )\n    \n    print(f\"AffectNet: {len(affectnet_train_df)} train, {len(affectnet_val_df)} validation\")\n    print(f\"FER2013: {len(fer_train_df)} train, {len(fer_val_df)} validation\")\n    \n    # 4. Create datasets with emphasis on problematic classes\n    print(\"\\n2. Creating enhanced data pipelines\")\n    \n    # AffectNet datasets\n    affectnet_train_ds, class_indices = create_emphasis_dataset(\n        affectnet_train_df, is_training=True)\n    \n    affectnet_val_ds, _ = create_dataset(\n        affectnet_val_df, is_training=False, \n        dataset_type='affectnet')\n    \n    affectnet_test_ds, _ = create_dataset(\n        test_affectnet_df, is_training=False, \n        dataset_type='affectnet')\n    \n    # FER2013 datasets\n    fer_train_ds, _ = create_emphasis_dataset(\n        fer_train_df, is_training=True)\n    \n    fer_val_ds, _ = create_dataset(\n        fer_val_df, is_training=False, \n        dataset_type='fer2013')\n    \n    fer_test_ds, _ = create_dataset(\n        test_fer_df, is_training=False, \n        dataset_type='fer2013')\n    \n    # Create combined test dataset\n    combined_test_ds, _ = create_dataset(\n        test_df, is_training=False)\n    \n    # 5. Calculate steps\n    affectnet_steps_per_epoch = len(affectnet_train_df) // BATCH_SIZE\n    affectnet_val_steps = len(affectnet_val_df) // BATCH_SIZE\n    affectnet_test_steps = len(test_affectnet_df) // BATCH_SIZE\n    \n    fer_steps_per_epoch = len(fer_train_df) // BATCH_SIZE\n    fer_val_steps = len(fer_val_df) // BATCH_SIZE\n    fer_test_steps = len(test_fer_df) // BATCH_SIZE\n    \n    combined_test_steps = len(test_df) // BATCH_SIZE\n    \n    # 6. Create enhanced model\n    print(\"\\n3. Creating enhanced model\")\n    model, base_model = create_emotion_model(num_classes)\n    \n    # 7. Compute class weights for each dataset with adjustments\n    print(\"\\n4. Computing class weights with adjustments for problematic classes\")\n    \n    # AffectNet class weights\n    affectnet_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(affectnet_train_df[\"label\"]),\n        y=affectnet_train_df[\"label\"]\n    )\n    affectnet_class_weights = {class_indices[label]: weight for label, weight in \n                     zip(np.unique(affectnet_train_df[\"label\"]), affectnet_weights)}\n    \n    # FER2013 class weights\n    fer_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(fer_train_df[\"label\"]),\n        y=fer_train_df[\"label\"]\n    )\n    fer_class_weights = {class_indices[label]: weight for label, weight in \n                zip(np.unique(fer_train_df[\"label\"]), fer_weights)}\n    \n    # Increase weights for problematic classes\n    for problem_class in PROBLEMATIC_CLASSES:\n        if problem_class in class_indices:\n            class_idx = class_indices[problem_class]\n            # Increase the weight by 20%\n            if class_idx in affectnet_class_weights:\n                affectnet_class_weights[class_idx] *= 1.2\n            if class_idx in fer_class_weights:\n                fer_class_weights[class_idx] *= 1.2\n    \n    print(\"Enhanced AffectNet class weights:\", affectnet_class_weights)\n    print(\"Enhanced FER2013 class weights:\", fer_class_weights)\n    \n    # 8. Setup callbacks with enhanced monitoring\n    print(\"\\n5. Setting up enhanced callbacks\")\n    \n    # Base callbacks shared across training phases\n    base_callbacks = [\n        # Early stopping\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=10,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        # Learning rate scheduler\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.5,\n            patience=5,\n            min_lr=1e-6,\n            verbose=1\n        ),\n        # TensorBoard\n        tf.keras.callbacks.TensorBoard(\n            log_dir=LOG_DIR,\n            histogram_freq=1,\n            update_freq='epoch'\n        )\n    ]\n    \n    # AffectNet-specific callbacks\n    affectnet_callbacks = base_callbacks + [\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'model_checkpoints/affectnet_best.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        ),\n        # Enhanced confusion matrix monitoring (fixed version)\n        EnhancedConfusionMatrixCallback(\n            affectnet_val_ds, \n            classes, \n            log_dir=LOG_DIR + '/affectnet',\n            model_name=\"AffectNet\",\n            freq=3\n        ),\n        # CSV Logger\n        tf.keras.callbacks.CSVLogger(\n            'affectnet_training_log.csv', \n            append=True\n        )\n    ]\n    \n    # FER2013-specific callbacks\n    fer_callbacks = base_callbacks + [\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'model_checkpoints/fer2013_best.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        ),\n        # Enhanced confusion matrix monitoring (fixed version)\n        EnhancedConfusionMatrixCallback(\n            fer_val_ds, \n            classes, \n            log_dir=LOG_DIR + '/fer2013',\n            model_name=\"FER2013\",\n            freq=3\n        ),\n        # CSV Logger\n        tf.keras.callbacks.CSVLogger(\n            'fer2013_training_log.csv', \n            append=True\n        )\n    ]\n    \n    # 9. STAGE 1: Train on AffectNet using progressive unfreezing\n    print(\"\\n6. STAGE 1: Training on AffectNet with progressive unfreezing\")\n    \n    history_affectnet_head, history_affectnet_finetune = train_with_progressive_unfreezing(\n        model, base_model,\n        affectnet_train_ds, affectnet_val_ds,\n        affectnet_steps_per_epoch, affectnet_val_steps,\n        epochs_head=10, epochs_finetune=15,\n        callbacks=affectnet_callbacks,\n        class_weights=affectnet_class_weights\n    )\n    \n    # Save AffectNet model\n    model.save(\"affectnet_model.keras\")\n    print(\"AffectNet model saved to 'affectnet_model.keras'\")\n    \n    # 10. Evaluate on AffectNet test set\n    affectnet_metrics = evaluate_model(\n        model, \n        affectnet_test_ds, \n        affectnet_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"AffectNet\"\n    )\n    \n    # 11. STAGE 2: Fine-tune on FER2013 with progressive unfreezing\n    print(\"\\n7. STAGE 2: Fine-tuning on FER2013 with progressive unfreezing\")\n    \n    history_fer_head, history_fer_finetune = train_with_progressive_unfreezing(\n        model, base_model,\n        fer_train_ds, fer_val_ds,\n        fer_steps_per_epoch, fer_val_steps,\n        epochs_head=8, epochs_finetune=12,\n        callbacks=fer_callbacks,\n        class_weights=fer_class_weights\n    )\n    \n    # 12. Evaluate on FER2013 test set\n    fer_metrics = evaluate_model(\n        model, \n        fer_test_ds, \n        fer_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"FER2013\"\n    )\n    \n    # 13. Evaluate on combined test set\n    combined_metrics = evaluate_model(\n        model, \n        combined_test_ds, \n        combined_test_steps,\n        classes,\n        LOG_DIR,\n        dataset_name=\"Combined\"\n    )\n    \n    # 14. Save the final model\n    model.save(\"final_enhanced_emotion_model.keras\")\n    print(\"Final model saved to 'final_enhanced_emotion_model.keras'\")\n    \n    # Return models and metrics\n    return model, {\n        'affectnet': affectnet_metrics,\n        'fer2013': fer_metrics,\n        'combined': combined_metrics\n    }\n\n# =============================================================================\n# Main entry point\n# =============================================================================\nif __name__ == \"__main__\":\n    # Set data directory path\n    data_dir = \"/kaggle/input/custom-fer2013affectnet/Custom_ferAffect2013net\"\n    \n    # Train model with all improvements\n    model, metrics = train_enhanced_emotion_model(data_dir)\n    \n    # Print final results\n    print(\"\\n=== FINAL RESULTS ===\")\n    print(f\"AffectNet Test Accuracy: {metrics['affectnet']['accuracy']:.4f}\")\n    print(f\"AffectNet F1 Score: {metrics['affectnet']['f1_score']:.4f}\")\n    print(f\"FER2013 Test Accuracy: {metrics['fer2013']['accuracy']:.4f}\")\n    print(f\"FER2013 F1 Score: {metrics['fer2013']['f1_score']:.4f}\")\n    print(f\"Combined Test Accuracy: {metrics['combined']['accuracy']:.4f}\")\n    print(f\"Combined F1 Score: {metrics['combined']['f1_score']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T13:09:26.023941Z","iopub.execute_input":"2025-03-11T13:09:26.024293Z","iopub.status.idle":"2025-03-11T13:30:17.269744Z","shell.execute_reply.started":"2025-03-11T13:09:26.024264Z","shell.execute_reply":"2025-03-11T13:30:17.268766Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Version 6.0z accuracy 0.1882 class balance deficit \n\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom sklearn.model_selection import train_test_split\n\n# =============================================================================\n# Enable memory growth and mixed precision\n# =============================================================================\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        print(e)\n\n# Enable mixed precision\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\n\n# =============================================================================\n# Key parameters\n# =============================================================================\nIMG_SIZE = 96  # Keep at 96x96 as requested\nBATCH_SIZE = 128  # Moderate batch size\nEPOCHS = 50\nAUTOTUNE = tf.data.AUTOTUNE\n\n# =============================================================================\n# Custom Focal Loss Implementation\n# =============================================================================\ndef focal_loss(gamma=2.0, alpha=0.25):\n    \"\"\"\n    Focal Loss implementation for multi-class classification.\n    Focal Loss is designed to address class imbalance by down-weighting easy examples.\n    \n    Args:\n        gamma: Focusing parameter. Higher values mean more focus on hard examples.\n        alpha: Class weight factor. Higher values give more weight to minority classes.\n        \n    Returns:\n        Focal loss function\n    \"\"\"\n    def focal_loss_fn(y_true, y_pred):\n        epsilon = 1e-7\n        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n        \n        # Calculate cross entropy\n        cross_entropy = -y_true * K.log(y_pred)\n        \n        # Apply focal weight\n        weight = alpha * K.pow(1 - y_pred, gamma) * y_true\n        \n        # Sum over classes\n        focal_loss = K.sum(weight * cross_entropy, axis=-1)\n        return K.mean(focal_loss)\n    \n    return focal_loss_fn\n\n# =============================================================================\n# Build DataFrame from dataset directory structure\n# =============================================================================\ndef build_image_df(root_dir, subfolders=[\"fer2013\", \"affectnet\"]):\n    \"\"\"\n    Scans the given root directory and returns a DataFrame with file paths and labels.\n    \"\"\"\n    data = []\n    emotions = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n    for emotion in emotions:\n        emotion_path = os.path.join(root_dir, emotion)\n        for sub in subfolders:\n            sub_path = os.path.join(emotion_path, sub)\n            if os.path.exists(sub_path):\n                for img_file in os.listdir(sub_path):\n                    if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n                        data.append({\n                            \"filepath\": os.path.join(sub_path, img_file),\n                            \"label\": emotion,\n                            \"source\": sub\n                        })\n    return pd.DataFrame(data)\n\n# =============================================================================\n# Data Augmentation for Minority Classes\n# =============================================================================\ndef augment_minority_classes(df, target_count=5000, minority_classes=None):\n    \"\"\"\n    Augment minority classes by duplicating samples to achieve more balanced class distribution.\n    \n    Args:\n        df: DataFrame with image paths and labels\n        target_count: Target number of samples per class\n        minority_classes: List of specific classes to augment (if None, determined automatically)\n        \n    Returns:\n        Augmented DataFrame\n    \"\"\"\n    print(\"Class distribution before augmentation:\")\n    print(df['label'].value_counts())\n    \n    if minority_classes is None:\n        # Identify classes with fewer than target_count samples\n        class_counts = df['label'].value_counts()\n        minority_classes = class_counts[class_counts < target_count].index.tolist()\n    \n    augmented_data = []\n    for cls in minority_classes:\n        class_df = df[df['label'] == cls]\n        needed = target_count - len(class_df)\n        if needed <= 0:\n            continue\n            \n        # Sample with replacement if needed\n        print(f\"Augmenting class '{cls}': Adding {needed} samples\")\n        samples = class_df.sample(n=needed, replace=True)\n        augmented_data.append(samples)\n    \n    # Combine augmented data with original\n    augmented_df = pd.concat([df] + augmented_data, ignore_index=True)\n    \n    print(\"Class distribution after augmentation:\")\n    print(augmented_df['label'].value_counts())\n    \n    return augmented_df\n\n# =============================================================================\n# Improved preprocessing function\n# =============================================================================\ndef preprocess_image(file_path, label, source):\n    \"\"\"\n    Unified preprocessing function with consistent augmentation for both datasets.\n    \n    Args:\n        file_path: Path to the image file\n        label: Emotion label (as index)\n        source: Dataset source ('fer2013' or 'affectnet')\n        \n    Returns:\n        Preprocessed image and one-hot encoded label\n    \"\"\"\n    # Read the file\n    img = tf.io.read_file(file_path)\n    \n    # Decode with better error handling\n    try:\n        img = tf.image.decode_image(img, channels=3, expand_animations=False)\n    except tf.errors.InvalidArgumentError:\n        try:\n            img = tf.image.decode_image(img, channels=1, expand_animations=False)\n            img = tf.image.grayscale_to_rgb(img)\n        except:\n            # Create a blank image if decoding fails\n            img = tf.zeros([IMG_SIZE, IMG_SIZE, 3], dtype=tf.uint8)\n            print(f\"Warning: Failed to decode image at {file_path}\")\n    \n    # Ensure the image has the right shape and type\n    img = tf.ensure_shape(img, [None, None, 3])\n    \n    # Resize to target size\n    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE], method='bilinear')\n    \n    # Normalize to [0, 1]\n    img = tf.cast(img, tf.float32) / 255.0\n    \n    # Apply consistent augmentation for both datasets\n    if tf.random.uniform([], 0, 1) > 0.5:\n        # Standard horizontal flipping\n        img = tf.image.random_flip_left_right(img)\n        \n        # Color augmentations\n        img = tf.image.random_brightness(img, 0.2)\n        img = tf.image.random_contrast(img, 0.8, 1.2)\n        img = tf.image.random_saturation(img, 0.8, 1.2)\n        \n        # Slight rotation (maximum 15 degrees)\n        angle = tf.random.uniform([], -0.25, 0.25)  # in radians\n        img = tf.image.rot90(img, k=tf.cast(angle * 2 / 3.14159, tf.int32))\n    \n    # Convert label to one-hot encoding\n    label = tf.one_hot(label, depth=8)  # Assuming 8 emotion classes\n    \n    return img, label\n\n# =============================================================================\n# Fixed dataset creation function\n# =============================================================================\ndef create_dataset(dataframe, is_training=True):\n    \"\"\"\n    Create an optimized tf.data.Dataset from a DataFrame with fixed repeating.\n    \n    Args:\n        dataframe: DataFrame with filepath, label, and source columns\n        is_training: Whether to apply augmentations and shuffling\n        \n    Returns:\n        tf.data.Dataset\n    \"\"\"\n    # Convert labels to indices\n    class_indices = {cls: i for i, cls in enumerate(sorted(dataframe[\"label\"].unique()))}\n    labels = [class_indices[label] for label in dataframe[\"label\"]]\n    \n    # Create dataset from file paths, labels, and sources\n    ds = tf.data.Dataset.from_tensor_slices((\n        dataframe[\"filepath\"].values,\n        labels,\n        dataframe[\"source\"].values\n    ))\n    \n    # Apply preprocessing\n    ds = ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)\n    \n    if is_training:\n        # Training pipeline with augmentation\n        ds = ds.shuffle(buffer_size=min(10000, len(dataframe)))\n        \n    # Important: Always repeat the dataset for multiple epochs\n    ds = ds.repeat()\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(AUTOTUNE)\n    \n    return ds, class_indices\n\n# =============================================================================\n# Confusion Matrix Callback\n# =============================================================================\nclass ConfusionMatrixCallback(tf.keras.callbacks.Callback):\n    \"\"\"\n    Callback to display confusion matrix during training.\n    \"\"\"\n    def __init__(self, validation_data, class_names, freq=5):\n        super(ConfusionMatrixCallback, self).__init__()\n        self.validation_data = validation_data\n        self.class_names = class_names\n        self.freq = freq\n        \n    def on_epoch_end(self, epoch, logs=None):\n        if (epoch + 1) % self.freq == 0:\n            # Get a batch of validation data\n            validation_steps = 30  # Limit to prevent too much computation\n            y_true = []\n            y_pred = []\n            \n            # Get predictions for validation data\n            for i, (images, labels) in enumerate(self.validation_data):\n                if i >= validation_steps:\n                    break\n                batch_preds = self.model.predict(images, verbose=0)\n                y_pred.append(np.argmax(batch_preds, axis=1))\n                y_true.append(np.argmax(labels.numpy(), axis=1))\n            \n            # Flatten the lists\n            y_true = np.concatenate(y_true)\n            y_pred = np.concatenate(y_pred)\n            \n            # Calculate confusion matrix\n            cm = confusion_matrix(y_true, y_pred)\n            \n            # Print confusion matrix\n            print(\"\\nConfusion Matrix:\")\n            print(cm)\n            \n            # Calculate per-class accuracy\n            class_acc = cm.diagonal() / cm.sum(axis=1)\n            for i, (name, acc) in enumerate(zip(self.class_names, class_acc)):\n                print(f\"{name}: {acc:.4f}\", end=\"  \")\n                if (i + 1) % 4 == 0:\n                    print()  # New line for readability\n            print()\n\n# =============================================================================\n# Model Creation\n# =============================================================================\ndef create_simplified_model(num_classes):\n    \"\"\"\n    Create a simplified EfficientNetB0 model with a smaller head.\n    \n    Args:\n        num_classes: Number of emotion classes\n        \n    Returns:\n        Compiled Keras model\n    \"\"\"\n    # Input layer\n    inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n    \n    # Load pre-trained model with imagenet weights\n    base_model = EfficientNetB0(\n        include_top=False, \n        weights=\"imagenet\", \n        input_tensor=inputs\n    )\n    \n    # Initially freeze all layers\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    # Add custom classification head\n    x = base_model.output\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(0.4)(x)\n    \n    # Ensure final layer uses float32 for numerical stability\n    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n    \n    # Create model\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    \n    # Compile with focal loss\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n        loss=focal_loss(gamma=2.0, alpha=0.25),\n        metrics=[\"accuracy\"]\n    )\n    \n    return model, base_model\n\n# =============================================================================\n# Main Training Function\n# =============================================================================\ndef train_emotion_recognition_model(data_dir):\n    \"\"\"\n    Complete training pipeline incorporating all improvements.\n    \n    Args:\n        data_dir: Path to the dataset directory\n        \n    Returns:\n        Trained model and evaluation metrics\n    \"\"\"\n    print(\"Starting improved facial emotion recognition training\")\n    \n    # 1. Load and prepare data\n    print(\"\\n1. Loading dataset\")\n    train_dir = os.path.join(data_dir, \"Train\")\n    test_dir = os.path.join(data_dir, \"Test\")\n    \n    train_df_full = build_image_df(train_dir)\n    test_df = build_image_df(test_dir)\n    \n    print(f\"Original training data: {train_df_full.shape}\")\n    print(f\"Test data: {test_df.shape}\")\n    \n    # 2. Apply class balancing through augmentation\n    print(\"\\n2. Balancing class distribution\")\n    train_df_balanced = augment_minority_classes(train_df_full, target_count=5000)\n    \n    # 3. Split into train and validation sets\n    print(\"\\n3. Creating train/validation split\")\n    train_df, val_df = train_test_split(\n        train_df_balanced, \n        test_size=0.15, \n        stratify=train_df_balanced[\"label\"], \n        random_state=42\n    )\n    \n    print(f\"Training samples: {len(train_df)}\")\n    print(f\"Validation samples: {len(val_df)}\")\n    print(f\"Test samples: {len(test_df)}\")\n    \n    # 4. Create fixed tf.data datasets\n    print(\"\\n4. Creating data pipelines\")\n    train_ds, class_indices = create_dataset(train_df, is_training=True)\n    val_ds, _ = create_dataset(val_df, is_training=False)\n    test_ds, _ = create_dataset(test_df, is_training=False)\n    \n    # Get class names in order\n    classes = sorted(train_df[\"label\"].unique())\n    num_classes = len(classes)\n    print(f\"Classes: {classes}\")\n    \n    # Calculate steps\n    steps_per_epoch = len(train_df) // BATCH_SIZE\n    validation_steps = len(val_df) // BATCH_SIZE\n    \n    # 5. Create model\n    print(\"\\n5. Creating simplified model\")\n    model, base_model = create_simplified_model(num_classes)\n    print(\"Model created\")\n    \n    # 6. Calculate proper class weights\n    print(\"\\n6. Computing class weights\")\n    class_weights_array = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(train_df[\"label\"]),\n        y=train_df[\"label\"]\n    )\n    class_weights = {class_indices[label]: weight for label, weight in \n                     zip(np.unique(train_df[\"label\"]), class_weights_array)}\n    print(\"Class weights:\", class_weights)\n    \n    # 7. Setup callbacks\n    print(\"\\n7. Setting up training callbacks\")\n    callbacks = [\n        # Model checkpoint\n        tf.keras.callbacks.ModelCheckpoint(\n            'best_emotion_model.weights.h5',\n            monitor='val_accuracy',\n            save_best_only=True,\n            save_weights_only=True,\n            verbose=1\n        ),\n        # Early stopping\n        tf.keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=7,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        # Learning rate scheduler\n        tf.keras.callbacks.ReduceLROnPlateau(\n            monitor='val_loss',\n            factor=0.5,\n            patience=3,\n            min_lr=1e-6,\n            verbose=1\n        ),\n        # Logging\n        tf.keras.callbacks.CSVLogger('training_log.csv', append=True),\n        # Confusion matrix\n        ConfusionMatrixCallback(val_ds, classes, freq=3)\n    ]\n    \n    # 8. Progressive training approach\n    print(\"\\n8. Stage 1: Training only the model head\")\n    history_stage1 = model.fit(\n        train_ds,\n        epochs=10,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=validation_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    \n    # 9. Fine-tune the upper layers\n    print(\"\\n9. Stage 2: Fine-tuning upper layers\")\n    # Unfreeze the top layers of the base model\n    for layer in base_model.layers[-30:]:\n        layer.trainable = True\n        \n    # Recompile with a lower learning rate\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n        loss=focal_loss(gamma=2.0, alpha=0.25),\n        metrics=[\"accuracy\"]\n    )\n    \n    history_stage2 = model.fit(\n        train_ds,\n        epochs=20,\n        steps_per_epoch=steps_per_epoch,\n        validation_data=val_ds,\n        validation_steps=validation_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    \n    # 10. Evaluate on test set\n    print(\"\\n10. Final evaluation\")\n    # Update test steps\n    test_steps = len(test_df) // BATCH_SIZE\n    \n    # Get predictions\n    all_predictions = []\n    all_labels = []\n    \n    # Loop through batches\n    for i, (images, labels) in enumerate(test_ds):\n        if i >= test_steps:\n            break\n        batch_preds = model.predict(images, verbose=0)\n        all_predictions.append(np.argmax(batch_preds, axis=1))\n        all_labels.append(np.argmax(labels.numpy(), axis=1))\n    \n    # Concatenate\n    all_predictions = np.concatenate(all_predictions)\n    all_labels = np.concatenate(all_labels)\n    \n    # Calculate metrics\n    test_accuracy = np.mean(all_predictions == all_labels)\n    f1 = f1_score(all_labels, all_predictions, average='weighted')\n    \n    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n    print(f\"Weighted F1-Score: {f1:.4f}\")\n    \n    # Print classification report\n    print(\"\\nClassification Report:\")\n    print(classification_report(\n        all_labels, \n        all_predictions, \n        target_names=classes,\n        zero_division=0\n    ))\n    \n    # Print confusion matrix\n    cm = confusion_matrix(all_labels, all_predictions)\n    print(\"\\nConfusion Matrix:\")\n    print(cm)\n    \n    # 11. Save the final model\n    model.save(\"final_improved_emotion_model.keras\")\n    print(\"Model saved to 'final_improved_emotion_model.keras'\")\n    \n    return model, {'accuracy': test_accuracy, 'f1_score': f1}\n\n# =============================================================================\n# Main entry point\n# =============================================================================\nif __name__ == \"__main__\":\n    # Set data directory path\n    data_dir = \"/kaggle/input/custom-fer2013affectnet/Custom_ferAffect2013net\"\n    \n    # Train model\n    model, metrics = train_emotion_recognition_model(data_dir)\n    \n    print(\"Training completed successfully!\")\n    print(f\"Final Test Accuracy: {metrics['accuracy']:.4f}\")\n    print(f\"Final F1 Score: {metrics['f1_score']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T23:28:45.447003Z","iopub.execute_input":"2025-03-10T23:28:45.447275Z","iopub.status.idle":"2025-03-10T23:39:01.046153Z","shell.execute_reply.started":"2025-03-10T23:28:45.447252Z","shell.execute_reply":"2025-03-10T23:39:01.045323Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Version 6.0 accuracy 0.1832 \n\nimport os\nimport math\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\nfrom sklearn.model_selection import train_test_split\n\n# Enable memory growth to prevent TF from allocating all GPU memory at once\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        print(e)\n\n# Enable mixed precision for faster training\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\n\n# Memory cleanup callback\nclass MemoryCleanupCallback(keras.callbacks.Callback):\n    \"\"\"Callback to clear TensorFlow session after each epoch to free memory.\"\"\"\n    def on_epoch_end(self, epoch, logs=None):\n        tf.keras.backend.clear_session()\n\n# =============================================================================\n# Define key parameters\n# =============================================================================\nIMG_SIZE = 96  # Unified image size for both datasets\nBATCH_SIZE = 32  # Start with a conservative value\nEPOCHS = 30\nAUTOTUNE = tf.data.AUTOTUNE\n\n# Try to determine optimal batch size based on available GPU memory\n# Start with default batch size\noptimal_batch_size = BATCH_SIZE\n\n# Try to detect available GPU memory and adjust batch size\ntry:\n    gpus = tf.config.experimental.list_physical_devices('GPU')\n    if gpus:\n        # Get GPU memory info if possible (works on some systems)\n        gpu_details = tf.config.experimental.get_device_details(gpus[0])\n        if 'memory_limit' in gpu_details:\n            # Memory in bytes, convert to GB\n            gpu_memory_gb = gpu_details['memory_limit'] / (1024**3)\n            \n            # Simple heuristic: 1GB supports batch size of ~16 for this model\n            if gpu_memory_gb > 14:  # High-end GPU (16GB+)\n                optimal_batch_size = 128\n            elif gpu_memory_gb > 7:  # Mid-range GPU (8GB)\n                optimal_batch_size = 64\n            else:  # Lower memory GPU\n                optimal_batch_size = 32\n                \n            print(f\"Detected {gpu_memory_gb:.1f}GB GPU memory, setting batch size to {optimal_batch_size}\")\n        else:\n            # If we can't detect memory, try a reasonable default for Kaggle\n            optimal_batch_size = 64\n            print(f\"Could not detect GPU memory, using default batch size of {optimal_batch_size}\")\nexcept Exception:\n    # If anything fails, stay with the default\n    print(f\"Using default batch size of {optimal_batch_size}\")\n\n# Update batch size to optimal value\nBATCH_SIZE = optimal_batch_size\n\n# =============================================================================\n# 1. Build a DataFrame from the dataset directory structure - Keeping your original function\n# =============================================================================\ndef build_image_df(root_dir, subfolders=[\"fer2013\", \"affectnet\"]):\n    \"\"\"\n    Scans the given root directory and returns a DataFrame with file paths and labels.\n    \"\"\"\n    data = []\n    emotions = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n    for emotion in emotions:\n        emotion_path = os.path.join(root_dir, emotion)\n        for sub in subfolders:\n            sub_path = os.path.join(emotion_path, sub)\n            if os.path.exists(sub_path):\n                for img_file in os.listdir(sub_path):\n                    if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n                        data.append({\n                            \"filepath\": os.path.join(sub_path, img_file),\n                            \"label\": emotion,\n                            \"source\": sub\n                        })\n    return pd.DataFrame(data)\n\n# =============================================================================\n# 2. Dataset Paths & DataFrame Creation\n# =============================================================================\ndata_dir = \"/kaggle/input/custom-fer2013affectnet/Custom_ferAffect2013net\"\ntrain_dir = os.path.join(data_dir, \"Train\")\ntest_dir = os.path.join(data_dir, \"Test\")\n\ntrain_df_full = build_image_df(train_dir)\ntest_df = build_image_df(test_dir)\n\nprint(\"Train DataFrame shape:\", train_df_full.shape)\nprint(\"Test DataFrame shape:\", test_df.shape)\n\n# Add data augmentation specifically for underrepresented classes\ndef augment_minority_classes(df, target_count=5000, minority_classes=None):\n    if minority_classes is None:\n        # Identify classes with fewer than target_count samples\n        class_counts = df['label'].value_counts()\n        minority_classes = class_counts[class_counts < target_count].index.tolist()\n    \n    augmented_data = []\n    for cls in minority_classes:\n        class_df = df[df['label'] == cls]\n        needed = target_count - len(class_df)\n        if needed <= 0:\n            continue\n            \n        # Sample with replacement if needed\n        samples = class_df.sample(n=needed, replace=True)\n        augmented_data.append(samples)\n    \n    # Combine augmented data with original\n    return pd.concat([df] + augmented_data, ignore_index=True)\n\n# Use this before train/val split\ntrain_df_full = augment_minority_classes(train_df_full)\n\n# =============================================================================\n# 3. Split Training Data into Train & Validation Sets\n# =============================================================================\ntrain_df, val_df = train_test_split(\n    train_df_full, \n    test_size=0.2, \n    stratify=train_df_full[\"label\"], \n    random_state=42\n)\n\n# Get class names and create mapping\nclasses = sorted(train_df_full[\"label\"].unique())\nclass_indices = {cls: i for i, cls in enumerate(classes)}\nnum_classes = len(classes)\n\n# =============================================================================\n# 4. Create an optimized tf.data pipeline\n# =============================================================================\ndef preprocess_image(file_path, label, source):\n    \"\"\"\n    Unified preprocessing function that handles both FER2013 and AffectNet images.\n    \n    Args:\n        file_path: Path to the image file\n        label: Emotion label (as index)\n        source: Dataset source ('fer2013' or 'affectnet')\n        \n    Returns:\n        Preprocessed image and one-hot encoded label\n    \"\"\"\n    # Read the file\n    img = tf.io.read_file(file_path)\n    \n    # Decode with error handling\n    try:\n        img = tf.image.decode_image(img, channels=3, expand_animations=False)\n    except:\n        img = tf.zeros([IMG_SIZE, IMG_SIZE, 3], dtype=tf.uint8)\n    \n    # Ensure shape and resize\n    img = tf.ensure_shape(img, [None, None, 3])\n    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE], method='bilinear')\n    \n    # Apply consistent preprocessing for both datasets\n    img = tf.cast(img, tf.float32) / 255.0\n    \n    # Apply the same augmentation regardless of source\n    if tf.random.uniform([], 0, 1) > 0.5:\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_brightness(img, 0.2)\n        img = tf.image.random_contrast(img, 0.8, 1.2)\n    \n    # One-hot encode label\n    label = tf.one_hot(label, depth=num_classes)\n    \n    return img, label\n\ndef create_dataset(dataframe, is_training=True): # , cache=True\n    \"\"\"\n    Create an optimized tf.data.Dataset from a DataFrame.\n    \n    Args:\n        dataframe: DataFrame with filepath, label, and source columns\n        is_training: Whether to apply augmentations\n        cache: Whether to cache the dataset (disable for very large datasets)\n        \n    Returns:\n        tf.data.Dataset\n    \"\"\"\n    # Convert labels to indices\n    labels = [class_indices[label] for label in dataframe[\"label\"]]\n    \n    # Create dataset\n    ds = tf.data.Dataset.from_tensor_slices((\n        dataframe[\"filepath\"].values,\n        labels,\n        dataframe[\"source\"].values\n    ))\n    \n    # Apply preprocessing and batching\n    ds = ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)\n    \n    if is_training:\n        ds = ds.shuffle(buffer_size=min(10000, len(dataframe)))\n        \n    # Make sure to repeat the dataset for multiple epochs\n    ds = ds.repeat()  # This is crucial\n    ds = ds.batch(BATCH_SIZE)\n    ds = ds.prefetch(AUTOTUNE)\n    \n    return ds\n\n# Create datasets\ntrain_ds = create_dataset(train_df, is_training=True)\nval_ds = create_dataset(val_df, is_training=False)\ntest_ds = create_dataset(test_df, is_training=False)\n\n# Calculate steps\nsteps_per_epoch = len(train_df) // BATCH_SIZE\nvalidation_steps = min(len(val_df) // BATCH_SIZE, 100)  # Limit validation steps\n\n# Sanity check - inspect a batch to verify the dataset pipeline\ndef inspect_dataset(dataset, name):\n    \"\"\"Inspect a dataset to verify it's created correctly.\"\"\"\n    print(f\"\\nInspecting {name} dataset:\")\n    \n    try:\n        # Get one batch\n        for images, labels in dataset.take(1):\n            print(f\"  Batch shape: {images.shape}\")\n            print(f\"  Labels shape: {labels.shape}\")\n            print(f\"  Data type: {images.dtype}\")\n            print(f\"  Min/Max values: {tf.reduce_min(images).numpy():.4f}/{tf.reduce_max(images).numpy():.4f}\")\n            \n            # Check for NaNs\n            has_nans = tf.math.reduce_any(tf.math.is_nan(images))\n            print(f\"  Contains NaNs: {has_nans.numpy()}\")\n            \n            # Verify one-hot labels\n            label_sums = tf.reduce_sum(labels, axis=1)\n            all_ones = tf.reduce_all(tf.equal(label_sums, 1))\n            print(f\"  Labels are valid one-hot: {all_ones.numpy()}\")\n            \n            # All checks passed\n            print(f\"  ✅ {name} dataset looks good!\")\n            return True\n    except Exception as e:\n        print(f\"  ❌ Error inspecting {name} dataset: {str(e)}\")\n        return False\n\n# Run sanity checks\ntrain_ok = inspect_dataset(train_ds, \"Training\")\nval_ok = inspect_dataset(val_ds, \"Validation\")\ntest_ok = inspect_dataset(test_ds, \"Test\")\n\n# Abort if datasets are not created correctly\nif not (train_ok and val_ok and test_ok):\n    print(\"\\n⚠️ Dataset sanity check failed! Please check the error messages above.\")\n    print(\"You can continue but training might fail.\")\n\n# =============================================================================\n# 5. Compute Class Weights to handle imbalance\n# =============================================================================\nclass_weights_array = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.unique(train_df[\"label\"]),\n    y=train_df[\"label\"]\n)\nclass_weights = {class_indices[label]: weight for label, weight in \n                 zip(np.unique(train_df[\"label\"]), class_weights_array)}\n\n# =============================================================================\n# 6. Model Architecture with Optimized Transfer Learning\n# =============================================================================\ndef create_model():\n    \"\"\"\n    Create an EfficientNetB0 model with frozen layers and custom top.\n    \n    Returns:\n        Compiled Keras model\n    \"\"\"\n    # Create input layer with the correct shape\n    input_tensor = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n    \n    # Load pre-trained model with imagenet weights\n    base_model = EfficientNetB0(\n        include_top=False, \n        weights=\"imagenet\", \n        input_tensor=input_tensor\n    )\n    \n    # Freeze the first 70% of layers\n    freeze_until = int(len(base_model.layers) * 0.7)\n    for layer in base_model.layers[:freeze_until]:\n        layer.trainable = False\n    \n    # Add custom classification head\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dropout(0.5)(x)\n    x = Dense(256, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01))(x)\n    x = Dropout(0.4)(x)\n    # Ensure final layer uses float32 for numerical stability with softmax\n    output = Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n    \n    # Create model\n    model = Model(inputs=input_tensor, outputs=output)\n    \n    # Compile with Adam optimizer\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    \n    return model\n\n# =============================================================================\n# 7. Learning Rate Scheduler and Callbacks\n# =============================================================================\ndef cosine_decay_schedule(epoch, lr):\n    \"\"\"\n    Cosine decay learning rate schedule.\n    \n    Args:\n        epoch: Current epoch\n        lr: Current learning rate\n        \n    Returns:\n        New learning rate\n    \"\"\"\n    initial_lr = 1e-4\n    return initial_lr * (1 + math.cos(math.pi * epoch / EPOCHS)) / 2\n\n# Create callbacks\ncallbacks = [\n    # Save checkpoints (using proper file extension for weights)\n    keras.callbacks.ModelCheckpoint(\n        'best_model.weights.h5',\n        monitor='val_accuracy',\n        save_best_only=True,\n        save_weights_only=True,  # Save only weights to reduce I/O\n        verbose=1\n    ),\n    # Early stopping\n    keras.callbacks.EarlyStopping(\n        monitor='val_loss',\n        patience=5,\n        restore_best_weights=True,\n        verbose=1\n    ),\n    # Learning rate scheduling\n    keras.callbacks.ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.5,\n        patience=3,\n        min_lr=1e-6,\n        verbose=1\n    ),\n    # Log training metrics\n    keras.callbacks.CSVLogger('training_log.csv', append=True),\n    # Memory cleanup after each epoch\n    MemoryCleanupCallback()\n\n]\n\n# =============================================================================\n# 8. Training\n# =============================================================================\ndef train_model(custom_callbacks=None, existing_model=None, quick_test=False):\n    \"\"\"\n    Train the model with the optimized pipeline.\n    \n    Args:\n        custom_callbacks: Additional callbacks to use during training\n        existing_model: Continue training this model if provided\n        quick_test: Whether this is a quick test run\n        \n    Returns:\n        Trained model and history\n    \"\"\"\n    # Create new model or use existing one\n    if existing_model is None:\n        model = create_model()\n        # Print model summary\n        model.summary()\n    else:\n        model = existing_model\n        print(\"Continuing training with existing model\")\n    \n    # Use custom callbacks if provided, otherwise use default callbacks\n    training_callbacks = custom_callbacks if custom_callbacks else callbacks\n    \n    # Adjust epochs and steps for quick test\n    current_epochs = 2 if quick_test else EPOCHS\n    current_steps = min(20, steps_per_epoch) if quick_test else steps_per_epoch\n    current_val_steps = min(10, validation_steps) if quick_test else validation_steps\n    \n    if quick_test:\n        print(f\"Quick test mode: {current_epochs} epochs, {current_steps} steps/epoch\")\n    \n    # Train model\n    history = model.fit(\n        train_ds,\n        epochs=current_epochs,\n        steps_per_epoch=current_steps,\n        validation_data=val_ds,\n        validation_steps=current_val_steps,\n        callbacks=training_callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    \n    return model, history\n\n# =============================================================================\n# 9. LR Finder - Fixed version with termination condition\n# =============================================================================\nclass LRFinder(keras.callbacks.Callback):\n    \"\"\"\n    Learning rate finder callback.\n    \n    This callback helps find the optimal learning rate by exponentially\n    increasing the learning rate during training and recording the loss.\n    \"\"\"\n    def __init__(self, min_lr=1e-7, max_lr=1e-2, steps=100, max_batches=1000):\n        super(LRFinder, self).__init__()\n        self.min_lr = min_lr\n        self.max_lr = max_lr\n        self.steps = steps\n        self.max_batches = max_batches  # Safety limit\n        self.lrs = []\n        self.losses = []\n        self.batch_counter = 0\n        \n    def on_train_begin(self, logs=None):\n        # Store original learning rate\n        self.original_lr = tf.keras.backend.get_value(self.model.optimizer.learning_rate)\n        # Set initial learning rate to minimum\n        tf.keras.backend.set_value(self.model.optimizer.learning_rate, self.min_lr)\n        self.optimizer = self.model.optimizer\n    \n    def on_train_batch_end(self, batch, logs=None):\n        # Get current learning rate\n        lr = tf.keras.backend.get_value(self.optimizer.learning_rate)\n        self.lrs.append(lr)\n        self.losses.append(logs.get('loss'))\n        \n        # Calculate new learning rate\n        new_lr = lr * (self.max_lr / self.min_lr) ** (1/self.steps)\n        tf.keras.backend.set_value(self.optimizer.learning_rate, new_lr)\n        \n        # Increment counter and check for termination\n        self.batch_counter += 1\n        if batch >= self.steps or self.batch_counter >= self.max_batches:\n            self.model.stop_training = True\n            \n    def on_train_end(self, logs=None):\n        # Restore original learning rate\n        tf.keras.backend.set_value(self.optimizer.learning_rate, self.original_lr)\n        \n    def plot_lr_finder(self):\n        \"\"\"Plot the learning rate finder results.\"\"\"\n        try:\n            import matplotlib.pyplot as plt\n            \n            plt.figure(figsize=(10, 6))\n            plt.plot(self.lrs, self.losses)\n            plt.xscale('log')\n            plt.xlabel('Learning Rate')\n            plt.ylabel('Loss')\n            plt.title('Learning Rate Finder')\n            plt.savefig('lr_finder_results.png')\n        except ImportError:\n            print(\"Matplotlib not available for plotting. Saving results to CSV instead.\")\n            import csv\n            with open('lr_finder_results.csv', 'w', newline='') as f:\n                writer = csv.writer(f)\n                writer.writerow(['learning_rate', 'loss'])\n                for lr, loss in zip(self.lrs, self.losses):\n                    writer.writerow([lr, loss])\n\n# =============================================================================\n# 10. Training with LR Finder\n# =============================================================================\ndef find_optimal_lr():\n    \"\"\"\n    Find the optimal learning rate using the LR Finder.\n    \n    Returns:\n        Suggested learning rate\n    \"\"\"\n    # Create model\n    model = create_model()\n    \n    # Create LR Finder callback\n    lr_finder = LRFinder(min_lr=1e-7, max_lr=1e-2, steps=100, max_batches=100)\n    \n    # Fit model for a few batches to find optimal LR\n    model.fit(\n        train_ds,\n        epochs=1,\n        steps_per_epoch=100,\n        callbacks=[lr_finder],\n        verbose=1\n    )\n    \n    # Plot results\n    lr_finder.plot_lr_finder()\n    \n    # Find the learning rate with the steepest negative gradient\n    losses = lr_finder.losses\n    lrs = lr_finder.lrs\n    \n    # Smoothing\n    smooth_losses = []\n    for i in range(len(losses)):\n        if i < 2 or i >= len(losses) - 2:\n            smooth_losses.append(losses[i])\n        else:\n            smooth_losses.append(sum(losses[i-2:i+3]) / 5)\n    \n    # Calculate gradients\n    gradients = []\n    for i in range(1, len(smooth_losses)):\n        gradients.append((smooth_losses[i] - smooth_losses[i-1]) / (lrs[i] - lrs[i-1]))\n    \n    # Find the point with the steepest negative gradient\n    steepest_idx = np.argmin(gradients)\n    optimal_lr = lrs[steepest_idx + 1] / 10  # Division by 10 is common practice\n    \n    print(f\"Suggested learning rate: {optimal_lr:.2e}\")\n    return optimal_lr\n\n# =============================================================================\n# 11. Evaluation\n# =============================================================================\ndef evaluate_model(model):\n    \"\"\"\n    Evaluate the model on the test set.\n    \n    Args:\n        model: Trained Keras model\n        \n    Returns:\n        Evaluation metrics\n    \"\"\"\n    # Evaluate model\n    loss, accuracy = model.evaluate(test_ds)\n    print(f\"\\nTest Loss: {loss:.4f}\")\n    print(f\"Test Accuracy: {accuracy:.4f}\")\n    \n    # Get predictions\n    predictions = np.argmax(model.predict(test_ds), axis=-1)\n    \n    # Get true labels\n    true_labels = []\n    for _, y in test_ds.unbatch():\n        true_labels.append(np.argmax(y.numpy()))\n    true_labels = np.array(true_labels)\n    \n    # Calculate F1 score\n    f1 = f1_score(true_labels, predictions, average='weighted')\n    print(f\"\\nWeighted F1-Score: {f1:.4f}\")\n    \n    # Print classification report\n    print(\"\\nClassification Report:\")\n    print(classification_report(\n        true_labels, \n        predictions, \n        target_names=classes,\n        zero_division=0\n    ))\n    \n    return {\n        'loss': loss,\n        'accuracy': accuracy,\n        'f1_score': f1,\n        'predictions': predictions,\n        'true_labels': true_labels\n    }\n\n# =============================================================================\n# 12. Fine-tune Model\n# =============================================================================\ndef fine_tune_model(model, epochs=5, custom_callbacks=None, quick_test=False):\n    \"\"\"\n    Fine-tune the model by unfreezing all layers.\n    \n    Args:\n        model: Trained model\n        epochs: Number of fine-tuning epochs\n        custom_callbacks: Additional callbacks to use during fine-tuning\n        quick_test: Whether this is a quick test run\n        \n    Returns:\n        Fine-tuned model and history\n    \"\"\"\n    # Unfreeze all layers\n    for layer in model.layers:\n        layer.trainable = True\n    \n    # Recompile with a lower learning rate\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    \n    # Use custom callbacks if provided, otherwise use default callbacks\n    training_callbacks = custom_callbacks if custom_callbacks else callbacks\n    \n    # Adjust epochs and steps for quick test\n    current_epochs = 2 if quick_test else epochs\n    current_steps = min(20, steps_per_epoch) if quick_test else steps_per_epoch\n    current_val_steps = min(10, validation_steps) if quick_test else validation_steps\n    \n    if quick_test:\n        print(f\"Quick fine-tuning: {current_epochs} epochs, {current_steps} steps/epoch\")\n    \n    # Fine-tune\n    history = model.fit(\n        train_ds,\n        epochs=current_epochs,\n        steps_per_epoch=current_steps,\n        validation_data=val_ds,\n        validation_steps=current_val_steps,\n        callbacks=training_callbacks,\n        class_weight=class_weights,\n        verbose=1\n    )\n    \n    return model, history\n\n# =============================================================================\n# 13. Performance Monitoring\n# =============================================================================\nclass PerformanceMonitor(keras.callbacks.Callback):\n    \"\"\"\n    Monitor and log training performance metrics like time per step.\n    \"\"\"\n    def __init__(self):\n        super(PerformanceMonitor, self).__init__()\n        self.batch_times = []\n        self.epoch_start_time = None\n        \n    def on_epoch_begin(self, epoch, logs=None):\n        self.epoch_start_time = time.time()\n        self.batch_start_time = time.time()\n        self.batch_times = []\n        \n    def on_batch_end(self, batch, logs=None):\n        batch_time = time.time() - self.batch_start_time\n        self.batch_times.append(batch_time)\n        self.batch_start_time = time.time()\n        \n        # Log every 50 batches\n        if batch % 50 == 0:\n            avg_time = sum(self.batch_times[-50:]) / min(50, len(self.batch_times))\n            print(f\"\\nBatch {batch} - Avg time: {avg_time*1000:.2f}ms/step\")\n            \n            # Try to get GPU memory info if available\n            try:\n                import subprocess\n                gpu_info = subprocess.check_output(['nvidia-smi', '--query-gpu=memory.used', '--format=csv,noheader']).decode('utf-8')\n                print(f\"GPU Memory: {gpu_info.strip()}\")\n            except:\n                pass\n        \n    def on_epoch_end(self, epoch, logs=None):\n        epoch_time = time.time() - self.epoch_start_time\n        avg_batch_time = sum(self.batch_times) / len(self.batch_times)\n        print(f\"\\nEpoch {epoch+1} completed in {epoch_time:.2f}s - Avg: {avg_batch_time*1000:.2f}ms/step\")\n\n# =============================================================================\n# 14. Main training loop\n# =============================================================================\ndef main():\n    \"\"\"Main function to run the training pipeline.\"\"\"\n    # Print TF and GPU info\n    print(f\"TensorFlow version: {tf.__version__}\")\n    print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n    \n    # Print dataset info\n    print(f\"Train samples: {len(train_df)} ({len(train_df[train_df['source'] == 'fer2013'])} FER, {len(train_df[train_df['source'] == 'affectnet'])} AffectNet)\")\n    print(f\"Validation samples: {len(val_df)}\")\n    print(f\"Test samples: {len(test_df)}\")\n    print(f\"Classes: {classes}\")\n    print(f\"Steps per epoch: {steps_per_epoch}\")\n    print(f\"Batch size: {BATCH_SIZE}\")\n    \n    # Set to True to run a quick test first, or False for full training\n    run_quick_test = True  # Change this manually if needed\n    \n    if run_quick_test:\n        print(\"\\nRunning quick test (2 epochs with limited steps)...\")\n        # Define variables for testing\n        quick_test_epochs = 2\n        quick_test_steps = min(20, steps_per_epoch)\n        print(f\"Quick test settings: {quick_test_epochs} epochs, {quick_test_steps} steps per epoch\")\n    \n    # Create performance monitor\n    perf_monitor = PerformanceMonitor()\n    \n    # Add performance monitor to callbacks\n    training_callbacks = callbacks + [perf_monitor]\n    \n    try:\n        # Find optimal learning rate (optional)\n        # optimal_lr = find_optimal_lr()\n        \n        # Train model (with quick test if selected)\n        print(\"\\n=== Starting initial training phase ===\")\n        \n        if run_quick_test:\n            # Run a quick test first\n            print(\"\\n=== Running quick test ===\")\n            model, quick_history = train_model(\n                custom_callbacks=training_callbacks,\n                quick_test=True\n            )\n            \n            # After successful quick test, continue with full training\n            print(\"\\n=== Quick test complete, continuing with full training ===\")\n            model, history = train_model(\n                custom_callbacks=training_callbacks,\n                existing_model=model\n            )\n        else:\n            # Full training from the start\n            model, history = train_model(custom_callbacks=training_callbacks)\n            \n            # Evaluate model after initial training\n            print(\"\\n=== Evaluating after initial training ===\")\n            metrics = evaluate_model(model)\n            \n            # Fine-tune model (with quick test mode if enabled)\n            print(\"\\n=== Starting fine-tuning phase ===\")\n            model, ft_history = fine_tune_model(\n                model, \n                epochs=5, \n                custom_callbacks=training_callbacks,\n                quick_test=run_quick_test\n            )\n        \n        # Final evaluation\n        print(\"\\n=== Final evaluation ===\")\n        final_metrics = evaluate_model(model)\n        \n        # Save the final model\n        model.save(\"final_emotion_model.keras\")\n        \n        print(\"\\nTraining complete! Final model saved as 'final_emotion_model.keras'\")\n        \n    except Exception as e:\n        import traceback\n        print(\"\\n*** ERROR DURING TRAINING ***\")\n        print(traceback.format_exc())\n        print(\"\\nDetailed error:\", str(e))\n        \n        # Try to save the model if it exists\n        try:\n            if 'model' in locals():\n                print(\"Attempting to save the model before exiting...\")\n                model.save(\"emergency_save_model.keras\")\n                print(\"Model saved as emergency_save_model.keras\")\n        except Exception as save_error:\n            print(f\"Failed to save model: {save_error}\")\n    \nif __name__ == \"__main__\":\n    import time\n    start_time = time.time()\n    main()\n    total_time = time.time() - start_time\n    print(f\"\\nTotal execution time: {total_time/60:.2f} minutes\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T22:42:26.281033Z","iopub.execute_input":"2025-03-10T22:42:26.281407Z","iopub.status.idle":"2025-03-10T23:28:28.958149Z","shell.execute_reply.started":"2025-03-10T22:42:26.281380Z","shell.execute_reply":"2025-03-10T23:28:28.956816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Version 5.0 orginal working code slightly\n\nimport os\nimport glob\nimport math\nimport numpy as np\nimport pandas as pd\nimport itertools\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport time\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Input\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\n\nimport logging\nlogging.basicConfig(level=logging.INFO)\ntf.get_logger().setLevel(logging.INFO)\n\nimport gc\nclass MemoryCleanup(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        gc.collect()\n        tf.keras.backend.clear_session()\n\n\n# =============================================================================\n# Define key parameters\n# =============================================================================\nimg_size = 96         # We upscale FER images to 96x96\nbatch_size = 64\nepochs = 30\n\n# =============================================================================\n# Learning Rate Finder Callback (Fixed)\n# =============================================================================\nclass LRFinder(tf.keras.callbacks.Callback):\n    def __init__(self, min_lr=1e-6, max_lr=1e-2, steps=100):\n        super(LRFinder, self).__init__()\n        self.min_lr = min_lr\n        self.max_lr = max_lr\n        self.steps = steps\n        self.lrs = []\n        self.losses = []\n        \n    def on_train_begin(self, logs=None):\n        # Use optimizer.learning_rate (compatible with LossScaleOptimizer)\n        self.original_lr = tf.keras.backend.get_value(self.model.optimizer.learning_rate)\n        tf.keras.backend.set_value(self.model.optimizer.learning_rate, self.min_lr)\n        self.optimizer = self.model.optimizer\n    \n    def on_batch_end(self, batch, logs=None):\n        lr = tf.keras.backend.get_value(self.optimizer.learning_rate)\n        self.lrs.append(lr)\n        self.losses.append(logs.get('loss'))\n        new_lr = lr * (self.max_lr / self.min_lr) ** (1/self.steps)\n        tf.keras.backend.set_value(self.optimizer.learning_rate, new_lr)\n        if batch >= self.steps:\n            self.model.stop_training = True\n            \n    def on_train_end(self, logs=None):\n        tf.keras.backend.set_value(self.optimizer.learning_rate, self.original_lr)\n\n# =============================================================================\n# 1. Build a DataFrame from the dataset directory structure\n# =============================================================================\ndef build_image_df(root_dir, subfolders=[\"fer2013\", \"affectnet\"]):\n    \"\"\"\n    Scans the given root directory (Train or Test) and returns a DataFrame with columns:\n      - filepath: full path to the image file\n      - label: the emotion (parent folder name)\n      - source: the subfolder name (e.g., fer2013 or affectnet)\n    Assumes directory structure: root_dir/emotion/subfolder/image.jpg\n    \"\"\"\n    data = []\n    emotions = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n    for emotion in emotions:\n        emotion_path = os.path.join(root_dir, emotion)\n        for sub in subfolders:\n            sub_path = os.path.join(emotion_path, sub)\n            if os.path.exists(sub_path):\n                for img_file in os.listdir(sub_path):\n                    if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n                        data.append({\n                            \"filepath\": os.path.join(sub_path, img_file),\n                            \"label\": emotion,\n                            \"source\": sub\n                        })\n    return pd.DataFrame(data)\n\n# =============================================================================\n# 2. Dataset Paths & DataFrame Creation\n# =============================================================================\ndata_dir = \"/kaggle/input/custom-fer2013affectnet/Custom_ferAffect2013net\"\ntrain_dir = os.path.join(data_dir, \"Train\")   # Case-sensitive!\ntest_dir  = os.path.join(data_dir, \"Test\")\n\ntrain_df_full = build_image_df(train_dir)\ntest_df = build_image_df(test_dir)\n\nprint(\"Train DataFrame shape:\", train_df_full.shape)\nprint(\"Test DataFrame shape:\", test_df.shape)\n\n# Additional Plots: Separate by Source (Optional)\nfer_df = train_df_full[train_df_full[\"source\"] == \"fer2013\"]\naff_df = train_df_full[train_df_full[\"source\"] == \"affectnet\"]\n\nplt.figure(figsize=(14, 6))\nplt.subplot(1, 2, 1)\nsns.countplot(x=\"label\", data=fer_df, palette=\"coolwarm\")\nplt.title(\"FER2013 Training Data Volume\")\nplt.xlabel(\"Emotion Label\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=45)\n\nplt.subplot(1, 2, 2)\nsns.countplot(x=\"label\", data=aff_df, palette=\"Spectral\")\nplt.title(\"AffectNet Training Data Volume\")\nplt.xlabel(\"Emotion Label\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=45)\n\nplt.tight_layout()\nplt.show()\n\n\n# =============================================================================\n# 3. Split Training Data into Train & Validation Sets\n# =============================================================================\ntrain_df, val_df = train_test_split(train_df_full, test_size=0.2, stratify=train_df_full[\"label\"], random_state=42)\n\n# =============================================================================\n# X. Visualization Code for DataFrames\n# =============================================================================\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set Seaborn style for a beautiful design.\nsns.set(style=\"whitegrid\", context=\"talk\", palette=\"viridis\")\n\n# Plot 1: Training Data (Combined by Source)\nplt.figure(figsize=(16, 5))\nplt.subplot(1, 3, 1)\nsns.countplot(x=\"label\", hue=\"source\", data=train_df_full, palette=\"viridis\")\nplt.title(\"Training Data Volume (Combined)\")\nplt.xlabel(\"Emotion Label\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=45)\nplt.legend(title=\"Source\")\n\n# Plot 2: Validation Data (Combined by Source)\nplt.subplot(1, 3, 2)\nif \"source\" in val_df.columns:\n    sns.countplot(x=\"label\", hue=\"source\", data=val_df, palette=\"viridis\")\n    plt.legend(title=\"Source\")\nelse:\n    sns.countplot(x=\"label\", data=val_df, palette=\"viridis\")\nplt.title(\"Validation Data Volume\")\nplt.xlabel(\"Emotion Label\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=45)\n\n# Plot 3: Test Data\nplt.subplot(1, 3, 3)\nif \"source\" in test_df.columns:\n    sns.countplot(x=\"label\", hue=\"source\", data=test_df, palette=\"viridis\")\n    plt.legend(title=\"Source\")\nelse:\n    sns.countplot(x=\"label\", data=test_df, palette=\"viridis\")\nplt.title(\"Test Data Volume\")\nplt.xlabel(\"Emotion Label\")\nplt.ylabel(\"Count\")\nplt.xticks(rotation=45)\n\nplt.tight_layout()\nplt.show()\n\n# =============================================================================\n# 4. Source-Specific Augmentation Functions\n# =============================================================================\ndef apply_fer_augmentations(img):\n    # Gentle augmentations for low-res FER2013 images\n    img = tf.image.random_flip_left_right(img)\n    img = tf.image.random_brightness(img, max_delta=0.1)\n    return img\n\ndef apply_affectnet_augmentations(img):\n    # Stronger augmentations for high-res AffectNet images\n    img = tf.image.random_flip_left_right(img)\n    img = tf.image.random_brightness(img, max_delta=0.3)\n    img = tf.image.random_contrast(img, lower=0.8, upper=1.2)\n    return img\n\ndef augment_based_on_source(img, source):\n    # Source-aware augmentation: assume img is a tensor in [0,1]\n    if source == \"fer2013\":\n        img = tf.image.rgb_to_grayscale(img)  # Ensure it's grayscale\n        img = apply_fer_augmentations(img)\n    else:\n        img = apply_affectnet_augmentations(img)\n    return img\n\n# =============================================================================\n# 5. Create Separate Generators for FER2013 and AffectNet\n# =============================================================================\n# Create a simpler, more robust training loop\n# First, simplify your dataset creation\n\nclasses = sorted(train_df_full[\"label\"].unique())\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255\n    #preprocessing_function=lambda x: np.repeat(x, 3, axis=-1) if x.shape[-1] == 1 else x\n)\n\nsimple_train_gen = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=(img_size, img_size),\n    color_mode=\"rgb\",  # Use rgb for all images to simplify\n    class_mode=\"categorical\",\n    classes=classes,\n    batch_size=16,  # Reduced batch size\n    shuffle=True\n)\n\n# Split the training DataFrame by source\nfer_train_df = train_df[train_df[\"source\"] == \"fer2013\"]\naff_train_df = train_df[train_df[\"source\"] == \"affectnet\"]\n\n# For FER2013: load as grayscale with gentle augmentation.\nfer_aug_params = {\n    \"rescale\": 1./255,\n    \"rotation_range\": 15,\n    \"width_shift_range\": 0.1,\n    \"height_shift_range\": 0.1,\n    \"brightness_range\": [0.8, 1.2]\n}\nfer_datagen = ImageDataGenerator(**fer_aug_params)\nfer_gen = fer_datagen.flow_from_dataframe(\n    dataframe=fer_train_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=(img_size, img_size),\n    color_mode=\"grayscale\",\n    class_mode=\"categorical\",\n    classes=classes,\n    batch_size=64,\n    shuffle=True\n)\n\n# For AffectNet: load as RGB with stronger augmentation.\naff_aug_params = {\n    \"rescale\": 1./255,\n    \"rotation_range\": 30,  # Reduced from 40\n    \"brightness_range\": [0.7, 1.3],  # Reduced from [0.5, 1.5]\n    \"zoom_range\": 0.1  # Reduced from 0.2\n}\naff_datagen = ImageDataGenerator(**aff_aug_params)\naff_gen = aff_datagen.flow_from_dataframe(\n    dataframe=aff_train_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=(img_size, img_size),\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    classes=classes,\n    batch_size=64,\n    shuffle=True\n)\n\n#######################################################################################\n# If your images are grayscale and need to be converted to RGB, add this:\ndef convert_grayscale_to_rgb(batch_x, batch_y):\n    # If the last dimension is 1, repeat it 3 times\n    if batch_x.shape[-1] == 1:\n        batch_x = np.repeat(batch_x, 3, axis=-1)\n    return batch_x, batch_y\n\n# Create a wrapper for your generator\ndef rgb_generator_wrapper(gen):\n    for batch_x, batch_y in gen:\n        yield convert_grayscale_to_rgb(batch_x, batch_y)\n\n# Use the wrapped generator\nrgb_train_gen = rgb_generator_wrapper(simple_train_gen)\n\n#######################################################################################\n\n# Calculate steps for each dataset.\nsteps_fer = math.ceil(len(fer_train_df) / 64)  # 22986/32=719\nsteps_aff = math.ceil(len(aff_train_df) / 64)  # 23209/32=726\nsteps_per_epoch = steps_fer + steps_aff        # 1445\n\n#steps_fer = math.ceil(fer_train_df.shape[0] / 32)\n#steps_aff = math.ceil(aff_train_df.shape[0] / 32)\n#steps_per_epoch = steps_fer + steps_aff\n#print(f\"Steps per epoch: {steps_per_epoch}\")\n\n# After splitting in Section 3:\nprint(f\"Train samples: {len(train_df)}\")  # Should be ~36k (80% of 46k)\nprint(f\"FER samples: {len(fer_train_df)}\")  # ~18k (80% of 23k)\nprint(f\"AffectNet samples: {len(aff_train_df)}\")  # ~18k (80% of 23k)\n\n# =============================================================================\n# 6. Enhanced Upscaling for FER2013: Bicubic interpolation and channel replication.\n# =============================================================================\ndef preprocess_fer_batch(batch):\n    # Input: (batch_size, H, W, 1)\n    upscaled = tf.image.resize(batch, [img_size, img_size], method=\"bicubic\")\n    return tf.repeat(upscaled, repeats=3, axis=-1)  # Now shape: (batch_size, img_size, img_size, 3)\n\n# Wrap the FER generator into a tf.data.Dataset.\ndef fer_gen_wrapper():\n    for batch in fer_gen:\n        images, labels = batch\n        images = tf.convert_to_tensor(images)\n        images = preprocess_fer_batch(images)\n        yield (images, labels)\n\nds_fer = tf.data.Dataset.from_generator(\n    fer_gen_wrapper,\n    output_signature=(\n        tf.TensorSpec(shape=(None, img_size, img_size, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(None, len(fer_gen.class_indices)), dtype=tf.float32)\n    )\n)\n\n# For AffectNet, simply convert batches to tensors.\ndef aff_gen_wrapper():\n    for batch in aff_gen:\n        images, labels = batch\n        images = tf.convert_to_tensor(images)\n        yield (images, labels)\n\nds_aff = tf.data.Dataset.from_generator(\n    aff_gen_wrapper,\n    output_signature=(\n        tf.TensorSpec(shape=(None, img_size, img_size, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(None, len(aff_gen.class_indices)), dtype=tf.float32)\n    )\n)\n\n# =============================================================================\n# 7. Combine the Two Datasets and Optimize Pipeline\n# =============================================================================\n# Both ds_fer and ds_aff already yield batches, so do NOT apply an additional .batch() here.\ncombined_ds = ds_fer.concatenate(ds_aff)\ncombined_ds = combined_ds.shuffle(buffer_size=200).prefetch(2)\n\n#combined_ds = ds_fer.concatenate(ds_aff)\n#combined_ds = combined_ds.shuffle(500).prefetch(tf.data.AUTOTUNE)\n\n# =============================================================================\n# 8. Compute Class Weights\n# =============================================================================\nclass_weights = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.unique(train_df[\"label\"]),\n    y=train_df[\"label\"]\n)\nlabel_to_index = fer_gen.class_indices  # Assumes consistency across sources.\nclass_weights = {label_to_index[label]: weight for label, weight in zip(np.unique(train_df[\"label\"]), class_weights)}\n\n# =============================================================================\n# 9. Model Architecture\n# =============================================================================\n# (Optional) Enable mixed precision\npolicy = tf.keras.mixed_precision.Policy('mixed_float16')\ntf.keras.mixed_precision.set_global_policy(policy)\n\n#from tensorflow.keras.applications import MobileNetV2\n#base_model = MobileNetV2(include_top=False, weights=\"imagenet\", \n#                        input_tensor=input_tensor,\n#                        input_shape=(img_size, img_size, 3))\n\ninput_tensor = Input(shape=(img_size, img_size, 3))\nbase_model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_tensor=input_tensor)\nbase_model.trainable = True\n\nfreeze_until = int(len(base_model.layers) * 0.7)\nfor layer in base_model.layers[:freeze_until]:\n    layer.trainable = False\n\nx = GlobalAveragePooling2D()(base_model.output)\nx = Dropout(0.5)(x)\nx = Dense(256, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01))(x)\nx = Dropout(0.4)(x)\noutput = Dense(len(classes), activation=\"softmax\", dtype=\"float32\")(x)\nmodel = Model(inputs=input_tensor, outputs=output)\n\n# =============================================================================\n# 10. Focal Loss (Optional)\n# =============================================================================\ndef focal_loss(gamma=2.0, alpha=0.25):\n    def loss_fn(y_true, y_pred):\n        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0 - 1e-7)\n        cross_entropy = -y_true * tf.math.log(y_pred)\n        loss = alpha * tf.math.pow(1 - y_pred, gamma) * cross_entropy\n        return tf.reduce_mean(tf.reduce_sum(loss, axis=1))\n    return loss_fn\n\nloss_function = focal_loss()  # Or use \"categorical_crossentropy\"\n\nsimple_model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(len(classes), activation='softmax')\n])\n\nsimple_model.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-4),\n    loss=loss_function, #'categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# =============================================================================\n# 11. Training Configuration & Callbacks\n# =============================================================================\n\ndef cosine_annealing(epoch, lr):\n    initial_lr = 1e-4\n    return initial_lr * (1 + math.cos(math.pi * epoch / epochs)) / 2\n\n# Minimal callback list\nminimal_callbacks = [\n    tf.keras.callbacks.ModelCheckpoint('checkpoint.keras', save_best_only=True),\n    tf.keras.callbacks.CSVLogger('simple_training_log.csv', append=True)\n]\n\n# Create a validation dataset from val_df using a similar pipeline for FER images.\nval_datagen = ImageDataGenerator(rescale=1./255)\nval_generator = val_datagen.flow_from_dataframe(\n    dataframe=val_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=(img_size, img_size),\n    color_mode=\"grayscale\",\n    classes=classes,\n    batch_size=batch_size,\n    shuffle=False\n)\ndef val_gen_wrapper():\n    for batch in val_generator:\n        images, labels = batch\n        images = preprocess_fer_batch(images)\n        yield (images, labels)\n\nds_val = tf.data.Dataset.from_generator(\n    lambda: val_gen_wrapper(),\n    output_signature=(\n        tf.TensorSpec(shape=(None, img_size, img_size, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(None, len(classes)), dtype=tf.float32)\n    )\n).prefetch(tf.data.AUTOTUNE)\n\nstart_time = time.time()\nprint(\"Starting simplified training...\")\nsimple_history = simple_model.fit(\n    simple_train_gen,\n    epochs=2,\n    steps_per_epoch=50,  # Drastically reduced to test\n    validation_data=ds_val, #val_generator,\n    validation_steps=10,  # Also reduced\n    callbacks=minimal_callbacks\n)\nprint(\"Simplified training completed!\")\n\n# Save the trained model\nmodel.save(\"final_emotion_model.keras\")\n\n# =============================================================================\n# 12. Evaluation & Visualization on Test Data\n# =============================================================================\n# First, create a clean test generator without any preprocessing\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    x_col=\"filepath\",\n    y_col=\"label\",\n    target_size=(img_size, img_size),\n    color_mode=\"grayscale\",  # Load as grayscale first\n    class_mode=\"categorical\",\n    classes=classes,\n    batch_size=batch_size,\n    shuffle=False\n)\n\n# Then create a simpler wrapper that ensures exactly 3 channels\ndef test_wrapper():\n    for batch_x, batch_y in test_generator:\n        # Convert grayscale to RGB once - explicitly tracking shape\n        if batch_x.shape[-1] == 1:\n            # This creates exactly 3 channels\n            batch_x_rgb = np.concatenate([batch_x, batch_x, batch_x], axis=-1)\n            yield batch_x_rgb, batch_y\n        else:\n            yield batch_x, batch_y\n\n# Create the dataset with proper output signature\ntest_ds = tf.data.Dataset.from_generator(\n    test_wrapper,\n    output_signature=(\n        tf.TensorSpec(shape=(None, img_size, img_size, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(None, len(classes)), dtype=tf.float32)\n    )\n).batch(batch_size).prefetch(2)\n\n# Now evaluate with this clean dataset\nloss, accuracy = simple_model.evaluate(test_ds)\n\nprint(f\"\\nTest Loss: {loss:.4f}\")\nprint(f\"Test Accuracy: {accuracy:.4f}\")\n\npredictions = np.argmax(simple_model.predict(test_generator), axis=-1)\ntrue_labels = test_generator.classes\n\nprint(f\"\\nWeighted F1-Score: {f1_score(true_labels, predictions, average='weighted'):.4f}\")\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(confusion_matrix(true_labels, predictions), \n            annot=True, fmt=\"d\", \n            cmap=\"Blues\",\n            xticklabels=test_generator.class_indices.keys(),\n            yticklabels=test_generator.class_indices.keys())\nplt.title(\"Confusion Matrix\")\nplt.show()\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(true_labels, predictions, target_names=test_generator.class_indices.keys()))\n\nplt.figure(figsize=(14, 5))\nplt.subplot(1, 2, 1)\nplt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\nplt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\nplt.legend()\nplt.title(\"Accuracy Curves\")\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history[\"loss\"], label=\"Training Loss\")\nplt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\nplt.legend()\nplt.title(\"Loss Curves\")\nplt.show()\n\n# =============================================================================\n# 13. Testing Saved Model on Individual Test Images\n# =============================================================================\nsaved_model = keras.models.load_model(\"final_emotion_model.keras\", compile=False)\nclass_labels = list(test_generator.class_indices.keys())\n\nfor class_name in class_labels:\n    class_path = os.path.join(test_dir, class_name)\n    if os.path.exists(class_path):\n        test_images = os.listdir(class_path)\n        print(f\"\\nTesting images for class: {class_name}\")\n        for img_name in test_images[:5]:\n            img_path = os.path.join(class_path, img_name)\n            # Load as grayscale then convert to RGB.\n            img = keras.preprocessing.image.load_img(img_path, target_size=(img_size, img_size), color_mode=\"grayscale\")\n            img_array = keras.preprocessing.image.img_to_array(img) / 255.0\n            img_array = np.repeat(img_array, 3, axis=-1)\n            img_array = np.expand_dims(img_array, axis=0)\n            \n            prediction = saved_model.predict(img_array)\n            predicted_class = class_labels[np.argmax(prediction)]\n            confidence = np.max(prediction)\n            \n            plt.imshow(img_array[0].astype(\"float32\"))\n            plt.title(f\"Predicted: {predicted_class}\\nConfidence: {confidence:.2f}\")\n            plt.axis(\"off\")\n            plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T21:39:44.181466Z","iopub.execute_input":"2025-03-10T21:39:44.181807Z","iopub.status.idle":"2025-03-10T21:44:00.496987Z","shell.execute_reply.started":"2025-03-10T21:39:44.181778Z","shell.execute_reply":"2025-03-10T21:44:00.495881Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"/kaggle/input/custom-fer2013affectnet/Custom_ferAffect2013net\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-21T06:04:56.087843Z","iopub.execute_input":"2025-01-21T06:04:56.088139Z","iopub.status.idle":"2025-01-21T06:04:56.443115Z","shell.execute_reply.started":"2025-01-21T06:04:56.088111Z","shell.execute_reply":"2025-01-21T06:04:56.442405Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fer_dirs = glob.glob(os.path.join(train_dir, \"*\", \"fer2013\"))\naff_dirs = glob.glob(os.path.join(train_dir, \"*\", \"affectnet\"))\nprint(\"FER directories found:\", glob.glob(os.path.join(train_dir, \"*\", \"fer2013\")))\nprint(\"AffectNet directories found:\", glob.glob(os.path.join(train_dir, \"*\", \"affectnet\")))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T10:53:25.033801Z","iopub.execute_input":"2025-02-01T10:53:25.034111Z","iopub.status.idle":"2025-02-01T10:53:25.061789Z","shell.execute_reply.started":"2025-02-01T10:53:25.034089Z","shell.execute_reply":"2025-02-01T10:53:25.060926Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# NEW Experimental\n\nimport tensorflow.keras.backend as K\nimport os\nimport glob\nimport math\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport time\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score\nfrom tensorflow.keras.applications import EfficientNetB0, MobileNetV3Small\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Input, Concatenate\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.metrics import AUC, Precision, Recall\n\n# =============================================================================\n# Define key parameters\n# =============================================================================\nimg_size = 96         # We upscale FER images to 96x96\nbatch_size = 64       # Smaller batch size to avoid memory issues\nepochs = 20           # Increase epochs, we'll use early stopping\nmodel_type = \"efficientnet\"  # Options: \"efficientnet\", \"mobilenet\", \"ensemble\"\n\n# =============================================================================\n# 1. Build a DataFrame from the dataset directory structure\n# =============================================================================\ndef build_image_df(root_dir, subfolders=[\"fer2013\", \"affectnet\"]):\n    \"\"\"\n    Scans the given root directory (Train or Test) and returns a DataFrame with columns:\n      - filepath: full path to the image file\n      - label: the emotion (parent folder name)\n      - source: the subfolder name (e.g., fer2013 or affectnet)\n    Assumes directory structure: root_dir/emotion/subfolder/image.jpg\n    \"\"\"\n    data = []\n    emotions = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n    for emotion in emotions:\n        emotion_path = os.path.join(root_dir, emotion)\n        for sub in subfolders:\n            sub_path = os.path.join(emotion_path, sub)\n            if os.path.exists(sub_path):\n                for img_file in os.listdir(sub_path):\n                    if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n                        data.append({\n                            \"filepath\": os.path.join(sub_path, img_file),\n                            \"label\": emotion,\n                            \"source\": sub\n                        })\n    return pd.DataFrame(data)\n\n# =============================================================================\n# 2. Dataset Paths & DataFrame Creation\n# =============================================================================\n# Adjust this path to your actual data directory\ndata_dir = \"/kaggle/input/custom-fer2013affectnet/Custom_ferAffect2013net\"\ntrain_dir = os.path.join(data_dir, \"Train\")\ntest_dir  = os.path.join(data_dir, \"Test\")\n\ntrain_df_full = build_image_df(train_dir)\ntest_df = build_image_df(test_dir)\n\nprint(\"Train DataFrame shape:\", train_df_full.shape)\nprint(\"Test DataFrame shape:\", test_df.shape)\n\n# =============================================================================\n# 3. Split Training Data into Train & Validation Sets\n# =============================================================================\ntrain_df, val_df = train_test_split(train_df_full, test_size=0.2, stratify=train_df_full[\"label\"], random_state=42)\n\n# =============================================================================\n# 4. Data Visualization (Optional)\n# =============================================================================\ndef plot_data_distribution():\n    # Plot distribution of emotions by source\n    plt.figure(figsize=(16, 6))\n    \n    # Combined\n    plt.subplot(1, 3, 1)\n    sns.countplot(x=\"label\", data=train_df_full, palette=\"viridis\")\n    plt.title(\"Full Dataset Distribution\")\n    plt.xlabel(\"Emotion\")\n    plt.ylabel(\"Count\")\n    plt.xticks(rotation=45)\n    \n    # FER2013\n    plt.subplot(1, 3, 2)\n    sns.countplot(x=\"label\", data=train_df_full[train_df_full[\"source\"] == \"fer2013\"], palette=\"coolwarm\")\n    plt.title(\"FER2013 Distribution\")\n    plt.xlabel(\"Emotion\")\n    plt.ylabel(\"Count\")\n    plt.xticks(rotation=45)\n    \n    # AffectNet\n    plt.subplot(1, 3, 3)\n    sns.countplot(x=\"label\", data=train_df_full[train_df_full[\"source\"] == \"affectnet\"], palette=\"Spectral\")\n    plt.title(\"AffectNet Distribution\")\n    plt.xlabel(\"Emotion\")\n    plt.ylabel(\"Count\")\n    plt.xticks(rotation=45)\n    \n    plt.tight_layout()\n    plt.show()\n\n# Uncomment to visualize data distribution\n# plot_data_distribution()\n\n# =============================================================================\n# 5. Optimized Data Generators\n# =============================================================================\n# Get emotion classes\nclasses = sorted(train_df_full[\"label\"].unique())\nprint(f\"Classes: {classes}\")\n\n# Define preprocessing functions\ndef preprocess_fer(img):\n    \"\"\"Convert grayscale to RGB and resize to target size\"\"\"\n    # Convert to 3 channels by repeating the grayscale channel\n    img = tf.image.grayscale_to_rgb(img)\n    # Resize to target size\n    img = tf.image.resize(img, [img_size, img_size], method='bicubic')\n    return img / 255.0  # Normalize\n\ndef preprocess_affectnet(img):\n    \"\"\"Resize RGB image to target size\"\"\"\n    img = tf.image.resize(img, [img_size, img_size])\n    return img / 255.0  # Normalize\n\n# Create training data generators\ndef create_generators():\n    # Common augmentation parameters\n    common_aug = {\n        'horizontal_flip': True,\n        'rotation_range': 20,\n        'fill_mode': 'nearest'\n    }\n    \n    # For FER2013 (grayscale)\n    fer_datagen = ImageDataGenerator(\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        zoom_range=0.1,\n        brightness_range=[0.8, 1.2],\n        **common_aug\n    )\n    \n    fer_train_gen = fer_datagen.flow_from_dataframe(\n        dataframe=train_df[train_df[\"source\"] == \"fer2013\"],\n        x_col=\"filepath\",\n        y_col=\"label\",\n        target_size=(img_size, img_size),\n        color_mode=\"grayscale\",\n        class_mode=\"categorical\",\n        classes=classes,\n        batch_size=batch_size,\n        shuffle=True\n    )\n    \n    # For AffectNet (RGB)\n    aff_datagen = ImageDataGenerator(\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        zoom_range=0.2,\n        brightness_range=[0.7, 1.3],\n        **common_aug\n    )\n    \n    aff_train_gen = aff_datagen.flow_from_dataframe(\n        dataframe=train_df[train_df[\"source\"] == \"affectnet\"],\n        x_col=\"filepath\",\n        y_col=\"label\",\n        target_size=(img_size, img_size),\n        color_mode=\"rgb\",\n        class_mode=\"categorical\",\n        classes=classes,\n        batch_size=batch_size,\n        shuffle=True\n    )\n    \n    # Validation generators - no augmentation\n    val_datagen = ImageDataGenerator()\n    \n    fer_val_gen = val_datagen.flow_from_dataframe(\n        dataframe=val_df[val_df[\"source\"] == \"fer2013\"],\n        x_col=\"filepath\",\n        y_col=\"label\",\n        target_size=(img_size, img_size),\n        color_mode=\"grayscale\",\n        class_mode=\"categorical\",\n        classes=classes,\n        batch_size=batch_size,\n        shuffle=False\n    )\n    \n    aff_val_gen = val_datagen.flow_from_dataframe(\n        dataframe=val_df[val_df[\"source\"] == \"affectnet\"],\n        x_col=\"filepath\",\n        y_col=\"label\",\n        target_size=(img_size, img_size),\n        color_mode=\"rgb\",\n        class_mode=\"categorical\",\n        classes=classes,\n        batch_size=batch_size,\n        shuffle=False\n    )\n    \n    return fer_train_gen, aff_train_gen, fer_val_gen, aff_val_gen\n\n# Create test generator\ndef create_test_generator():\n    test_datagen = ImageDataGenerator()\n    \n    # Split test data by source\n    fer_test_df = test_df[test_df[\"source\"] == \"fer2013\"]\n    aff_test_df = test_df[test_df[\"source\"] == \"affectnet\"]\n    \n    fer_test_gen = test_datagen.flow_from_dataframe(\n        dataframe=fer_test_df,\n        x_col=\"filepath\",\n        y_col=\"label\",\n        target_size=(img_size, img_size),\n        color_mode=\"grayscale\",\n        class_mode=\"categorical\",\n        classes=classes,\n        batch_size=batch_size,\n        shuffle=False\n    )\n    \n    aff_test_gen = test_datagen.flow_from_dataframe(\n        dataframe=aff_test_df,\n        x_col=\"filepath\",\n        y_col=\"label\",\n        target_size=(img_size, img_size),\n        color_mode=\"rgb\",\n        class_mode=\"categorical\",\n        classes=classes,\n        batch_size=batch_size,\n        shuffle=False\n    )\n    \n    return fer_test_gen, aff_test_gen\n\nfer_train_gen, aff_train_gen, fer_val_gen, aff_val_gen = create_generators()\nfer_test_gen, aff_test_gen = create_test_generator()\n\n# =============================================================================\n# 6. Custom Data Generator that combines both sources\n# =============================================================================\nclass CombinedGenerator:\n    def __init__(self, fer_gen, aff_gen, batch_size=32):\n        self.fer_gen = fer_gen\n        self.aff_gen = aff_gen\n        self.batch_size = batch_size\n        self.n_classes = len(classes)\n        self.fer_samples = len(fer_gen.filenames)\n        self.aff_samples = len(aff_gen.filenames)\n        self.total_samples = self.fer_samples + self.aff_samples\n        \n    def __len__(self):\n        return (self.total_samples + self.batch_size - 1) // self.batch_size\n    \n    def __iter__(self):\n        self.fer_iter = iter(self.fer_gen)\n        self.aff_iter = iter(self.aff_gen)\n        return self\n    \n    def __next__(self):\n        # Randomly choose which generator to pull from based on dataset size ratio\n        if np.random.random() < self.fer_samples / self.total_samples:\n            try:\n                batch_x, batch_y = next(self.fer_iter)\n                # Convert grayscale to RGB\n                if batch_x.shape[-1] == 1:\n                    batch_x = np.repeat(batch_x, 3, axis=-1)\n                return batch_x, batch_y\n            except StopIteration:\n                self.fer_iter = iter(self.fer_gen)\n                return next(self)\n        else:\n            try:\n                return next(self.aff_iter)\n            except StopIteration:\n                self.aff_iter = iter(self.aff_gen)\n                return next(self)\n\n# Create combined generators\ntrain_gen = CombinedGenerator(fer_train_gen, aff_train_gen, batch_size)\nval_gen = CombinedGenerator(fer_val_gen, aff_val_gen, batch_size)\ntest_gen = CombinedGenerator(fer_test_gen, aff_test_gen, batch_size)\n\n# =============================================================================\n# 7. Compute Class Weights for imbalanced dataset\n# =============================================================================\ndef compute_class_weights(train_df):\n    # Compute balanced class weights\n    class_weights = compute_class_weight(\n        class_weight=\"balanced\",\n        classes=np.unique(train_df[\"label\"]),\n        y=train_df[\"label\"]\n    )\n    \n    # Map class names to indices\n    label_to_index = {label: i for i, label in enumerate(classes)}\n    \n    # Create dictionary of class weights\n    weights_dict = {label_to_index[label]: weight \n                    for label, weight in zip(np.unique(train_df[\"label\"]), class_weights)}\n    \n    return weights_dict\n\nclass_weights = compute_class_weights(train_df)\nprint(\"Class weights:\", class_weights)\n\n# =============================================================================\n# 8. Model Architecture\n# =============================================================================\ndef create_model(model_type=\"efficientnet\"):\n    input_tensor = Input(shape=(img_size, img_size, 3))\n    \n    if model_type == \"efficientnet\":\n        # EfficientNetB0 without any extra preprocessing\n        base_model = EfficientNetB0(\n            include_top=False, \n            weights=\"imagenet\", \n            input_tensor=input_tensor\n        )\n        # Freeze early layers\n        for layer in base_model.layers[:100]:\n            layer.trainable = False\n        \n        x = base_model.output\n        \n    elif model_type == \"mobilenet\":\n        # MobileNetV3Small\n        base_model = MobileNetV3Small(\n            include_top=False, \n            weights=\"imagenet\", \n            input_tensor=input_tensor\n        )\n        # Freeze early layers\n        for layer in base_model.layers[:50]:\n            layer.trainable = False\n        \n        x = base_model.output\n        \n    elif model_type == \"ensemble\":\n        # Use both models\n        efficient_base = EfficientNetB0(\n            include_top=False, \n            weights=\"imagenet\", \n            input_tensor=input_tensor\n        )\n        mobile_base = MobileNetV3Small(\n            include_top=False, \n            weights=\"imagenet\", \n            input_tensor=input_tensor\n        )\n        \n        # Freeze early layers\n        for layer in efficient_base.layers[:100]:\n            layer.trainable = False\n        for layer in mobile_base.layers[:50]:\n            layer.trainable = False\n        \n        # Global pooling for both models\n        efficient_features = GlobalAveragePooling2D()(efficient_base.output)\n        mobile_features = GlobalAveragePooling2D()(mobile_base.output)\n        \n        # Concatenate features\n        x = Concatenate()([efficient_features, mobile_features])\n    else:\n        raise ValueError(f\"Unknown model type: {model_type}\")\n    \n    # Common head for all models\n    if model_type != \"ensemble\":\n        x = GlobalAveragePooling2D()(x)\n    \n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    \n    x = Dense(256, activation=\"relu\")(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.3)(x)\n    \n    # Output layer\n    outputs = Dense(len(classes), activation=\"softmax\")(x)\n    \n    model = Model(inputs=input_tensor, outputs=outputs)\n\n    # Compile model with a fixed learning rate\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-4, clipnorm=1.0),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    \n    return model\n\n# Simplify model to verify training works\nsimple_model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(len(classes), activation='softmax')\n])\n\nsimple_model.compile(\n    optimizer=tf.keras.optimizers.Adam(1e-4),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# =============================================================================\n# 9. Training with callbacks\n# =============================================================================\n\ncheckpoint_path = os.path.join(\"checkpoints\", f\"{model_type}_emotion_model.keras\")\nos.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n\ndef train_model(model, train_generator, val_generator, epochs=20, class_weights=None):\n    # Better learning rate schedule\n    steps_per_epoch = len(train_generator)\n    lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n        initial_learning_rate=1e-3,\n        decay_steps=steps_per_epoch * epochs,\n        alpha=1e-5\n    )\n\n    # Update the model's optimizer with the new learning rate schedule\n    model.optimizer.learning_rate = lr_schedule  # Direct assignment\n\n    checkpoint_path_keras = checkpoint_path + \".keras\"\n\n    # Callbacks\n    callbacks = [\n        # Save best model\n        ModelCheckpoint(\n            checkpoint_path,\n            save_weights_only=False,\n            monitor=\"val_accuracy\",\n            save_best_only=True,\n            verbose=1\n        ),\n        # Early stopping\n        EarlyStopping(\n            monitor=\"val_accuracy\",\n            patience=7,\n            restore_best_weights=True,\n            verbose=1\n        ),\n        # Reduce learning rate when plateau\n        ReduceLROnPlateau(\n            monitor=\"val_loss\",\n            factor=0.5,\n            patience=3,\n            min_lr=1e-6,\n            verbose=1\n        )\n    ]\n\n    # Calculate steps per epoch and validation steps\n    steps_per_epoch = len(train_generator)\n    validation_steps = len(val_generator)\n\n    print(f\"Steps per epoch: {steps_per_epoch}\")\n    print(f\"Validation steps: {validation_steps}\")\n\n    # Train model\n    start_time = time.time()\n    try:\n        history = model.fit(\n            train_generator,\n            epochs=epochs,\n            steps_per_epoch=steps_per_epoch,\n            validation_data=val_generator,\n            validation_steps=validation_steps,\n            class_weight=class_weights,\n            callbacks=callbacks,\n            verbose=1\n        )\n    except Exception as e:\n        print(f\"Training error: {str(e)}\")\n        return None\n    training_time = time.time() - start_time\n    print(f\"Training completed in {training_time:.2f} seconds\")\n    return history\n\n# =============================================================================\n# 10. Evaluation\n# =============================================================================\ndef evaluate_model(model, test_generator):\n    # Calculate steps for test data\n    test_steps = len(test_generator)\n    \n    # Evaluate model\n    test_loss, test_acc = model.evaluate(test_generator, steps=test_steps)\n    print(f\"Test Loss: {test_loss:.4f}\")\n    print(f\"Test Accuracy: {test_acc:.4f}\")\n    \n    # Get predictions\n    y_pred_probs = model.predict(test_generator, steps=test_steps)\n    y_pred = np.argmax(y_pred_probs, axis=1)\n    \n    # Get true labels\n    y_true = []\n    for i in range(test_steps):\n        try:\n            _, batch_y = next(iter(test_generator))\n            y_true.extend(np.argmax(batch_y, axis=1))\n        except StopIteration:\n            break\n    \n    # Limit to same size\n    y_true = y_true[:len(y_pred)]\n    \n    # Print classification report\n    print(\"\\nClassification Report:\")\n    print(classification_report(\n        y_true, \n        y_pred, \n        target_names=classes\n    ))\n    \n    # Plot confusion matrix\n    plt.figure(figsize=(10, 8))\n    cm = confusion_matrix(y_true, y_pred)\n    sns.heatmap(\n        cm, \n        annot=True, \n        fmt=\"d\", \n        cmap=\"Blues\",\n        xticklabels=classes,\n        yticklabels=classes\n    )\n    plt.title(\"Confusion Matrix\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.tight_layout()\n    plt.show()\n    \n    return y_true, y_pred\n\n# =============================================================================\n# 11. Visualization Functions\n# =============================================================================\ndef plot_training_history(history):\n    plt.figure(figsize=(12, 5))\n    \n    # Plot accuracy\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'], label='Training')\n    plt.plot(history.history['val_accuracy'], label='Validation')\n    plt.title('Model Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    # Plot loss\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'], label='Training')\n    plt.plot(history.history['val_loss'], label='Validation')\n    plt.title('Model Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()\n\n# =============================================================================\n# 12. Test on sample images\n# =============================================================================\ndef test_on_samples(model, num_samples=3):\n    plt.figure(figsize=(16, 12))\n    \n    # Get sample images from each class\n    for i, emotion in enumerate(classes):\n        # Get sample paths\n        sample_paths = []\n        fer_samples = test_df[(test_df['label'] == emotion) & (test_df['source'] == 'fer2013')]['filepath'].values\n        aff_samples = test_df[(test_df['label'] == emotion) & (test_df['source'] == 'affectnet')]['filepath'].values\n        \n        if len(fer_samples) > 0:\n            sample_paths.append(fer_samples[0])\n        if len(aff_samples) > 0:\n            sample_paths.append(aff_samples[0])\n        \n        # Limit to num_samples\n        sample_paths = sample_paths[:num_samples]\n        \n        for j, img_path in enumerate(sample_paths):\n            # Load and preprocess image\n            color_mode = 'grayscale' if 'fer2013' in img_path else 'rgb'\n            img = keras.preprocessing.image.load_img(\n                img_path, \n                target_size=(img_size, img_size),\n                color_mode=color_mode\n            )\n            img_array = keras.preprocessing.image.img_to_array(img) / 255.0\n            \n            # Convert grayscale to RGB if needed\n            if img_array.shape[-1] == 1:\n                img_array = np.repeat(img_array, 3, axis=-1)\n            \n            # Add batch dimension\n            img_batch = np.expand_dims(img_array, axis=0)\n            \n            # Predict\n            predictions = model.predict(img_batch)\n            predicted_class = classes[np.argmax(predictions[0])]\n            confidence = np.max(predictions[0]) * 100\n            \n            # Plot\n            plt_idx = i * num_samples + j + 1\n            if plt_idx <= num_samples * len(classes):\n                plt.subplot(len(classes), num_samples, plt_idx)\n                plt.imshow(img_array)\n                plt.title(f\"True: {emotion}\\nPred: {predicted_class}\\nConf: {confidence:.1f}%\")\n                plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n# =============================================================================\n# MAIN EXECUTION\n# =============================================================================\ndef main():\n    # Debug information\n    print(\"Starting main function\")\n    print(f\"Model type: {model_type}\")\n    \n    try:\n        # Create and train model\n        model = create_model(model_type)\n        print(f\"Created {model_type} model\")\n    \n        # Print model summary\n        model.summary()\n    \n        # Train model\n        history = train_model(\n            model, \n            train_gen, \n            val_gen, \n            epochs=epochs, \n            class_weights=class_weights\n        )\n    \n        # Plot training history\n        plot_training_history(history)\n        \n        # Evaluate model\n        y_true, y_pred = evaluate_model(model, test_gen)\n        \n        # Test on sample images\n        test_on_samples(model)\n        \n        # Save final model\n        model.save(f\"final_{model_type}_emotion_model.keras\")\n        print(f\"Model saved as final_{model_type}_emotion_model.keras\")\n        \n        return model, history\n        \n    except Exception as e:\n        print(f\"Error in main function: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n        return None, None\n\nif __name__ == \"__main__\":\n    # Set random seeds for reproducibility\n    np.random.seed(42)\n    tf.random.set_seed(42)\n    \n    # Mixed precision for faster training\n    try:\n        policy = tf.keras.mixed_precision.Policy('mixed_float16')\n        tf.keras.mixed_precision.set_global_policy(policy)\n        print(\"Using mixed precision\")\n    except:\n        print(\"Mixed precision not available\")\n    \n    # Train model\n    model, history = main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T05:28:38.296917Z","iopub.execute_input":"2025-03-05T05:28:38.297226Z","iopub.status.idle":"2025-03-05T05:29:36.161782Z","shell.execute_reply.started":"2025-03-05T05:28:38.297203Z","shell.execute_reply":"2025-03-05T05:29:36.160926Z"}},"outputs":[],"execution_count":null}]}