{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMzFZNNlbnczNUDBs6m1EF0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f99ad818f2c34204a88c3e1db02949b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b1560a2fbde46a6b443be7f4b205237",
              "IPY_MODEL_1c3a3dd807864da98b0a982dadb2d4a2"
            ],
            "layout": "IPY_MODEL_9e4713a3fca04e23a5432a8f9f8331e8"
          }
        },
        "8b1560a2fbde46a6b443be7f4b205237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Document Path:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_39189604307545eb8869df7bb4eca79b",
            "placeholder": "​",
            "style": "IPY_MODEL_84f67e75cb194538a801016f5c3e2638",
            "value": "/content/drive/MyDrive/RAGDocuments"
          }
        },
        "1c3a3dd807864da98b0a982dadb2d4a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "Load Documents",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_56353f3751d94f02aca691149fd0540e",
            "style": "IPY_MODEL_e2f7007073c342228317e97256c65a63",
            "tooltip": ""
          }
        },
        "9e4713a3fca04e23a5432a8f9f8331e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39189604307545eb8869df7bb4eca79b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "80%"
          }
        },
        "84f67e75cb194538a801016f5c3e2638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "56353f3751d94f02aca691149fd0540e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "30%"
          }
        },
        "e2f7007073c342228317e97256c65a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "c5a7fc34f04c4a24a0166721e935abc0": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_18346f09ca7b48b89c5844e718407604",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Loading documents from: /content/drive/MyDrive/RAGDocuments\n",
                  "Found 1 documents to process\n",
                  "Processing: Psychology And Law Truthfulness,accuracy And Credibility 2nd Ed - Amina Memon.pdf\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "  ✓ Loaded 239 pages/sections\n",
                  "Split 239 documents into 939 chunks\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Creating new Chroma database in /content/drive/MyDrive/RAGVectorDB\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Note: Using Chroma DB which now auto-persists data\n",
                  "✅ System ready for questions!\n"
                ]
              }
            ]
          }
        },
        "18346f09ca7b48b89c5844e718407604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid #ddd",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5a57eb022fc475f9da97b12c171d2fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79518f6298664f1bb3bbca9e97f94d9e",
              "IPY_MODEL_fb2b184007df41d2b19a4d7224903b70",
              "IPY_MODEL_e3d58bc39ee849b8a3b09a3d5e30ebbd"
            ],
            "layout": "IPY_MODEL_faa1d1a783084325976c1e850c8eaad6"
          }
        },
        "79518f6298664f1bb3bbca9e97f94d9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Question:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_42812bbf8f024bb9b8c9d79f1b4ae935",
            "placeholder": "Ask a question about your documents...",
            "style": "IPY_MODEL_df1bfb2d8f564b4eb3ff60d797ac4603",
            "value": ""
          }
        },
        "fb2b184007df41d2b19a4d7224903b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Ask",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_c9b1b9b1952446709f9a3f190091e118",
            "style": "IPY_MODEL_e2f401023d6c4f1fadc8d2a2ed67c064",
            "tooltip": ""
          }
        },
        "e3d58bc39ee849b8a3b09a3d5e30ebbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "warning",
            "description": "Reset Chat",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_b300499e67934696a60b66d4cb433670",
            "style": "IPY_MODEL_211b530f8c994708898e77e7b63b7c74",
            "tooltip": ""
          }
        },
        "faa1d1a783084325976c1e850c8eaad6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42812bbf8f024bb9b8c9d79f1b4ae935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "80%"
          }
        },
        "df1bfb2d8f564b4eb3ff60d797ac4603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "c9b1b9b1952446709f9a3f190091e118": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20%"
          }
        },
        "e2f401023d6c4f1fadc8d2a2ed67c064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "b300499e67934696a60b66d4cb433670": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20%"
          }
        },
        "211b530f8c994708898e77e7b63b7c74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "5b6c9d30cf6948ec88acf9e0463ac19e": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_9e1dbc673c4245fda50dae4fbb339106",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Q: summarize topic of TELLING AND DETECTING LIES\n",
                  "\n",
                  "A: Based on the provided text, the document sections cover \"Detecting Lies\" and \"Difficulties and Pitfalls for Lie Detectors.\"  A \"Summary and Conclusion\" section is also mentioned.  However, no details about the content of these sections are given.\n",
                  "\n",
                  "Sources: Psychology And Law Truthfulness,accuracy And Credibility 2nd Ed - Amina Memon.pdf\n"
                ]
              }
            ]
          }
        },
        "9e1dbc673c4245fda50dae4fbb339106": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid #ddd",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q langchain langchain_google_genai langchain_community unstructured pdf2image pytesseract pdfminer.six python-docx chromadb sentence-transformers google-generativeai ipywidgets faiss-cpu\n",
        "\n",
        "# Fix deprecation warning for HuggingFaceEmbeddings\n",
        "!pip install -q langchain-huggingface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "E8c7_nyQl1vQ",
        "outputId": "089a0752-b56e-4c46-de0e-36b6321baa29"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.4/415.4 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.8/166.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tempfile\n",
        "import shutil\n",
        "import re\n",
        "import glob\n",
        "from typing import List, Dict, Any, Tuple\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import uuid\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Access Colab secrets\n",
        "from google.colab import userdata\n",
        "\n",
        "# For document processing\n",
        "from langchain_community.document_loaders import (\n",
        "    PyPDFLoader,\n",
        "    TextLoader,\n",
        "    Docx2txtLoader,\n",
        "    UnstructuredFileLoader\n",
        ")\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# For embeddings and vector DB\n",
        "import chromadb\n",
        "from langchain_community.vectorstores import Chroma, FAISS\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# For generative AI model\n",
        "import google.generativeai as genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain"
      ],
      "metadata": {
        "id": "whmPXuRyloef"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a65EE3TTl-H_",
        "outputId": "e14b950a-efa1-483f-f33e-ffdd87d217ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== CONFIGURATION =====\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration parameters for the application.\"\"\"\n",
        "\n",
        "    # Paths\n",
        "    DOC_DIR = \"/content/drive/MyDrive/RAGDocuments\"  # Directory containing documents\n",
        "    DB_DIR = \"/content/drive/MyDrive/RAGVectorDB\"    # Directory to store vector database\n",
        "\n",
        "    # Document processing\n",
        "    CHUNK_SIZE = 1000\n",
        "    CHUNK_OVERLAP = 200\n",
        "\n",
        "    # Vector DB\n",
        "    EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"  # HF model for embeddings\n",
        "\n",
        "    # Retrieval parameters\n",
        "    TOP_K_RETRIEVAL = 4  # Number of chunks to retrieve for context\n",
        "\n",
        "    # Security - will be loaded from environment variables\n",
        "    HF_TOKEN = None\n",
        "    GENAI_API_KEY = None\n",
        "\n",
        "# ===== SECURE KEY MANAGEMENT =====\n",
        "\n",
        "def setup_api_keys() -> None:\n",
        "    \"\"\"Securely set up API keys from environment variables or Colab secrets.\"\"\"\n",
        "\n",
        "    # For Hugging Face\n",
        "    try:\n",
        "        # Check if already set\n",
        "        import huggingface_hub\n",
        "\n",
        "        # Try Colab userdata first\n",
        "        try:\n",
        "            hf_token = userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "            huggingface_hub.HfFolder.save_token(hf_token)\n",
        "            Config.HF_TOKEN = hf_token\n",
        "            print(\"✅ Hugging Face token configured from Colab secrets\")\n",
        "        except:\n",
        "            # Fallback to environment variables\n",
        "            hf_token = os.environ.get('HUGGINGFACEHUB_API_TOKEN', '') or os.environ.get('HF_TOKEN', '')\n",
        "            if hf_token:\n",
        "                huggingface_hub.HfFolder.save_token(hf_token)\n",
        "                Config.HF_TOKEN = hf_token\n",
        "                print(\"✅ Hugging Face token configured from environment\")\n",
        "            else:\n",
        "                print(\"⚠️ Hugging Face token not found\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Hugging Face token not configured: {e}\")\n",
        "\n",
        "    # For Google Genai\n",
        "    try:\n",
        "        # Try Colab userdata first\n",
        "        try:\n",
        "            gemini_key = userdata.get('GEMINI_API_KEY')\n",
        "            Config.GENAI_API_KEY = gemini_key\n",
        "            genai.configure(api_key=gemini_key)\n",
        "            print(\"✅ Gemini API key configured from Colab secrets\")\n",
        "        except:\n",
        "            # Fallback to environment variables\n",
        "            gemini_key = os.environ.get('GEMINI_API_KEY', '') or os.environ.get('GENAI_API_KEY', '')\n",
        "            if gemini_key:\n",
        "                Config.GENAI_API_KEY = gemini_key\n",
        "                genai.configure(api_key=gemini_key)\n",
        "                print(\"✅ Gemini API key configured from environment\")\n",
        "            else:\n",
        "                print(\"⚠️ Gemini API key not set\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error configuring Gemini API: {e}\")\n",
        "\n",
        "# Prompt user to input API keys if not found in environment\n",
        "def request_api_keys() -> None:\n",
        "    \"\"\"Request API keys from user if not found in environment variables.\"\"\"\n",
        "\n",
        "    print(\"\\n==== Secure API Key Configuration ====\")\n",
        "    print(\"API keys will be stored in environment variables for this session only.\")\n",
        "\n",
        "    if not Config.HF_TOKEN:\n",
        "        hf_token = input(\"Enter your Hugging Face API token (or press Enter to skip): \")\n",
        "        if hf_token:\n",
        "            os.environ['HUGGINGFACEHUB_API_TOKEN'] = hf_token\n",
        "            Config.HF_TOKEN = hf_token\n",
        "            import huggingface_hub\n",
        "            huggingface_hub.HfFolder.save_token(hf_token)\n",
        "            print(\"✅ Hugging Face token set\")\n",
        "\n",
        "    if not Config.GENAI_API_KEY:\n",
        "        genai_key = input(\"Enter your Google Generative AI API key: \")\n",
        "        if genai_key:\n",
        "            os.environ['GEMINI_API_KEY'] = genai_key\n",
        "            Config.GENAI_API_KEY = genai_key\n",
        "            genai.configure(api_key=genai_key)\n",
        "            print(\"✅ Gemini API key set\")\n",
        "\n",
        "# ===== DOCUMENT PROCESSING MODULE =====\n",
        "\n",
        "class DocumentProcessor:\n",
        "    \"\"\"Handle document ingestion, parsing, and chunking.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_loader_for_file(file_path: str):\n",
        "        \"\"\"Return the appropriate loader based on file extension.\"\"\"\n",
        "        file_extension = file_path.split('.')[-1].lower()\n",
        "\n",
        "        try:\n",
        "            if file_extension == 'pdf':\n",
        "                return PyPDFLoader(file_path)\n",
        "            elif file_extension == 'txt':\n",
        "                return TextLoader(file_path)\n",
        "            elif file_extension in ['docx', 'doc']:\n",
        "                return Docx2txtLoader(file_path)\n",
        "            else:\n",
        "                # Fallback to unstructured for other file types\n",
        "                return UnstructuredFileLoader(file_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating loader for {file_path}: {e}\")\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def load_documents(directory: str) -> Tuple[List[Any], List[str]]:\n",
        "        \"\"\"\n",
        "        Load all supported documents from a directory.\n",
        "\n",
        "        Args:\n",
        "            directory: Path to directory containing documents\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (loaded documents, list of failed files)\n",
        "        \"\"\"\n",
        "        documents = []\n",
        "        failed_files = []\n",
        "\n",
        "        # Check if directory exists\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "            print(f\"Created document directory: {directory}\")\n",
        "            return documents, failed_files\n",
        "\n",
        "        # Get all files with supported extensions\n",
        "        file_pattern = os.path.join(directory, \"**\")\n",
        "        all_files = []\n",
        "\n",
        "        for ext in ['pdf', 'txt', 'docx', 'doc']:\n",
        "            all_files.extend(glob.glob(f\"{file_pattern}/*.{ext}\", recursive=True))\n",
        "\n",
        "        if not all_files:\n",
        "            print(f\"No supported documents found in {directory}\")\n",
        "            return documents, failed_files\n",
        "\n",
        "        print(f\"Found {len(all_files)} documents to process\")\n",
        "\n",
        "        # Process each file\n",
        "        for file_path in all_files:\n",
        "            try:\n",
        "                print(f\"Processing: {os.path.basename(file_path)}\")\n",
        "                loader = DocumentProcessor.get_loader_for_file(file_path)\n",
        "\n",
        "                if loader:\n",
        "                    file_docs = loader.load()\n",
        "                    # Add source metadata if not present\n",
        "                    for doc in file_docs:\n",
        "                        if 'source' not in doc.metadata:\n",
        "                            doc.metadata['source'] = file_path\n",
        "                    documents.extend(file_docs)\n",
        "                    print(f\"  ✓ Loaded {len(file_docs)} pages/sections\")\n",
        "                else:\n",
        "                    failed_files.append(file_path)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ✗ Failed to load {file_path}: {e}\")\n",
        "                failed_files.append(file_path)\n",
        "\n",
        "        return documents, failed_files\n",
        "\n",
        "    @staticmethod\n",
        "    def chunk_documents(documents: List[Any], chunk_size: int = 1000, chunk_overlap: int = 200) -> List[Any]:\n",
        "        \"\"\"\n",
        "        Split documents into chunks for processing.\n",
        "\n",
        "        Args:\n",
        "            documents: List of LangChain document objects\n",
        "            chunk_size: Maximum size of each chunk\n",
        "            chunk_overlap: Overlap between chunks\n",
        "\n",
        "        Returns:\n",
        "            List of document chunks\n",
        "        \"\"\"\n",
        "        if not documents:\n",
        "            return []\n",
        "\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=chunk_size,\n",
        "            chunk_overlap=chunk_overlap,\n",
        "            length_function=len,\n",
        "            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        "        )\n",
        "\n",
        "        chunks = text_splitter.split_documents(documents)\n",
        "        print(f\"Split {len(documents)} documents into {len(chunks)} chunks\")\n",
        "\n",
        "        return chunks\n",
        "\n",
        "# ===== VECTOR DATABASE MODULE =====\n",
        "\n",
        "class VectorDBManager:\n",
        "    \"\"\"Manage vector database operations including embedding and storage.\"\"\"\n",
        "\n",
        "    def __init__(self, embedding_model_name: str = Config.EMBEDDING_MODEL, persist_dir: str = Config.DB_DIR):\n",
        "        \"\"\"\n",
        "        Initialize the vector database manager.\n",
        "\n",
        "        Args:\n",
        "            embedding_model_name: Name of the HuggingFace embedding model\n",
        "            persist_dir: Directory to persist the vector database\n",
        "        \"\"\"\n",
        "        self.persist_dir = persist_dir\n",
        "\n",
        "        # Create embeddings model\n",
        "        self.embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=embedding_model_name,\n",
        "            cache_folder=\"/tmp/hf_cache\"\n",
        "        )\n",
        "\n",
        "        # Ensure persistence directory exists\n",
        "        os.makedirs(persist_dir, exist_ok=True)\n",
        "\n",
        "    def create_or_load_db(self, document_chunks: List[Any], db_type: str = \"chroma\") -> Any:\n",
        "        \"\"\"\n",
        "        Create a new vector database or load existing one.\n",
        "\n",
        "        Args:\n",
        "            document_chunks: List of document chunks to embed\n",
        "            db_type: Type of vector database (\"chroma\" or \"faiss\")\n",
        "\n",
        "        Returns:\n",
        "            Vector database instance\n",
        "        \"\"\"\n",
        "        if not document_chunks and not os.path.exists(os.path.join(self.persist_dir, 'index')):\n",
        "            raise ValueError(\"Cannot create database: No documents provided and no existing DB found\")\n",
        "\n",
        "        if db_type.lower() == \"chroma\":\n",
        "            # Check if database already exists\n",
        "            if os.path.exists(os.path.join(self.persist_dir, 'index')):\n",
        "                print(f\"Loading existing Chroma database from {self.persist_dir}\")\n",
        "                return Chroma(\n",
        "                    persist_directory=self.persist_dir,\n",
        "                    embedding_function=self.embeddings\n",
        "                )\n",
        "            else:\n",
        "                print(f\"Creating new Chroma database in {self.persist_dir}\")\n",
        "                db = Chroma.from_documents(\n",
        "                    documents=document_chunks,\n",
        "                    embedding=self.embeddings,\n",
        "                    persist_directory=self.persist_dir\n",
        "                )\n",
        "                # DB is auto-persisted since Chroma 0.4.x\n",
        "                return db\n",
        "\n",
        "        elif db_type.lower() == \"faiss\":\n",
        "            index_file = os.path.join(self.persist_dir, \"faiss_index\")\n",
        "\n",
        "            if os.path.exists(index_file):\n",
        "                print(f\"Loading existing FAISS database from {index_file}\")\n",
        "                return FAISS.load_local(\n",
        "                    folder_path=self.persist_dir,\n",
        "                    embeddings=self.embeddings,\n",
        "                    index_name=\"faiss_index\"\n",
        "                )\n",
        "            else:\n",
        "                print(f\"Creating new FAISS database in {self.persist_dir}\")\n",
        "                db = FAISS.from_documents(\n",
        "                    documents=document_chunks,\n",
        "                    embedding=self.embeddings\n",
        "                )\n",
        "                db.save_local(self.persist_dir, index_name=\"faiss_index\")\n",
        "                return db\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported vector database type: {db_type}\")\n",
        "\n",
        "# ===== RAG AGENT MODULE =====\n",
        "\n",
        "class RAGAgent:\n",
        "    \"\"\"Implement the RAG pipeline with retrieval and generation capabilities.\"\"\"\n",
        "\n",
        "    def __init__(self, vector_db: Any, api_key: str = None):\n",
        "        \"\"\"\n",
        "        Initialize the RAG agent.\n",
        "\n",
        "        Args:\n",
        "            vector_db: Vector database for retrieval\n",
        "            api_key: Google Generative AI API key\n",
        "        \"\"\"\n",
        "        self.vector_db = vector_db\n",
        "\n",
        "        # Configure the Gemini model\n",
        "        if api_key:\n",
        "            genai.configure(api_key=api_key)\n",
        "\n",
        "        # Create the LLM using the approach confirmed to work\n",
        "        self.llm = ChatGoogleGenerativeAI(\n",
        "            model=\"gemini-1.5-flash\",  # Use the free tier model that's working\n",
        "            temperature=0.3,\n",
        "            top_p=0.95,\n",
        "            google_api_key=api_key,  # Explicitly pass the API key\n",
        "            convert_system_message_to_human=True\n",
        "        )\n",
        "\n",
        "        # Set up the retriever\n",
        "        self.retriever = vector_db.as_retriever(\n",
        "            search_type=\"similarity\",\n",
        "            search_kwargs={\"k\": Config.TOP_K_RETRIEVAL}\n",
        "        )\n",
        "\n",
        "        # Create conversation memory\n",
        "        self.memory = ConversationBufferMemory(\n",
        "            memory_key=\"chat_history\",\n",
        "            return_messages=True,\n",
        "            output_key=\"answer\"  # Explicitly set the output key\n",
        "        )\n",
        "\n",
        "    def create_qa_chain(self) -> Any:\n",
        "        \"\"\"\n",
        "        Create a conversational QA chain with RAG capabilities.\n",
        "\n",
        "        Returns:\n",
        "            Conversational retrieval chain\n",
        "        \"\"\"\n",
        "        # Custom prompt template for RAG\n",
        "        prompt_template = \"\"\"\n",
        "        You are a helpful assistant answering questions based on retrieved document content.\n",
        "\n",
        "        CONTEXT INFORMATION:\n",
        "        {context}\n",
        "\n",
        "        CHAT HISTORY:\n",
        "        {chat_history}\n",
        "\n",
        "        QUESTION:\n",
        "        {question}\n",
        "\n",
        "        YOUR RESPONSE:\n",
        "        Answer the question based ONLY on the provided context. If the context doesn't contain\n",
        "        relevant information, say \"I don't have enough information to answer this question.\"\n",
        "\n",
        "        When answering, cite the source document names in your response.\n",
        "        Follow the KISS principle (Keep It Simple, Stupid) and provide clear, concise answers.\n",
        "        \"\"\"\n",
        "\n",
        "        PROMPT = PromptTemplate(\n",
        "            template=prompt_template,\n",
        "            input_variables=[\"context\", \"chat_history\", \"question\"]\n",
        "        )\n",
        "\n",
        "        # Create the conversational chain with explicit output_key\n",
        "        chain = ConversationalRetrievalChain.from_llm(\n",
        "            llm=self.llm,\n",
        "            retriever=self.retriever,\n",
        "            memory=self.memory,\n",
        "            combine_docs_chain_kwargs={\"prompt\": PROMPT},\n",
        "            return_source_documents=True,\n",
        "            output_key=\"answer\",  # Explicitly set the output key\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        return chain\n",
        "\n",
        "    def answer_question(self, question: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Answer a question using the RAG pipeline.\n",
        "\n",
        "        Args:\n",
        "            question: User's question\n",
        "\n",
        "        Returns:\n",
        "            Dict with answer and source documents\n",
        "        \"\"\"\n",
        "        chain = self.create_qa_chain()\n",
        "\n",
        "        try:\n",
        "            # Use the chain to answer the question\n",
        "            result = chain.invoke({\"question\": question})\n",
        "\n",
        "            # Extract answer and sources\n",
        "            answer = result.get(\"answer\", \"\")\n",
        "\n",
        "            # Extract source information\n",
        "            sources = []\n",
        "            if \"source_documents\" in result:\n",
        "                for doc in result[\"source_documents\"]:\n",
        "                    if \"source\" in doc.metadata:\n",
        "                        source_path = doc.metadata[\"source\"]\n",
        "                        source_name = os.path.basename(source_path)\n",
        "                        sources.append(source_name)\n",
        "\n",
        "            return {\n",
        "                \"answer\": answer,\n",
        "                \"sources\": list(set(sources))  # Deduplicate sources\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error generating answer: {str(e)}\"\n",
        "            print(error_msg)\n",
        "            return {\n",
        "                \"answer\": \"I encountered an error while trying to answer your question. Please try again.\",\n",
        "                \"error\": error_msg,\n",
        "                \"sources\": []\n",
        "            }\n",
        "\n",
        "    def reset_memory(self) -> None:\n",
        "        \"\"\"Reset the conversation memory.\"\"\"\n",
        "        self.memory.clear()\n",
        "\n",
        "# ===== USER INTERFACE MODULE =====\n",
        "\n",
        "class RAGUI:\n",
        "    \"\"\"User interface for the RAG application.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the UI components.\"\"\"\n",
        "        self.rag_agent = None\n",
        "        self.document_processor = None\n",
        "        self.vector_db_manager = None\n",
        "        self.vector_db = None\n",
        "\n",
        "        # UI components\n",
        "        self.doc_path_input = widgets.Text(\n",
        "            value=Config.DOC_DIR,\n",
        "            description='Document Path:',\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='80%')\n",
        "        )\n",
        "\n",
        "        self.load_docs_button = widgets.Button(\n",
        "            description='Load Documents',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='30%')\n",
        "        )\n",
        "        self.load_docs_button.on_click(self.load_documents_callback)\n",
        "\n",
        "        self.status_output = widgets.Output(layout={'border': '1px solid #ddd'})\n",
        "\n",
        "        self.question_input = widgets.Text(\n",
        "            value='',\n",
        "            placeholder='Ask a question about your documents...',\n",
        "            description='Question:',\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='80%'),\n",
        "            disabled=True\n",
        "        )\n",
        "        self.question_input.on_submit(self.answer_question_callback)\n",
        "\n",
        "        self.ask_button = widgets.Button(\n",
        "            description='Ask',\n",
        "            button_style='success',\n",
        "            layout=widgets.Layout(width='20%'),\n",
        "            disabled=True\n",
        "        )\n",
        "        self.ask_button.on_click(self.answer_question_callback)\n",
        "\n",
        "        self.reset_chat_button = widgets.Button(\n",
        "            description='Reset Chat',\n",
        "            button_style='warning',\n",
        "            layout=widgets.Layout(width='20%'),\n",
        "            disabled=True\n",
        "        )\n",
        "        self.reset_chat_button.on_click(self.reset_chat_callback)\n",
        "\n",
        "        self.answer_output = widgets.Output(layout={'border': '1px solid #ddd'})\n",
        "\n",
        "    def display_ui(self) -> None:\n",
        "        \"\"\"Display the complete UI.\"\"\"\n",
        "        # First check and request API keys\n",
        "        setup_api_keys()\n",
        "        if not Config.HF_TOKEN or not Config.GENAI_API_KEY:\n",
        "            request_api_keys()\n",
        "\n",
        "        # App title\n",
        "        display(HTML(\"<h1>RAG-Powered Document Q&A System</h1>\"))\n",
        "\n",
        "        # Document loading section\n",
        "        display(HTML(\"<h2>1. Document Processing</h2>\"))\n",
        "        display(widgets.HBox([self.doc_path_input, self.load_docs_button]))\n",
        "        display(self.status_output)\n",
        "\n",
        "        # Q&A section\n",
        "        display(HTML(\"<h2>2. Ask Questions</h2>\"))\n",
        "        display(widgets.HBox([self.question_input, self.ask_button, self.reset_chat_button]))\n",
        "        display(self.answer_output)\n",
        "\n",
        "        # Display initial status\n",
        "        with self.status_output:\n",
        "            print(\"Status: Ready to load documents\")\n",
        "            print(f\"Document directory: {Config.DOC_DIR}\")\n",
        "            print(f\"Vector DB directory: {Config.DB_DIR}\")\n",
        "            if os.path.exists(os.path.join(Config.DB_DIR, 'index')):\n",
        "                print(\"An existing vector database was found and will be used if no new documents are loaded.\")\n",
        "\n",
        "    def load_documents_callback(self, button) -> None:\n",
        "        \"\"\"Callback for document loading button.\"\"\"\n",
        "        with self.status_output:\n",
        "            clear_output()\n",
        "            print(f\"Loading documents from: {self.doc_path_input.value}\")\n",
        "\n",
        "            try:\n",
        "                # Update document directory in config\n",
        "                Config.DOC_DIR = self.doc_path_input.value\n",
        "\n",
        "                # Initialize document processor\n",
        "                self.document_processor = DocumentProcessor()\n",
        "\n",
        "                # Load documents\n",
        "                documents, failed_files = self.document_processor.load_documents(Config.DOC_DIR)\n",
        "\n",
        "                if not documents:\n",
        "                    print(\"⚠️ No documents were loaded successfully. Please check the document directory.\")\n",
        "                    if failed_files:\n",
        "                        print(f\"Failed files: {', '.join([os.path.basename(f) for f in failed_files])}\")\n",
        "                    return\n",
        "\n",
        "                # Chunk documents\n",
        "                document_chunks = self.document_processor.chunk_documents(\n",
        "                    documents,\n",
        "                    chunk_size=Config.CHUNK_SIZE,\n",
        "                    chunk_overlap=Config.CHUNK_OVERLAP\n",
        "                )\n",
        "\n",
        "                # Initialize vector database\n",
        "                self.vector_db_manager = VectorDBManager(\n",
        "                    embedding_model_name=Config.EMBEDDING_MODEL,\n",
        "                    persist_dir=Config.DB_DIR\n",
        "                )\n",
        "\n",
        "                # Create or load vector database\n",
        "                self.vector_db = self.vector_db_manager.create_or_load_db(document_chunks)\n",
        "\n",
        "                # Fix persistence warning\n",
        "                if hasattr(self.vector_db, 'persist'):\n",
        "                    print(\"Note: Using Chroma DB which now auto-persists data\")\n",
        "\n",
        "                # Initialize RAG agent\n",
        "                self.rag_agent = RAGAgent(self.vector_db, api_key=Config.GENAI_API_KEY)\n",
        "\n",
        "                # Enable Q&A components\n",
        "                self.question_input.disabled = False\n",
        "                self.ask_button.disabled = False\n",
        "                self.reset_chat_button.disabled = False\n",
        "\n",
        "                print(\"✅ System ready for questions!\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error during document processing: {str(e)}\")\n",
        "\n",
        "    def answer_question_callback(self, widget) -> None:\n",
        "        \"\"\"Callback for question answering.\"\"\"\n",
        "        question = self.question_input.value\n",
        "\n",
        "        if not question.strip():\n",
        "            return\n",
        "\n",
        "        with self.answer_output:\n",
        "            clear_output()\n",
        "            print(f\"Q: {question}\")\n",
        "            print(\"Thinking...\")\n",
        "\n",
        "            if self.rag_agent:\n",
        "                try:\n",
        "                    result = self.rag_agent.answer_question(question)\n",
        "\n",
        "                    clear_output()\n",
        "                    print(f\"Q: {question}\")\n",
        "                    print(f\"\\nA: {result['answer']}\")\n",
        "\n",
        "                    if result.get('sources'):\n",
        "                        print(f\"\\nSources: {', '.join(result['sources'])}\")\n",
        "\n",
        "                    if result.get('error'):\n",
        "                        print(f\"\\nError details: {result['error']}\")\n",
        "                except Exception as e:\n",
        "                    clear_output()\n",
        "                    print(f\"Q: {question}\")\n",
        "                    print(f\"\\nA: I encountered an error while trying to answer your question.\")\n",
        "                    print(f\"\\nError details: {str(e)}\")\n",
        "            else:\n",
        "                print(\"❌ System not initialized. Please load documents first.\")\n",
        "\n",
        "        # Clear the question input\n",
        "        self.question_input.value = ''\n",
        "\n",
        "    def reset_chat_callback(self, button) -> None:\n",
        "        \"\"\"Callback to reset the chat history.\"\"\"\n",
        "        if self.rag_agent:\n",
        "            self.rag_agent.reset_memory()\n",
        "\n",
        "            with self.answer_output:\n",
        "                clear_output()\n",
        "                print(\"Chat history has been reset.\")\n",
        "\n",
        "# ===== MAIN APPLICATION =====\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main entry point for the application.\"\"\"\n",
        "    print(\"Starting RAG-Powered Document Q&A System...\")\n",
        "\n",
        "    # Debug - print environment variables (without showing key values)\n",
        "    print(\"\\nChecking for environment variables:\")\n",
        "    for env_var in ['HUGGINGFACEHUB_API_TOKEN', 'HF_TOKEN', 'GEMINI_API_KEY', 'GENAI_API_KEY']:\n",
        "        if env_var in os.environ:\n",
        "            print(f\"  ✓ {env_var} is set\")\n",
        "        else:\n",
        "            print(f\"  ✗ {env_var} is not set\")\n",
        "\n",
        "    # Create and display UI\n",
        "    ui = RAGUI()\n",
        "    ui.display_ui()\n",
        "\n",
        "# Run the application\n",
        "main()\n",
        "\n",
        "# ===== EXAMPLE USAGE =====\n",
        "\n",
        "\"\"\"\n",
        "# Example Test Queries\n",
        "\n",
        "Once you've loaded your documents, try these example queries:\n",
        "\n",
        "1. Basic information retrieval:\n",
        "   \"What are the main topics covered in these documents?\"\n",
        "\n",
        "2. Specific information retrieval:\n",
        "   \"What does [specific document] say about [specific topic]?\"\n",
        "\n",
        "3. Comparative analysis:\n",
        "   \"Compare how different documents approach [topic].\"\n",
        "\n",
        "4. Follow-up questions:\n",
        "   \"Tell me more about [something mentioned in previous answer].\"\n",
        "\n",
        "# Customization Options\n",
        "\n",
        "To customize this RAG application:\n",
        "\n",
        "1. Change embedding model:\n",
        "   - Modify Config.EMBEDDING_MODEL to use different HuggingFace models\n",
        "   - Options include \"sentence-transformers/all-mpnet-base-v2\" (higher quality but slower)\n",
        "\n",
        "2. Adjust chunking parameters:\n",
        "   - Increase/decrease Config.CHUNK_SIZE based on document complexity\n",
        "   - Adjust Config.CHUNK_OVERLAP to control context preservation\n",
        "\n",
        "3. Tune retrieval parameters:\n",
        "   - Change Config.TOP_K_RETRIEVAL to get more or fewer context chunks\n",
        "\n",
        "4. Switch vector database:\n",
        "   - Pass \"faiss\" instead of \"chroma\" to VectorDBManager.create_or_load_db()\n",
        "\n",
        "5. Modify LLM parameters:\n",
        "   - Adjust temperature, top_p in RAGAgent.__init__() for different generation styles\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755,
          "referenced_widgets": [
            "f99ad818f2c34204a88c3e1db02949b8",
            "8b1560a2fbde46a6b443be7f4b205237",
            "1c3a3dd807864da98b0a982dadb2d4a2",
            "9e4713a3fca04e23a5432a8f9f8331e8",
            "39189604307545eb8869df7bb4eca79b",
            "84f67e75cb194538a801016f5c3e2638",
            "56353f3751d94f02aca691149fd0540e",
            "e2f7007073c342228317e97256c65a63",
            "c5a7fc34f04c4a24a0166721e935abc0",
            "18346f09ca7b48b89c5844e718407604",
            "a5a57eb022fc475f9da97b12c171d2fe",
            "79518f6298664f1bb3bbca9e97f94d9e",
            "fb2b184007df41d2b19a4d7224903b70",
            "e3d58bc39ee849b8a3b09a3d5e30ebbd",
            "faa1d1a783084325976c1e850c8eaad6",
            "42812bbf8f024bb9b8c9d79f1b4ae935",
            "df1bfb2d8f564b4eb3ff60d797ac4603",
            "c9b1b9b1952446709f9a3f190091e118",
            "e2f401023d6c4f1fadc8d2a2ed67c064",
            "b300499e67934696a60b66d4cb433670",
            "211b530f8c994708898e77e7b63b7c74",
            "5b6c9d30cf6948ec88acf9e0463ac19e",
            "9e1dbc673c4245fda50dae4fbb339106"
          ]
        },
        "id": "Bx3_grE_JsNW",
        "outputId": "3d73911b-1347-47b6-bcc5-ceafb2c7a30f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting RAG-Powered Document Q&A System...\n",
            "\n",
            "Checking for environment variables:\n",
            "  ✗ HUGGINGFACEHUB_API_TOKEN is not set\n",
            "  ✗ HF_TOKEN is not set\n",
            "  ✗ GEMINI_API_KEY is not set\n",
            "  ✗ GENAI_API_KEY is not set\n",
            "✅ Hugging Face token configured from Colab secrets\n",
            "✅ Gemini API key configured from Colab secrets\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>RAG-Powered Document Q&A System</h1>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h2>1. Document Processing</h2>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Text(value='/content/drive/MyDrive/RAGDocuments', description='Document Path:', layout=Layout(w…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f99ad818f2c34204a88c3e1db02949b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output(layout=Layout(border='1px solid #ddd'))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5a7fc34f04c4a24a0166721e935abc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h2>2. Ask Questions</h2>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Text(value='', description='Question:', disabled=True, layout=Layout(width='80%'), placeholder=…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5a57eb022fc475f9da97b12c171d2fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output(layout=Layout(border='1px solid #ddd'))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b6c9d30cf6948ec88acf9e0463ac19e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Example Test Queries\\n\\nOnce you\\'ve loaded your documents, try these example queries:\\n\\n1. Basic information retrieval:\\n   \"What are the main topics covered in these documents?\"\\n\\n2. Specific information retrieval:\\n   \"What does [specific document] say about [specific topic]?\"\\n\\n3. Comparative analysis:\\n   \"Compare how different documents approach [topic].\"\\n\\n4. Follow-up questions:\\n   \"Tell me more about [something mentioned in previous answer].\"\\n\\n# Customization Options\\n\\nTo customize this RAG application:\\n\\n1. Change embedding model:\\n   - Modify Config.EMBEDDING_MODEL to use different HuggingFace models\\n   - Options include \"sentence-transformers/all-mpnet-base-v2\" (higher quality but slower)\\n\\n2. Adjust chunking parameters:\\n   - Increase/decrease Config.CHUNK_SIZE based on document complexity\\n   - Adjust Config.CHUNK_OVERLAP to control context preservation\\n\\n3. Tune retrieval parameters:\\n   - Change Config.TOP_K_RETRIEVAL to get more or fewer context chunks\\n\\n4. Switch vector database:\\n   - Pass \"faiss\" instead of \"chroma\" to VectorDBManager.create_or_load_db()\\n\\n5. Modify LLM parameters:\\n   - Adjust temperature, top_p in RAGAgent.__init__() for different generation styles\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}