{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNNkEcYmv1cZXxLyK8P99bE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6099e8bc57264383803bc3055edb1757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df915b47c1d04864ae4648f10d6c7908",
              "IPY_MODEL_2f14bceac44547159907ad29b36deff1"
            ],
            "layout": "IPY_MODEL_932abf1180d84b1aad436530ce704b03"
          }
        },
        "df915b47c1d04864ae4648f10d6c7908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Document Path:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_c89144318f144110a2a547f0ab0cadc1",
            "placeholder": "​",
            "style": "IPY_MODEL_59dc70cc7f1749d7bc2ecca89dd17524",
            "value": "/content/drive/MyDrive/RAGDocuments"
          }
        },
        "2f14bceac44547159907ad29b36deff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "primary",
            "description": "Load Documents",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_d57d799be9a646ed808cfdfbe437b62a",
            "style": "IPY_MODEL_59f64adf45e3413fb7b40de8f9e381c1",
            "tooltip": ""
          }
        },
        "932abf1180d84b1aad436530ce704b03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c89144318f144110a2a547f0ab0cadc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "40%"
          }
        },
        "59dc70cc7f1749d7bc2ecca89dd17524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "d57d799be9a646ed808cfdfbe437b62a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "10%"
          }
        },
        "59f64adf45e3413fb7b40de8f9e381c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3b7c0acc93814ea993f1720b742226a8": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_17777cb9321f4c02998ec824894e41c3",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Loading documents from: /content/drive/MyDrive/RAGDocuments\n",
                  "Found 1 documents to process\n",
                  "Processing: Deep Learning with Python.pdf\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "  ✓ Loaded 504 pages/sections\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Split 504 documents into 3272 chunks using adaptive chunking strategy\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Creating new Chroma database in /content/drive/MyDrive/RAGVectorDB\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Note: Using Chroma DB which now auto-persists data\n",
                  "✅ System ready for questions!\n"
                ]
              }
            ]
          }
        },
        "17777cb9321f4c02998ec824894e41c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid #ddd",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33127b92629d4df5bb1af68b079e748b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b29346ed04d455b967be7b2fc59af8d",
              "IPY_MODEL_e50dcbb7259c487181a1d2f010d6cde7",
              "IPY_MODEL_321aed7f12094d1db5cd9da1937e2219"
            ],
            "layout": "IPY_MODEL_88343724a44b4e998efad25779438dc8"
          }
        },
        "1b29346ed04d455b967be7b2fc59af8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Question:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_3231f320d01c4779a70dae4a6edbed55",
            "placeholder": "Ask a question about your documents...",
            "style": "IPY_MODEL_c3d7a168692b45f1a97bfd0fa2e55544",
            "value": ""
          }
        },
        "e50dcbb7259c487181a1d2f010d6cde7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Ask",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_d448c89b981a41ae90a118c92d781063",
            "style": "IPY_MODEL_453d2b05ea2c475a83b8dc263c8024ec",
            "tooltip": ""
          }
        },
        "321aed7f12094d1db5cd9da1937e2219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "warning",
            "description": "Reset Chat",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_2250ab7de3234675b76873b29f068a8f",
            "style": "IPY_MODEL_a2596b39dddb4cfdb8add6d78281db03",
            "tooltip": ""
          }
        },
        "88343724a44b4e998efad25779438dc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3231f320d01c4779a70dae4a6edbed55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "40%"
          }
        },
        "c3d7a168692b45f1a97bfd0fa2e55544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "initial"
          }
        },
        "d448c89b981a41ae90a118c92d781063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "5%"
          }
        },
        "453d2b05ea2c475a83b8dc263c8024ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "2250ab7de3234675b76873b29f068a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "5%"
          }
        },
        "a2596b39dddb4cfdb8add6d78281db03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "7ab66d9184fa4bbd86fcceec30a257ee": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_49723774080d4b0f958994e6d7348db3",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Q: what is the history of deep learning?\n",
                  "\n",
                  "A: Based on \"Chapter 1 What is deep learning?\", the history of modern deep learning is a co-evolution of hardware, software, and algorithms.  The availability of NVIDIA GPUs and CUDA enabled the success of backpropagation-trained convolutional neural networks (convnets).  This success led NVIDIA to further optimize its hardware and software for these algorithms, consolidating the research community around these methods.  However, even with early successes, deep learning's mainstream adoption was delayed by years due to skepticism from the computer vision community, which was invested in other methods.  By 2013-2014, this skepticism remained intense.\n",
                  "\n",
                  "Sources: Deep Learning with Python.pdf\n"
                ]
              }
            ]
          }
        },
        "49723774080d4b0f958994e6d7348db3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid #ddd",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Document Q&A System\n",
        "\n",
        "## Features\n",
        "- Document ingestion (`PDF`/`TXT`/`DOCX`)\n",
        "- Vector database management (`Chroma`/`FAISS`)\n",
        "- Gemini-powered conversational Q&A\n",
        "- Context-aware responses with source citations"
      ],
      "metadata": {
        "id": "G7-T0CinsJ-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# packages\n",
        "!pip install -q langchain langchain_google_genai langchain_community unstructured pdf2image pytesseract pdfminer.six python-docx chromadb sentence-transformers google-generativeai ipywidgets faiss-cpu\n",
        "!pip install -U langchain-unstructured\n",
        "# HuggingFaceEmbeddings\n",
        "!pip install -q langchain-huggingface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "E8c7_nyQl1vQ",
        "outputId": "d0394339-cfc9-4f9d-ce6f-9e1a8f7de38b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m415.4/415.4 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.8/166.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langchain-unstructured\n",
            "  Downloading langchain_unstructured-0.1.6-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain-unstructured) (0.3.43)\n",
            "Collecting onnxruntime<=1.19.2,>=1.17.0 (from langchain-unstructured)\n",
            "  Downloading onnxruntime-1.19.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: unstructured-client<1,>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from langchain-unstructured) (0.31.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.3.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2.10.6)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (25.2.10)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (1.26.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (1.13.1)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (24.1.0)\n",
            "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.11/dist-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (43.0.3)\n",
            "Requirement already satisfied: eval-type-backport>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (0.2.2)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (1.6.0)\n",
            "Requirement already satisfied: pypdf>=4.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (5.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (2.8.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (1.0.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client<1,>=0.27.0->langchain-unstructured) (0.4.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.1->unstructured-client<1,>=0.27.0->langchain-unstructured) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain-unstructured) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain-unstructured) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain-unstructured) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain-unstructured) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain-unstructured) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2.32.3)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->unstructured-client<1,>=0.27.0->langchain-unstructured) (1.17.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client<1,>=0.27.0->langchain-unstructured) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.6->langchain-unstructured) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->unstructured-client<1,>=0.27.0->langchain-unstructured) (1.3.1)\n",
            "Downloading langchain_unstructured-0.1.6-py3-none-any.whl (7.0 kB)\n",
            "Downloading onnxruntime-1.19.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnxruntime, langchain-unstructured\n",
            "  Attempting uninstall: onnxruntime\n",
            "    Found existing installation: onnxruntime 1.21.0\n",
            "    Uninstalling onnxruntime-1.21.0:\n",
            "      Successfully uninstalled onnxruntime-1.21.0\n",
            "Successfully installed langchain-unstructured-0.1.6 onnxruntime-1.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import tempfile\n",
        "import shutil\n",
        "import re\n",
        "import glob\n",
        "from typing import List, Dict, Any, Tuple, Optional, Union\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import uuid\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Access Colab secrets\n",
        "from google.colab import userdata\n",
        "\n",
        "# For document processing\n",
        "from langchain_community.document_loaders import (\n",
        "    PyPDFLoader,\n",
        "    TextLoader,\n",
        "    Docx2txtLoader\n",
        ")\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_unstructured import UnstructuredLoader\n",
        "# For embeddings and vector DB\n",
        "import chromadb\n",
        "from langchain_community.vectorstores import Chroma, FAISS\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# For generative AI model\n",
        "import google.generativeai as genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain"
      ],
      "metadata": {
        "id": "whmPXuRyloef"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a65EE3TTl-H_",
        "outputId": "5df3ff17-8260-4cdc-81ec-ee53066cbb83"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIG\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Central configuration for the RAG system.\n",
        "\n",
        "    Attributes:\n",
        "        DOC_DIR: Path to document storage (supports PDF/TXT/DOCX)\n",
        "        CHUNK_SIZE: Target token count per document chunk (default=1000)\n",
        "        CHUNK_OVERLAP: Overlap between chunks to preserve context (default=200)\n",
        "        EMBEDDING_MODEL: Sentence-transformers model for semantic encoding\n",
        "    \"\"\"\n",
        "\n",
        "    # Paths\n",
        "    DOC_DIR = \"/content/drive/MyDrive/RAGDocuments\"  # Directory containing documents\n",
        "    DB_DIR = \"/content/drive/MyDrive/RAGVectorDB\"    # Directory to store vector database\n",
        "\n",
        "    # Document processing\n",
        "    CHUNK_SIZES = {\n",
        "        \"technical\": 500,\n",
        "        \"narrative\": 1500,\n",
        "    }\n",
        "    DEFAULT_CHUNK_SIZE = 1000  # Fallback value\n",
        "    CHUNK_OVERLAP = max(200, int(DEFAULT_CHUNK_SIZE * 0.25))\n",
        "    TOP_K_RETRIEVAL = max(3, int(1000 / DEFAULT_CHUNK_SIZE * 4))\n",
        "\n",
        "    # Vector DB\n",
        "    EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"  # sentence-transformers/all-mpnet-base-v2 # sentence-transformers/all-MiniLM-L6-v2\n",
        "\n",
        "    # Security - will be loaded from environment variables\n",
        "    HF_TOKEN = None\n",
        "    GENAI_API_KEY = None"
      ],
      "metadata": {
        "id": "tdziAuFJuzUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##xXx## Check model's max token length (set parameters accordingly)\n",
        "#from sentence_transformers import SentenceTransformer\n",
        "#model = SentenceTransformer(Config.EMBEDDING_MODEL)\n",
        "#max_tokens = model.get_max_seq_length()\n",
        "#print(f\"Max tokens for {Config.EMBEDDING_MODEL}: {max_tokens}\")\n",
        "# Adjust chunk size accordingly\n",
        "#CHUNKY = min(500, max_tokens - 25)  # Leave buffer for special tokens\n",
        "#note we need to measure embeding model max dimension to manage collection accordily\n",
        "#Max tokens for sentence-transformers/all-MiniLM-L6-v2: 256\n",
        "#Max tokens for sentence-transformers/all-mpnet-base-v2: 384"
      ],
      "metadata": {
        "id": "1SlcBAtU-z5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SECURE KEY MANAGEMENT\n",
        "\n",
        "def setup_api_keys() -> None:\n",
        "    \"\"\"Securely set up API keys from environment variables or Colab secrets.\"\"\"\n",
        "\n",
        "    # For Hugging Face\n",
        "    try:\n",
        "        # Check if already set\n",
        "        import huggingface_hub\n",
        "\n",
        "        # Try Colab userdata first\n",
        "        try:\n",
        "            hf_token = userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "            huggingface_hub.HfFolder.save_token(hf_token)\n",
        "            Config.HF_TOKEN = hf_token\n",
        "            print(\"✅ Hugging Face token synced with Colab secrets\")\n",
        "        except:\n",
        "            # Fallback to environment variables\n",
        "            hf_token = os.environ.get('HUGGINGFACEHUB_API_TOKEN', '') or os.environ.get('HF_TOKEN', '')\n",
        "            if hf_token:\n",
        "                huggingface_hub.HfFolder.save_token(hf_token)\n",
        "                Config.HF_TOKEN = hf_token\n",
        "                print(\"✅ Hugging Face token configured from environment\")\n",
        "            else:\n",
        "                print(\"⚠️ Hugging Face token not found\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Hugging Face token not configured: {e}\")\n",
        "\n",
        "    # For Google Genai\n",
        "    try:\n",
        "        # Try Colab userdata first\n",
        "        try:\n",
        "            gemini_key = userdata.get('GEMINI_API_KEY')\n",
        "            Config.GENAI_API_KEY = gemini_key\n",
        "            genai.configure(api_key=gemini_key)\n",
        "            print(\"✅ Gemini API key synced with Colab secrets\")\n",
        "        except:\n",
        "            # Fallback to environment variables\n",
        "            gemini_key = os.environ.get('GEMINI_API_KEY', '') or os.environ.get('GENAI_API_KEY', '')\n",
        "            if gemini_key:\n",
        "                Config.GENAI_API_KEY = gemini_key\n",
        "                genai.configure(api_key=gemini_key)\n",
        "                print(\"✅ Gemini API key configured from environment\")\n",
        "            else:\n",
        "                print(\"⚠️ Gemini API key not set\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error configuring Gemini API: {e}\")\n",
        "\n",
        "# Prompt user to input API keys if not found in environment\n",
        "def request_api_keys() -> None:\n",
        "    \"\"\"Request API keys from user if not found in environment variables.\"\"\"\n",
        "\n",
        "    print(\"\\n==== Secure API Key Configuration ====\")\n",
        "    print(\"API keys will be stored in environment variables for this session only.\")\n",
        "\n",
        "    if not Config.HF_TOKEN:\n",
        "        hf_token = input(\"Enter your Hugging Face API token (or press Enter to skip): \")\n",
        "        if hf_token:\n",
        "            os.environ['HUGGINGFACEHUB_API_TOKEN'] = hf_token\n",
        "            Config.HF_TOKEN = hf_token\n",
        "            import huggingface_hub\n",
        "            huggingface_hub.HfFolder.save_token(hf_token)\n",
        "            print(\"✅ Hugging Face token set\")\n",
        "\n",
        "    if not Config.GENAI_API_KEY:\n",
        "        genai_key = input(\"Enter your Google Generative AI API key: \")\n",
        "        if genai_key:\n",
        "            os.environ['GEMINI_API_KEY'] = genai_key\n",
        "            Config.GENAI_API_KEY = genai_key\n",
        "            genai.configure(api_key=genai_key)\n",
        "            print(\"✅ Gemini API key set\")"
      ],
      "metadata": {
        "id": "rV9olyhVu7h4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Security Guidelines\n",
        "\n",
        "1. **API Key Management**\n",
        "   - Never hardcode credentials\n",
        "   - Use environment variables or Colab secrets\n",
        "   - Recommended: `python-dotenv` for local development\n",
        "\n",
        "2. **Data Storage**\n",
        "   - Vector databases contain document embeddings\n",
        "   - Sensitive content should be pre-processed before ingestion\n",
        "\n",
        "3. **Access Control**\n",
        "   - Restrict write access to `RAGDocuments` and `RAGVectorDB` directories"
      ],
      "metadata": {
        "id": "l_CEucIHvHJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DOCUMENT PROCESSING MODULE\n",
        "\n",
        "class DocumentProcessor:\n",
        "    \"\"\"Handle document ingestion, parsing, and chunking.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_loader_for_file(file_path: str):\n",
        "        \"\"\"Return the appropriate loader based on file extension.\"\"\"\n",
        "        file_extension = file_path.split('.')[-1].lower()\n",
        "\n",
        "        try:\n",
        "            if file_extension == 'pdf':\n",
        "                return PyPDFLoader(file_path)\n",
        "            elif file_extension == 'txt':\n",
        "                return TextLoader(file_path)\n",
        "            elif file_extension in ['docx', 'doc']:\n",
        "                try:\n",
        "                    return Docx2txtLoader(file_path)\n",
        "                except Exception as e:\n",
        "                    print(f\"  ⚠️ Docx2txtLoader failed, trying UnstructuredFileLoader: {e}\")\n",
        "                    return UnstructuredLoader(file_path, mode=\"elements\")\n",
        "            else:\n",
        "                # Fallback to unstructured for other file types\n",
        "                return UnstructuredLoader(file_path, mode=\"elements\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating loader for {file_path}: {e}\")\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def load_documents(directory: str) -> Tuple[List[Any], List[str]]:\n",
        "        \"\"\"\n",
        "        Load all supported documents from a directory.\n",
        "\n",
        "        Args:\n",
        "            directory: Path to directory containing documents\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (loaded documents, list of failed files)\n",
        "        \"\"\"\n",
        "        documents = []\n",
        "        failed_files = []\n",
        "\n",
        "        # Check if directory exists\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory, exist_ok=True)\n",
        "            print(f\"Created document directory: {directory}\")\n",
        "            return documents, failed_files\n",
        "\n",
        "        # Get all files with supported extensions\n",
        "        file_pattern = os.path.join(directory, \"**\")\n",
        "        all_files = []\n",
        "\n",
        "        for ext in ['pdf', 'txt', 'docx', 'doc']:\n",
        "            all_files.extend(glob.glob(f\"{file_pattern}/*.{ext}\", recursive=True))\n",
        "\n",
        "        if not all_files:\n",
        "            print(f\"No supported documents found in {directory}\")\n",
        "            return documents, failed_files\n",
        "\n",
        "        print(f\"Found {len(all_files)} documents to process\")\n",
        "\n",
        "        # Process each file\n",
        "        for file_path in all_files:\n",
        "            try:\n",
        "                print(f\"Processing: {os.path.basename(file_path)}\")\n",
        "                loader = DocumentProcessor.get_loader_for_file(file_path)\n",
        "\n",
        "                if loader:\n",
        "                    try:\n",
        "                        file_docs = loader.load()\n",
        "                        # Add source metadata if not present\n",
        "                        for doc in file_docs:\n",
        "                            if 'source' not in doc.metadata:\n",
        "                                doc.metadata['source'] = file_path\n",
        "                        documents.extend(file_docs)\n",
        "                        print(f\"  ✓ Loaded {len(file_docs)} pages/sections\")\n",
        "                    except Exception as inner_e:\n",
        "                        print(f\"  ⚠️ First loader method failed, trying backup method: {inner_e}\")\n",
        "                        # Try fallback to UnstructuredFileLoader if first method fails\n",
        "                        try:\n",
        "                            backup_loader = UnstructuredLoader(file_path, mode=\"elements\")\n",
        "                            file_docs = backup_loader.load()\n",
        "                            for doc in file_docs:\n",
        "                                if 'source' not in doc.metadata:\n",
        "                                    doc.metadata['source'] = file_path\n",
        "                            documents.extend(file_docs)\n",
        "                            print(f\"  ✓ Loaded {len(file_docs)} pages/sections using backup loader\")\n",
        "                        except Exception as backup_e:\n",
        "                            print(f\"  ✗ All loading methods failed for {file_path}: {backup_e}\")\n",
        "                            failed_files.append(file_path)\n",
        "                else:\n",
        "                    failed_files.append(file_path)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ✗ Failed to load {file_path}: {e}\")\n",
        "                failed_files.append(file_path)\n",
        "\n",
        "        return documents, failed_files\n",
        "\n",
        "    @staticmethod\n",
        "    def chunk_documents(documents: List[Any], config: Any = None) -> List[Any]:\n",
        "        \"\"\"\n",
        "        Split documents into chunks for processing, with document-type awareness.\n",
        "\n",
        "        Args:\n",
        "            documents: List of LangChain document objects\n",
        "            config: Configuration object with chunking parameters\n",
        "\n",
        "        Returns:\n",
        "            List of document chunks\n",
        "        \"\"\"\n",
        "        if not documents:\n",
        "            return []\n",
        "\n",
        "        if config is None:\n",
        "            config = Config\n",
        "\n",
        "        # Process documents by type\n",
        "        all_chunks = []\n",
        "\n",
        "        for doc in documents:\n",
        "            # Determine the document type based on content and filename\n",
        "            doc_type = DocumentProcessor._detect_document_type(doc)\n",
        "\n",
        "            # Get appropriate chunk size based on document type\n",
        "            if hasattr(config, 'CHUNK_SIZES') and doc_type in config.CHUNK_SIZES:\n",
        "                chunk_size = config.CHUNK_SIZES[doc_type]\n",
        "            else:\n",
        "                chunk_size = config.DEFAULT_CHUNK_SIZE\n",
        "\n",
        "            # Calculate overlap based on chunk size\n",
        "            chunk_overlap = max(config.CHUNK_OVERLAP, int(chunk_size * 0.25))\n",
        "\n",
        "            # Create a text splitter for this document\n",
        "            text_splitter = RecursiveCharacterTextSplitter(\n",
        "                chunk_size=chunk_size,\n",
        "                chunk_overlap=chunk_overlap,\n",
        "                length_function=len,\n",
        "                separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        "            )\n",
        "\n",
        "            # Split this document\n",
        "            doc_chunks = text_splitter.split_documents([doc])\n",
        "            all_chunks.extend(doc_chunks)\n",
        "\n",
        "        print(f\"Split {len(documents)} documents into {len(all_chunks)} chunks \" +\n",
        "              f\"using adaptive chunking strategy\")\n",
        "\n",
        "        return all_chunks\n",
        "\n",
        "    @staticmethod\n",
        "    def _detect_document_type(doc: Any) -> str:\n",
        "        \"\"\"\n",
        "        Detect whether a document is technical or narrative based on its content.\n",
        "\n",
        "        Args:\n",
        "            doc: LangChain document object\n",
        "\n",
        "        Returns:\n",
        "            String indicating document type (\"technical\" or \"narrative\")\n",
        "        \"\"\"\n",
        "        # Check filename first (if available)\n",
        "        if hasattr(doc, 'metadata') and 'source' in doc.metadata:\n",
        "            filename = doc.metadata['source'].lower()\n",
        "\n",
        "            # Check for technical indicators in filename\n",
        "            technical_indicators = ['manual', 'guide', 'reference', 'documentation',\n",
        "                                   'api', 'technical', 'spec', 'report', 'cheat', 'sheet']\n",
        "\n",
        "            for indicator in technical_indicators:\n",
        "                if indicator in filename:\n",
        "                    return \"technical\"\n",
        "\n",
        "        # Analyze content\n",
        "        if hasattr(doc, 'page_content') and doc.page_content:\n",
        "            content = doc.page_content.lower()\n",
        "\n",
        "            # Skip very short content\n",
        "            if len(content) < 50:  # Too short for reliable analysis\n",
        "                return \"technical\"  # Default to technical for very short content\n",
        "\n",
        "            # Check content characteristics\n",
        "\n",
        "            # Technical indicators: high presence of specialized terminology/formatting\n",
        "            technical_patterns = [\n",
        "                r'\\b[a-z]+\\([^)]*\\)',  # Function calls\n",
        "                r'\\b[A-Z][A-Za-z]*[A-Z][A-Za-z]*\\b',  # CamelCase\n",
        "                r'```|~~~',  # Code blocks\n",
        "                r'\\b\\d+\\.\\d+\\.\\d+\\b',  # Version numbers\n",
        "                r'http[s]?://',  # URLs\n",
        "                r'[<>{};]',  # HTML/code symbols\n",
        "                r'\\$[a-z]+'  # LaTeX\n",
        "            ]\n",
        "\n",
        "            technical_score = sum(len(re.findall(pattern, content)) for pattern in technical_patterns)\n",
        "\n",
        "            # Avoid division by zero by ensuring a minimum content length\n",
        "            content_length_kb = max(0.001, len(content) / 1000)  # Ensure minimum 0.001 to avoid div/0\n",
        "            technical_score = technical_score / content_length_kb  # Normalize per 1000 chars\n",
        "\n",
        "            if technical_score > 0.5:\n",
        "                return \"technical\"\n",
        "\n",
        "        # Default to narrative if nothing indicates technical\n",
        "        return \"narrative\""
      ],
      "metadata": {
        "id": "vCm-utolvtg2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VECTOR DATABASE MODULE\n",
        "\n",
        "class VectorDBManager:\n",
        "    \"\"\"Manage vector database operations including embedding and storage.\"\"\"\n",
        "\n",
        "    def __init__(self, embedding_model_name: str = Config.EMBEDDING_MODEL, persist_dir: str = Config.DB_DIR):\n",
        "        \"\"\"\n",
        "        Initialize the vector database manager.\n",
        "\n",
        "        Args:\n",
        "            embedding_model_name: Name of the HuggingFace embedding model\n",
        "            persist_dir: Directory to persist the vector database\n",
        "        \"\"\"\n",
        "        self.persist_dir = persist_dir\n",
        "\n",
        "        # Create embeddings model\n",
        "        self.embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=embedding_model_name,\n",
        "            cache_folder=\"/tmp/hf_cache\"\n",
        "        )\n",
        "\n",
        "        # Ensure persistence directory exists\n",
        "        os.makedirs(persist_dir, exist_ok=True)\n",
        "\n",
        "    def create_or_load_db(self, document_chunks: List[Any], db_type: str = \"chroma\") -> Any:\n",
        "        \"\"\"\n",
        "        Create a new vector database or load existing one.\n",
        "\n",
        "        Args:\n",
        "            document_chunks: List of document chunks to embed\n",
        "            db_type: Type of vector database (\"chroma\" or \"faiss\")\n",
        "\n",
        "        Returns:\n",
        "            Vector database instance\n",
        "        \"\"\"\n",
        "        if not document_chunks and not os.path.exists(os.path.join(self.persist_dir, 'index')):\n",
        "            raise ValueError(\"Cannot create database: No documents provided and no existing DB found\")\n",
        "\n",
        "        if db_type.lower() == \"chroma\":\n",
        "            # Check if database already exists\n",
        "            if os.path.exists(os.path.join(self.persist_dir, 'index')):\n",
        "                print(f\"Loading existing Chroma database from {self.persist_dir}\")\n",
        "                return Chroma(\n",
        "                    persist_directory=self.persist_dir,\n",
        "                    embedding_function=self.embeddings\n",
        "                )\n",
        "            else:\n",
        "                print(f\"Creating new Chroma database in {self.persist_dir}\")\n",
        "                db = Chroma.from_documents(\n",
        "                    documents=document_chunks,\n",
        "                    embedding=self.embeddings,\n",
        "                    persist_directory=self.persist_dir\n",
        "                )\n",
        "                # DB is auto-persisted since Chroma 0.4.x\n",
        "                return db\n",
        "\n",
        "        elif db_type.lower() == \"faiss\":\n",
        "            index_file = os.path.join(self.persist_dir, \"faiss_index\")\n",
        "\n",
        "            if os.path.exists(index_file):\n",
        "                print(f\"Loading existing FAISS database from {index_file}\")\n",
        "                return FAISS.load_local(\n",
        "                    folder_path=self.persist_dir,\n",
        "                    embeddings=self.embeddings,\n",
        "                    index_name=\"faiss_index\"\n",
        "                )\n",
        "            else:\n",
        "                print(f\"Creating new FAISS database in {self.persist_dir}\")\n",
        "                db = FAISS.from_documents(\n",
        "                    documents=document_chunks,\n",
        "                    embedding=self.embeddings\n",
        "                )\n",
        "                db.save_local(self.persist_dir, index_name=\"faiss_index\")\n",
        "                return db\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported vector database type: {db_type}\")"
      ],
      "metadata": {
        "id": "bPTGwq4px05D"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG AGENT MODULE\n",
        "\n",
        "class RAGAgent:\n",
        "    \"\"\"Implement the RAG pipeline with retrieval and generation capabilities.\"\"\"\n",
        "\n",
        "    def __init__(self, vector_db: Any, api_key: str = None):\n",
        "        \"\"\"\n",
        "        Initialize the RAG agent.\n",
        "\n",
        "        Args:\n",
        "            vector_db: Vector database for retrieval\n",
        "            api_key: Google Generative AI API key\n",
        "        \"\"\"\n",
        "        self.vector_db = vector_db\n",
        "\n",
        "        # Configure the Gemini model\n",
        "        if api_key:\n",
        "            genai.configure(api_key=api_key)\n",
        "\n",
        "        # Create the LLM using the approach confirmed to work\n",
        "        self.llm = ChatGoogleGenerativeAI(\n",
        "            model=\"gemini-1.5-flash\",\n",
        "            temperature=0.6,\n",
        "            top_p=0.95,\n",
        "            google_api_key=api_key,\n",
        "            convert_system_message_to_human=True\n",
        "        )\n",
        "\n",
        "        # Set up the retriever\n",
        "        self.retriever = vector_db.as_retriever(\n",
        "            search_type=\"similarity\",\n",
        "            search_kwargs={\"k\": Config.TOP_K_RETRIEVAL}\n",
        "        )\n",
        "\n",
        "        # Create conversation memory\n",
        "        self.memory = ConversationBufferMemory(\n",
        "            memory_key=\"chat_history\",\n",
        "            return_messages=True,\n",
        "            output_key=\"answer\"  # Explicitly set the output key\n",
        "        )\n",
        "\n",
        "    def create_qa_chain(self) -> Any:\n",
        "        \"\"\"\n",
        "        Create a conversational QA chain with RAG capabilities.\n",
        "\n",
        "        Returns:\n",
        "            Conversational retrieval chain\n",
        "        \"\"\"\n",
        "        # Custom prompt template for RAG\n",
        "        prompt_template = \"\"\"\n",
        "        You are a helpful assistant answering questions based on retrieved document content.\n",
        "\n",
        "        CONTEXT INFORMATION:\n",
        "        {context}\n",
        "\n",
        "        CHAT HISTORY:\n",
        "        {chat_history}\n",
        "\n",
        "        QUESTION:\n",
        "        {question}\n",
        "\n",
        "        YOUR RESPONSE:\n",
        "        Answer the question based ONLY on the provided context. If the context doesn't contain\n",
        "        relevant information, say \"I don't have enough information to answer this question.\"\n",
        "\n",
        "        When answering, cite the source document names in your response.\n",
        "        Follow the KISS principle (Keep It Simple, Stupid) and provide clear, concise answers.\n",
        "        \"\"\"\n",
        "\n",
        "        PROMPT = PromptTemplate(\n",
        "            template=prompt_template,\n",
        "            input_variables=[\"context\", \"chat_history\", \"question\"]\n",
        "        )\n",
        "\n",
        "        # Create the conversational chain with explicit output_key\n",
        "        chain = ConversationalRetrievalChain.from_llm(\n",
        "            llm=self.llm,\n",
        "            retriever=self.retriever,\n",
        "            memory=self.memory,\n",
        "            combine_docs_chain_kwargs={\"prompt\": PROMPT},\n",
        "            return_source_documents=True,\n",
        "            output_key=\"answer\",  # Explicitly set the output key\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        return chain\n",
        "\n",
        "    def answer_question(self, question: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Answer a question using the RAG pipeline.\n",
        "\n",
        "        Args:\n",
        "            question: User's question\n",
        "\t          possible error returns:\n",
        "    \t    \t    - 401: Invalid API key\n",
        "    \t    \t    - 429: Rate limit exceeded\n",
        "    \t    \t    - 500: LLM service unavailable\n",
        "\n",
        "        Returns:\n",
        "            Dict with keys:\n",
        "       \t        - 'answer' (str)\n",
        "\t              - 'sources' (List[str])\n",
        "\t              - 'error' (Optional[str])\n",
        "        \"\"\"\n",
        "\n",
        "        chain = self.create_qa_chain()\n",
        "\n",
        "        try:\n",
        "            # Use the chain to answer the question\n",
        "            result = chain.invoke({\"question\": question})\n",
        "\n",
        "            # Extract answer and sources\n",
        "            answer = result.get(\"answer\", \"\")\n",
        "\n",
        "            # Extract source information\n",
        "            sources = []\n",
        "            if \"source_documents\" in result:\n",
        "                for doc in result[\"source_documents\"]:\n",
        "                    if \"source\" in doc.metadata:\n",
        "                        source_path = doc.metadata[\"source\"]\n",
        "                        source_name = os.path.basename(source_path)\n",
        "                        sources.append(source_name)\n",
        "\n",
        "            return {\n",
        "                \"answer\": answer,\n",
        "                \"sources\": list(set(sources))  # Deduplicate sources\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error generating answer: {str(e)}\"\n",
        "            print(error_msg)\n",
        "            return {\n",
        "                \"answer\": \"I encountered an error while trying to answer your question. Please try again.\",\n",
        "                \"error\": error_msg,\n",
        "                \"sources\": []\n",
        "            }\n",
        "\n",
        "    def reset_memory(self) -> None:\n",
        "        \"\"\"Reset the conversation memory.\"\"\"\n",
        "        self.memory.clear()"
      ],
      "metadata": {
        "id": "rOdqeXfHyFvd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Framework"
      ],
      "metadata": {
        "id": "JxkacVFCApuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "h61mza7Q2CAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# UI MODULE\n",
        "\n",
        "class RAGUI:\n",
        "    \"\"\"User interface for the RAG application.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the UI components.\"\"\"\n",
        "        self.rag_agent = None\n",
        "        self.document_processor = None\n",
        "        self.vector_db_manager = None\n",
        "        self.vector_db = None\n",
        "\n",
        "        # UI components\n",
        "        self.doc_path_input = widgets.Text(\n",
        "            value=Config.DOC_DIR,\n",
        "            description='Document Path:',\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='40%')\n",
        "        )\n",
        "\n",
        "        self.load_docs_button = widgets.Button(\n",
        "            description='Load Documents',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='10%')\n",
        "        )\n",
        "        self.load_docs_button.on_click(self.load_documents_callback)\n",
        "\n",
        "        self.status_output = widgets.Output(layout={'border': '1px solid #ddd'})\n",
        "\n",
        "        self.question_input = widgets.Text(\n",
        "            value='',\n",
        "            placeholder='Ask a question about your documents...',\n",
        "            description='Question:',\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='40%'),\n",
        "            disabled=True\n",
        "        )\n",
        "        self.question_input.on_submit(self.answer_question_callback)\n",
        "\n",
        "        self.ask_button = widgets.Button(\n",
        "            description='Ask',\n",
        "            button_style='success',\n",
        "            layout=widgets.Layout(width='5%'),\n",
        "            disabled=True\n",
        "        )\n",
        "        self.ask_button.on_click(self.answer_question_callback)\n",
        "\n",
        "        self.reset_chat_button = widgets.Button(\n",
        "            description='Reset Chat',\n",
        "            button_style='warning',\n",
        "            layout=widgets.Layout(width='5%'),\n",
        "            disabled=True\n",
        "        )\n",
        "        self.reset_chat_button.on_click(self.reset_chat_callback)\n",
        "\n",
        "        self.answer_output = widgets.Output(layout={'border': '1px solid #ddd'})\n",
        "\n",
        "    def display_ui(self) -> None:\n",
        "        \"\"\"Display the complete UI.\"\"\"\n",
        "        # First check and request API keys\n",
        "        setup_api_keys()\n",
        "        if not Config.HF_TOKEN or not Config.GENAI_API_KEY:\n",
        "            request_api_keys()\n",
        "\n",
        "        # App title\n",
        "        display(HTML(\"<h1>RAG-Powered Document Q&A System</h1>\"))\n",
        "\n",
        "        # Document loading section\n",
        "        display(HTML(\"<h2>1. Document Processing</h2>\"))\n",
        "        display(widgets.HBox([self.doc_path_input, self.load_docs_button]))\n",
        "        display(self.status_output)\n",
        "\n",
        "        # Q&A section\n",
        "        display(HTML(\"<h2>2. Ask Questions</h2>\"))\n",
        "        display(widgets.HBox([self.question_input, self.ask_button, self.reset_chat_button]))\n",
        "        display(self.answer_output)\n",
        "\n",
        "        # Display initial status\n",
        "        with self.status_output:\n",
        "            print(\"Status: Ready to load documents\")\n",
        "            print(f\"Document directory: {Config.DOC_DIR}\")\n",
        "            print(f\"Vector DB directory: {Config.DB_DIR}\")\n",
        "            if os.path.exists(os.path.join(Config.DB_DIR, 'index')):\n",
        "                print(\"An existing vector database was found and will be used if no new documents are loaded.\")\n",
        "\n",
        "    def load_documents_callback(self, button) -> None:\n",
        "        \"\"\"Callback for document loading button.\"\"\"\n",
        "        with self.status_output:\n",
        "            clear_output()\n",
        "            print(f\"Loading documents from: {self.doc_path_input.value}\")\n",
        "\n",
        "            try:\n",
        "                # Update document directory in config\n",
        "                Config.DOC_DIR = self.doc_path_input.value\n",
        "\n",
        "                # Initialize document processor\n",
        "                self.document_processor = DocumentProcessor()\n",
        "\n",
        "                # Load documents\n",
        "                documents, failed_files = self.document_processor.load_documents(Config.DOC_DIR)\n",
        "\n",
        "                if not documents:\n",
        "                    print(\"⚠️ No documents were loaded successfully. Please check the document directory.\")\n",
        "                    if failed_files:\n",
        "                        print(f\"Failed files: {', '.join([os.path.basename(f) for f in failed_files])}\")\n",
        "                    return\n",
        "\n",
        "                # Chunk documents\n",
        "                document_chunks = self.document_processor.chunk_documents(\n",
        "                    documents,\n",
        "                    config=Config  # Pass the entire config\n",
        "                    #chunk_size=Config.CHUNK_SIZE,\n",
        "                    #chunk_overlap=Config.CHUNK_OVERLAP\n",
        "                )\n",
        "\n",
        "                # Initialize vector database\n",
        "                self.vector_db_manager = VectorDBManager(\n",
        "                    embedding_model_name=Config.EMBEDDING_MODEL,\n",
        "                    persist_dir=Config.DB_DIR\n",
        "                )\n",
        "\n",
        "                # Create or load vector database\n",
        "                self.vector_db = self.vector_db_manager.create_or_load_db(document_chunks)\n",
        "\n",
        "                # Fix persistence warning\n",
        "                if hasattr(self.vector_db, 'persist'):\n",
        "                    print(\"Note: Using Chroma DB which now auto-persists data\")\n",
        "\n",
        "                # Initialize RAG agent\n",
        "                self.rag_agent = RAGAgent(self.vector_db, api_key=Config.GENAI_API_KEY)\n",
        "\n",
        "                # Enable Q&A components\n",
        "                self.question_input.disabled = False\n",
        "                self.ask_button.disabled = False\n",
        "                self.reset_chat_button.disabled = False\n",
        "\n",
        "                print(\"✅ System ready for questions!\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error during document processing: {str(e)}\")\n",
        "\n",
        "    def answer_question_callback(self, widget) -> None:\n",
        "        \"\"\"Callback for question answering.\"\"\"\n",
        "        question = self.question_input.value\n",
        "\n",
        "        if not question.strip():\n",
        "            return\n",
        "\n",
        "        with self.answer_output:\n",
        "            clear_output()\n",
        "            print(f\"Q: {question}\")\n",
        "            print(\"Thinking...\")\n",
        "\n",
        "            if self.rag_agent:\n",
        "                try:\n",
        "                    result = self.rag_agent.answer_question(question)\n",
        "\n",
        "                    clear_output()\n",
        "                    print(f\"Q: {question}\")\n",
        "                    print(f\"\\nA: {result['answer']}\")\n",
        "\n",
        "                    if result.get('sources'):\n",
        "                        print(f\"\\nSources: {', '.join(result['sources'])}\")\n",
        "\n",
        "                    if result.get('error'):\n",
        "                        print(f\"\\nError details: {result['error']}\")\n",
        "                except Exception as e:\n",
        "                    clear_output()\n",
        "                    print(f\"Q: {question}\")\n",
        "                    print(f\"\\nA: I encountered an error while trying to answer your question.\")\n",
        "                    print(f\"\\nError details: {str(e)}\")\n",
        "            else:\n",
        "                print(\"❌ System not initialized. Please load documents first.\")\n",
        "\n",
        "        # Clear the question input\n",
        "        self.question_input.value = ''\n",
        "\n",
        "    def reset_chat_callback(self, button) -> None:\n",
        "        \"\"\"Callback to reset the chat history.\"\"\"\n",
        "        if self.rag_agent:\n",
        "            self.rag_agent.reset_memory()\n",
        "\n",
        "            with self.answer_output:\n",
        "                clear_output()\n",
        "                print(\"Chat history has been reset.\")"
      ],
      "metadata": {
        "id": "12t9-nJhyOwd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAIN APP\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main entry point for the application.\"\"\"\n",
        "    print(\"Starting RAG-Powered Document Q&A System...\")\n",
        "\n",
        "    # Debug - print environment variables (without showing key values)\n",
        "    print(\"\\nChecking for environment variables:\")\n",
        "    for env_var in ['HUGGINGFACEHUB_API_TOKEN', 'GEMINI_API_KEY']:\n",
        "        if env_var in os.environ:\n",
        "            print(f\" Local Env ✓ {env_var} is set\")\n",
        "        else:\n",
        "            print(f\" Local Env ✗ {env_var} is not set\")\n",
        "\n",
        "    # Create and display UI\n",
        "    ui = RAGUI()\n",
        "    ui.display_ui()\n",
        "\n",
        "# Run the application\n",
        "main()\n",
        "\n",
        "# EXAMPLE USAGE\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "display(HTML('''\n",
        "<style>\n",
        "    .modern-container {\n",
        "        max-width: 800px;\n",
        "        margin: 0 auto;\n",
        "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "        line-height: 1.6;\n",
        "    }\n",
        "\n",
        "    .section-header {\n",
        "        color: #2c3e50;\n",
        "        border-bottom: 2px solid #3498db;\n",
        "        padding: 15px 0;\n",
        "        margin: 25px 0 15px;\n",
        "    }\n",
        "\n",
        "    .card {\n",
        "        background: #ffffff;\n",
        "        border-radius: 8px;\n",
        "        box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
        "        padding: 20px;\n",
        "        margin: 15px 0;\n",
        "    }\n",
        "\n",
        "    .card h3 {\n",
        "        color: #34495e;\n",
        "        margin-top: 0;\n",
        "    }\n",
        "\n",
        "    .code-snippet {\n",
        "        background: #f8f9fa;\n",
        "        border: 1px solid #e1e4e8;\n",
        "        border-radius: 4px;\n",
        "        padding: 8px 12px;\n",
        "        font-family: 'Courier New', Courier, monospace;\n",
        "        color: #d63384;\n",
        "    }\n",
        "\n",
        "    .list-item {\n",
        "        margin: 10px 0;\n",
        "        padding-left: 20px;\n",
        "        position: relative;\n",
        "    }\n",
        "\n",
        "    .list-item::before {\n",
        "        content: '';\n",
        "        position: absolute;\n",
        "        left: 0;\n",
        "        top: 50%;\n",
        "        transform: translateY(-50%);\n",
        "        width: 8px;\n",
        "        height: 8px;\n",
        "        background: #1abc9c;\n",
        "        border-radius: 50%;\n",
        "    }\n",
        "</style>\n",
        "\n",
        "<div class=\"modern-container\">\n",
        "    <div class=\"card\">\n",
        "        <h2 class=\"section-header\">Example Test Queries</h2>\n",
        "        <div class=\"list-item\">\n",
        "            <h3>Basic information retrieval:</h3>\n",
        "            <p class=\"code-snippet\">\"What are the main topics covered in these documents?\"</p>\n",
        "        </div>\n",
        "        <div class=\"list-item\">\n",
        "            <h3>Specific information retrieval:</h3>\n",
        "            <p class=\"code-snippet\">\"What does [specific document] say about [specific topic]?\"</p>\n",
        "        </div>\n",
        "        <div class=\"list-item\">\n",
        "            <h3>Comparative analysis:</h3>\n",
        "            <p class=\"code-snippet\">\"Compare how different documents approach [topic].\"</p>\n",
        "        </div>\n",
        "        <div class=\"list-item\">\n",
        "            <h3>Follow-up questions:</h3>\n",
        "            <p class=\"code-snippet\">\"Tell me more about [something mentioned in previous answer].\"</p>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"card\">\n",
        "        <h2 class=\"section-header\">Customization Options</h2>\n",
        "        <div class=\"list-item\">\n",
        "            <h3>Change embedding model:</h3>\n",
        "            <p>Modify <span class=\"code-snippet\">Config.EMBEDDING_MODEL</span> to use different HuggingFace models</p>\n",
        "            <p class=\"code-snippet\">\"sentence-transformers/all-mpnet-base-v2\"</p>\n",
        "        </div>\n",
        "        <div class=\"list-item\">\n",
        "            <h3>Adjust chunking parameters:</h3>\n",
        "            <p>Modify <span class=\"code-snippet\">Config.CHUNK_SIZE</span> and <span class=\"code-snippet\">Config.CHUNK_OVERLAP</span></p>\n",
        "        </div>\n",
        "        <div class=\"list-item\">\n",
        "            <h3>Tune retrieval parameters:</h3>\n",
        "            <p>Adjust <span class=\"code-snippet\">Config.TOP_K_RETRIEVAL</span></p>\n",
        "        </div>\n",
        "        <div class=\"list-item\">\n",
        "            <h3>Switch vector database:</h3>\n",
        "            <p>Use <span class=\"code-snippet\">\"faiss\"</span> instead of <span class=\"code-snippet\">\"chroma\"</span></p>\n",
        "        </div>\n",
        "        <div class=\"list-item\">\n",
        "            <h3>Modify LLM parameters:</h3>\n",
        "            <p>Adjust <span class=\"code-snippet\">temperature</span> and <span class=\"code-snippet\">top_p</span> in <span class=\"code-snippet\">RAGAgent.__init__()</span></p>\n",
        "        </div>\n",
        "    </div>\n",
        "</div>\n",
        "'''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6099e8bc57264383803bc3055edb1757",
            "df915b47c1d04864ae4648f10d6c7908",
            "2f14bceac44547159907ad29b36deff1",
            "932abf1180d84b1aad436530ce704b03",
            "c89144318f144110a2a547f0ab0cadc1",
            "59dc70cc7f1749d7bc2ecca89dd17524",
            "d57d799be9a646ed808cfdfbe437b62a",
            "59f64adf45e3413fb7b40de8f9e381c1",
            "3b7c0acc93814ea993f1720b742226a8",
            "17777cb9321f4c02998ec824894e41c3",
            "33127b92629d4df5bb1af68b079e748b",
            "1b29346ed04d455b967be7b2fc59af8d",
            "e50dcbb7259c487181a1d2f010d6cde7",
            "321aed7f12094d1db5cd9da1937e2219",
            "88343724a44b4e998efad25779438dc8",
            "3231f320d01c4779a70dae4a6edbed55",
            "c3d7a168692b45f1a97bfd0fa2e55544",
            "d448c89b981a41ae90a118c92d781063",
            "453d2b05ea2c475a83b8dc263c8024ec",
            "2250ab7de3234675b76873b29f068a8f",
            "a2596b39dddb4cfdb8add6d78281db03",
            "7ab66d9184fa4bbd86fcceec30a257ee",
            "49723774080d4b0f958994e6d7348db3"
          ]
        },
        "id": "Bx3_grE_JsNW",
        "outputId": "22a9f7b7-0578-4590-c0a6-04cd20ef476a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting RAG-Powered Document Q&A System...\n",
            "\n",
            "Checking for environment variables:\n",
            " Local Env ✗ HUGGINGFACEHUB_API_TOKEN is not set\n",
            " Local Env ✗ GEMINI_API_KEY is not set\n",
            "✅ Hugging Face token synced with Colab secrets\n",
            "✅ Gemini API key synced with Colab secrets\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>RAG-Powered Document Q&A System</h1>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h2>1. Document Processing</h2>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Text(value='/content/drive/MyDrive/RAGDocuments', description='Document Path:', layout=Layout(w…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6099e8bc57264383803bc3055edb1757"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output(layout=Layout(border='1px solid #ddd'))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b7c0acc93814ea993f1720b742226a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h2>2. Ask Questions</h2>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Text(value='', description='Question:', disabled=True, layout=Layout(width='40%'), placeholder=…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33127b92629d4df5bb1af68b079e748b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output(layout=Layout(border='1px solid #ddd'))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ab66d9184fa4bbd86fcceec30a257ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    .modern-container {\n",
              "        max-width: 800px;\n",
              "        margin: 0 auto;\n",
              "        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
              "        line-height: 1.6;\n",
              "    }\n",
              "\n",
              "    .section-header {\n",
              "        color: #2c3e50;\n",
              "        border-bottom: 2px solid #3498db;\n",
              "        padding: 15px 0;\n",
              "        margin: 25px 0 15px;\n",
              "    }\n",
              "\n",
              "    .card {\n",
              "        background: #ffffff;\n",
              "        border-radius: 8px;\n",
              "        box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
              "        padding: 20px;\n",
              "        margin: 15px 0;\n",
              "    }\n",
              "\n",
              "    .card h3 {\n",
              "        color: #34495e;\n",
              "        margin-top: 0;\n",
              "    }\n",
              "\n",
              "    .code-snippet {\n",
              "        background: #f8f9fa;\n",
              "        border: 1px solid #e1e4e8;\n",
              "        border-radius: 4px;\n",
              "        padding: 8px 12px;\n",
              "        font-family: 'Courier New', Courier, monospace;\n",
              "        color: #d63384;\n",
              "    }\n",
              "\n",
              "    .list-item {\n",
              "        margin: 10px 0;\n",
              "        padding-left: 20px;\n",
              "        position: relative;\n",
              "    }\n",
              "\n",
              "    .list-item::before {\n",
              "        content: '';\n",
              "        position: absolute;\n",
              "        left: 0;\n",
              "        top: 50%;\n",
              "        transform: translateY(-50%);\n",
              "        width: 8px;\n",
              "        height: 8px;\n",
              "        background: #1abc9c;\n",
              "        border-radius: 50%;\n",
              "    }\n",
              "</style>\n",
              "\n",
              "<div class=\"modern-container\">\n",
              "    <div class=\"card\">\n",
              "        <h2 class=\"section-header\">Example Test Queries</h2>\n",
              "        <div class=\"list-item\">\n",
              "            <h3>Basic information retrieval:</h3>\n",
              "            <p class=\"code-snippet\">\"What are the main topics covered in these documents?\"</p>\n",
              "        </div>\n",
              "        <div class=\"list-item\">\n",
              "            <h3>Specific information retrieval:</h3>\n",
              "            <p class=\"code-snippet\">\"What does [specific document] say about [specific topic]?\"</p>\n",
              "        </div>\n",
              "        <div class=\"list-item\">\n",
              "            <h3>Comparative analysis:</h3>\n",
              "            <p class=\"code-snippet\">\"Compare how different documents approach [topic].\"</p>\n",
              "        </div>\n",
              "        <div class=\"list-item\">\n",
              "            <h3>Follow-up questions:</h3>\n",
              "            <p class=\"code-snippet\">\"Tell me more about [something mentioned in previous answer].\"</p>\n",
              "        </div>\n",
              "    </div>\n",
              "\n",
              "    <div class=\"card\">\n",
              "        <h2 class=\"section-header\">Customization Options</h2>\n",
              "        <div class=\"list-item\">\n",
              "            <h3>Change embedding model:</h3>\n",
              "            <p>Modify <span class=\"code-snippet\">Config.EMBEDDING_MODEL</span> to use different HuggingFace models</p>\n",
              "            <p class=\"code-snippet\">\"sentence-transformers/all-mpnet-base-v2\"</p>\n",
              "        </div>\n",
              "        <div class=\"list-item\">\n",
              "            <h3>Adjust chunking parameters:</h3>\n",
              "            <p>Modify <span class=\"code-snippet\">Config.CHUNK_SIZE</span> and <span class=\"code-snippet\">Config.CHUNK_OVERLAP</span></p>\n",
              "        </div>\n",
              "        <div class=\"list-item\">\n",
              "            <h3>Tune retrieval parameters:</h3>\n",
              "            <p>Adjust <span class=\"code-snippet\">Config.TOP_K_RETRIEVAL</span></p>\n",
              "        </div>\n",
              "        <div class=\"list-item\">\n",
              "            <h3>Switch vector database:</h3>\n",
              "            <p>Use <span class=\"code-snippet\">\"faiss\"</span> instead of <span class=\"code-snippet\">\"chroma\"</span></p>\n",
              "        </div>\n",
              "        <div class=\"list-item\">\n",
              "            <h3>Modify LLM parameters:</h3>\n",
              "            <p>Adjust <span class=\"code-snippet\">temperature</span> and <span class=\"code-snippet\">top_p</span> in <span class=\"code-snippet\">RAGAgent.__init__()</span></p>\n",
              "        </div>\n",
              "    </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EK-bx5AOBZzq"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}